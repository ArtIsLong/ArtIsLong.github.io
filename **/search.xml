<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Swagger常用注解]]></title>
    <url>%2F2018%2F12%2F01%2FSwagger%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。总体目标是使客户端和文件系统作为服务器以同样的速度来更新。文件的方法，参数和模型紧密集成到服务器端的代码，允许API来始终保持同步。 Swagger主要有以下几个作用： Swagger可以生成一个具有互动性的API控制台，开发者可以用来快速学习和尝试API。 Swagger文件可以在许多不同的平台上从代码注释中自动生成。 Swagger提供API在线测试功能 Swagger可以分析用户Swagger资源声明以各种语言生成客户端代码。 Swagger常用的功能还是生成在线API，接下来把Swagger常用的注解做以简单的记录。 @Api()用于类； 表示标识这个类是swagger的资源 123tags–表示说明 value–也是说明，可以使用tags替代 但是tags如果有多个值，会生成多个list @ApiOperation()用于方法；表示一个http请求的操作 123value用于方法描述 notes用于提示内容 tags可以重新分组（视情况而用） @ApiParam()用于方法，参数，字段说明；表示对参数的添加元数据（说明或是否必填等） 123name–参数名 value–参数说明 required–是否必填 @ApiModel()用于类表示对类进行说明，用于参数用实体类接收 12value–表示对象名 description–描述 @ApiModelProperty()用于方法，字段表示对model属性的说明或者数据操作更改 123456value–字段说明 name–重写属性名字 dataType–重写属性类型 required–是否必填 example–举例说明 hidden–隐藏 @ApiIgnore()用于类，方法，方法参数表示这个方法或者类被忽略,不被序列化 @ApiImplicitParam() 用于方法表示单独的请求参数 @ApiImplicitParams() 用于方法，包含多个 @ApiImplicitParam 12345name–参数ming value–参数说明 dataType–数据类型 paramType–参数类型 example–举例说明 推荐个大神的swagger-spring-boot-starter 12345&lt;dependency&gt; &lt;groupId&gt;com.spring4all&lt;/groupId&gt; &lt;artifactId&gt;swagger-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.7.1.RELEASE&lt;/version&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>开发工具框架</category>
      </categories>
      <tags>
        <tag>开发工具框架</tag>
        <tag>Swagger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jackson-annotations常用注解]]></title>
    <url>%2F2018%2F12%2F01%2FJackson-annotations%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文链接:https://www.dubby.cn/detail.html?id=9071 字段命名 @JsonProperty 可以指定字段的命名（还可以指定这个字段需要参与序列化和反序列化）。 @JsonProperty.value:指定的字段名字 @JsonProperty.index:指定顺序，默写数据格式是基于顺序(JSON不是这种数据格式)。 @JsonProperty.defaultValue:默认值。注意：这个属性目前为止并没有被core和data-bind使用；制备一些扩展模块使用。 字段包含 @JsonAutoDetect:定义默认的字段包含规则 @JsonIgnore:忽略某个指定的字段: 修饰字段，setter和getter中的任何一个，相当于所有都加了 除非使用@JsonProperty修饰，可以实现只忽略序列化或者反序列化 @JsonIgnoreProperties:修饰类，指定忽略一个字段列表，或者忽略那些未知的字段 @JsonIgnoreType:修饰类，忽略指定的类型的字段 @JsonInclude:可以定义空值是否参与(反)序列化 字段文档，元数据 @JsonPropertyDescription:2.3支持，给字段配置人类阅读的解释 core和data-bind不会使用这个注解，主要是被JSON Schema generator这个模块使用 反序列化和序列化的细节 @JsonFormat:对于Date/Time字段，可以指定格式化格式 @JsonUnwrapped:指定某个字段(类型是POJO)序列化成扁平化，而不是嵌套对象，在反序列化时再包装成对象 @JsonView:可以定义视图 @JsonUnwrapped(prefix = &quot;pre&quot;)简单解释: 1234567public class MyValue &#123; public String name; JsonUnwrapped(prefix = "pre_", suffix = "_suf") public MyValue myValue; public int age; public Date date;&#125; 序列化结果: 1&#123;"name":"杨正","pre_name_suf":null,"pre_age_suf":0,"pre_date_suf":null,"age":24,"date":"2017-12-09"&#125; @JsonView简单解释: 1234567891011121314151617181920212223242526272829303132public class JsonViewTest &#123; public static void main(String[] args) throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); String json = "&#123;\"username\":\"dubby.cn\",\"password\":\"123456\"&#125;"; //反序列化，使用视图 User user = objectMapper.readerWithView(User.UserWithoutPassword.class).forType(User.class).readValue(json); System.out.println(user); user.password = "xxxx"; //序列化，使用视图 String result1 = objectMapper.writerWithView(User.UserWithoutPassword.class).writeValueAsString(user); System.out.println(result1); String result2 = objectMapper.writerWithView(User.UserWithPassword.class).writeValueAsString(user); System.out.println(result2); &#125;&#125;class User &#123; @JsonView(&#123;UserWithoutPassword.class&#125;) public String username; @JsonView(&#123;UserWithPassword.class&#125;) public String password; public interface UserWithPassword extends UserWithoutPassword &#123; &#125; public interface UserWithoutPassword &#123; &#125; @Override public String toString() &#123; return "User&#123;" + "username='" + username + '\'' + ", password='" + password + '\'' + '&#125;'; &#125;&#125; 反序列化细节 @JacksonInject:指示某个字段的值是注入的，而不是从JSON中取出的 @JsonAnySetter:修饰一个2个参数的方法，任何JSON中有，而对象中没有的字段都会以(key,value)的形式传给这个方法 @JsonCreator:上篇文章自定义构造方法介绍过了 @JsonSetter:是@JsonProperty的替代注解 @JsonEnumDefaultValue:反序列化时，如果遇到未定义的枚举值时，赋值为默认枚举 @JsonAnySetter简单解释: 12345678910111213141516171819202122232425262728293031public class JsonAnySetterTest &#123; public static void main(String[] args) throws IOException &#123; String json = "&#123;\"username\":\"dubby.cn\",\"password\":\"123456\",\"x-key\":\"xxx-value\",\"y-key\":\"yyy-value\"&#125;"; ObjectMapper objectMapper = new ObjectMapper(); Data data = objectMapper.readValue(json, Data.class); System.out.println(data); &#125;&#125;class Data &#123; public String username; public String password; public String other; @JsonAnySetter public void anySetter(String a, String b) &#123; if (other == null) &#123; other = ""; &#125; other += a; other += ","; other += b; other += ";"; &#125; @Override public String toString() &#123; return "Data&#123;" + "username='" + username + '\'' + ", password='" + password + '\'' + ", other='" + other + '\'' + '&#125;'; &#125;&#125; 输出: 1Data&#123;username='dubby.cn', password='123456', other='x-key,xxx-value;y-key,yyy-value;'&#125; @JsonEnumDefaultValue简单解释: 123456789101112131415161718192021public class EnumTest &#123; public static void main(String[] args) throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); objectMapper.configure(DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_USING_DEFAULT_VALUE, true); String json = "&#123;\"myEnum\":\"V4\"&#125;"; EnumData enumData = objectMapper.readValue(json, EnumData.class); System.out.println(enumData); &#125;&#125;class EnumData &#123; public MyEnum myEnum; @Override public String toString() &#123; return "EnumData&#123;" + "myEnum=" + myEnum + '&#125;'; &#125;&#125;enum MyEnum &#123; V1, V2, V3, @JsonEnumDefaultValue Default;&#125; 输出: 1EnumData&#123;myEnum=Default&#125; 序列化细节 @JsonAnyGetter:修饰一个方法，返回Map，这个方法的返回值会被序列化成(key,value)形式 @JsonGetter:@JsonPropert的替代注解 @JsonPropertyOrder:注定序列化的顺序 @JsonRawValue:被修饰的字段“准确”的显示出来，没有转义或装饰，双引号都不加 @JsonValue:指定序列化输出的值 @JsonRootName:使用这个指定的值作为JSON的根，前提是SerializationFeature.WRAP_ROOT_VALUE已经打开了 @JsonAnyGetter简单解释: 12345678910111213141516171819public class JsonAnyGetterTest &#123; public static void main(String[] args) throws JsonProcessingException &#123; ObjectMapper objectMapper = new ObjectMapper(); AnyGetterData data = new AnyGetterData(); data.data = "http://dubby.cn"; System.out.println(objectMapper.writeValueAsString(data)); &#125;&#125;class AnyGetterData &#123; public String data; @JsonAnyGetter public Map other() &#123; Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put("key1", "value1"); map.put("key2", "value2"); map.put("key3", "value3"); return map; &#125;&#125; 输出: 1&#123;"data":"http://dubby.cn","key1":"value1","key2":"value2","key3":"value3"&#125; @JsonPropertyOrder简单解释: 12345678910111213141516public class JsonPropertyOrderTest &#123; public static void main(String[] args) throws JsonProcessingException &#123; ObjectMapper objectMapper = new ObjectMapper(); JsonPropertyOrderData data = new JsonPropertyOrderData(); data.name1 = "value1"; data.name2 = "value3"; data.name3 = "value4"; System.out.println(objectMapper.writeValueAsString(data)); &#125;&#125;@JsonPropertyOrder(value = &#123;"name2", "name3", "name1"&#125;)class JsonPropertyOrderData &#123; public String name1; public String name2; public String name3;&#125; 输出: 1&#123;"name2":"value3","name3":"value4","name1":"value1"&#125; @JsonValue简单解释: 1234567891011121314151617181920212223242526public class JsonValueTest &#123; public static void main(String[] args) throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); String json ="&#123;\"name2\":\"value3\",\"name3\":\"value4\",\"name1\":\"value1\"&#125;"; JsonValueData data = objectMapper.readValue(json, JsonValueData.class); System.out.println(data.toString()); System.out.println(objectMapper.writeValueAsString(data)); &#125;&#125;class JsonValueData &#123; public String name1; public String name2; public String name3; @JsonValue public String other() &#123; return name1+name2+name3; &#125; @Override public String toString() &#123; return "JsonValueData&#123;" + "name1='" + name1 + '\'' + ", name2='" + name2 + '\'' + ", name3='" + name3 + '\'' + '&#125;'; &#125;&#125; 输出: 1JsonValueData&#123;name1='value1', name2='value3', name3='value4'&#125;"value1value3value4" @JsonRootName简单解释: 1234567891011121314151617public class JsonRootNameTest &#123; public static void main(String[] args) throws JsonProcessingException &#123; ObjectMapper objectMapper = new ObjectMapper(); objectMapper.configure(SerializationFeature.WRAP_ROOT_VALUE, true); RootData data = new RootData(); data.name1 = "value1"; data.name2 = "value2"; data.name3 = "value3"; System.out.println(objectMapper.writeValueAsString(data)); &#125;&#125;@JsonRootName(value = "root")class RootData &#123; public String name1; public String name2; public String name3;&#125; 输出: 1&#123;"root":&#123;"name1":"value1","name2":"value2","name3":"value3"&#125;&#125;]]></content>
      <categories>
        <category>开发工具框架</category>
      </categories>
      <tags>
        <tag>开发工具框架</tag>
        <tag>Jackson</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac多Git账号配置]]></title>
    <url>%2F2018%2F11%2F26%2FMac%E9%85%8D%E7%BD%AE%E5%A4%9A%E4%B8%AAGit%E8%B4%A6%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[准备两个Git账号，如Github账号和Gitee账号在用户家目录下新建.ssh目录，进入目录后新建config文件使用ssh-keygen -t rsa -C “xxxxx@xxxxx.com“，生成ssh key 单个git账号配置时，不需要指定publicKey文件名，但是多个git账号配置，就需要指定文件名 12Generating public/private rsa key pair.Enter file in which to save the key (/Users/chenmin/.ssh/id_rsa): id_rsa_github 其他配置项继续回车即可 12Generating public/private rsa key pair.Enter file in which to save the key (/Users/chenmin/.ssh/id_rsa): id_rsa_gitee 此时会在.ssh目录下看到四个文件，id_rsa_github、id_rsa_github.pub和id_rsa_gitee、id_rsa_gitee.pub 将id_rsa_gitee.pub的公钥配置到gitee上的ssh公钥配置在设置 —&gt; 安全设置 —&gt; SSH公钥，然后将id_rsa_gitee.pub中的内容复制到公钥处，点击确定即可。 github类似。 在config文件中配置pub文件 1234Host userHostName https://github.comUser userIdentityFile ~/.ssh/id_rsa_github 注： HostName是服务器的地址，User是用户名，PreferredAuthentications照抄即可，这里主要说的是IdentityFile 配置测试 1ssh -T git@gitee.com 显示 Welcome to Gitee.com, yourname! 时则表示配置成功 若报错或不是这个结果，可使用 1ssh -vT git@gihub.com 查看错误信息，并使用下面的命令解决 12ssh-agent bashssh-add ~/.ssh/id_rsa]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Storm集群搭建]]></title>
    <url>%2F2018%2F08%2F07%2FStorm%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[近来公司项目步入大数据的范畴，需要Spark、Storm方面的知识储备。在学习了Scala之后，进入正式的开发准备工作，接下来对Storm集群的搭建略作介绍。 Storm集群搭建方式，可参考Storm官方文档搭建。 基本配置详解 配置项 配置说明 storm.zookeeper.servers ZooKeeper服务器列表 storm.zookeeper.port ZooKeeper连接端口 storm.local.dir storm使用的本地文件系统目录(必须存在并且storm进程可读写) storm.cluster.mode Storm集群运行模式([distributed\ local]) storm.local.mode.zmq Local模式下是否使用ZeroMQ作消息系统，如果设置为false则使用java消息系统。默认为false storm.zookeeper.root ZooKeeper中Storm的根目录位置 storm.zookeeper.session.timeout 客户端连接ZooKeeper超时时间 storm.id 运行中拓扑的id,由storm name和一个唯一随机数组成。 nimbus.host nimbus服务器地址 nimbus.thrift.port nimbus的thrift监听端口 nimbus.childopts 通过storm-deploy项目部署时指定给nimbus进程的jvm选项 nimbus.task.timeout.secs 心跳超时时间，超时后nimbus会认为task死掉并重分配给另一个地址。 nimbus.monitor.freq.secs nimbus检查心跳和重分配任务的时间间隔.注意如果是机器宕掉nimbus会立即接管并处理。 nimbus.supervisor.timeout.secs supervisor的心跳超时时间,一旦超过nimbus会认为该supervisor已死并停止为它分发新任务. nimbus.task.launch.secs task启动时的一个特殊超时设置.在启动后第一次心跳前会使用该值来临时替代nimbus.task.timeout.secs. nimbus.reassign 当发现task失败时nimbus是否重新分配执行。默认为真，不建议修改。 nimbus.file.copy.expiration.secs nimbus判断上传/下载链接的超时时间，当空闲时间超过该设定时nimbus会认为链接死掉并主动断开 ui.port Storm UI的服务端口 drpc.servers DRPC服务器列表，以便DRPCSpout知道和谁通讯 drpc.port Storm DRPC的服务端口 supervisor.slots.ports supervisor上能够运行workers的端口列表.每个worker占用一个端口,且每个端口只运行一个worker.通过这项配置可以调整每台机器上运行的worker数.(调整slot数/每机) supervisor.childopts 在storm-deploy项目中使用,用来配置supervisor守护进程的jvm选项 supervisor.worker.timeout.secs supervisor中的worker心跳超时时间,一旦超时supervisor会尝试重启worker进程. supervisor.worker.start.timeout.secs supervisor初始启动时，worker的心跳超时时间，当超过该时间supervisor会尝试重启worker。因为JVM初始启动和配置会带来的额外消耗，从而使得第一次心跳会超过supervisor.worker.timeout.secs的设定 supervisor.enable supervisor是否应当运行分配给他的workers.默认为true,该选项用来进行Storm的单元测试,一般不应修改. supervisor.heartbeat.frequency.secs supervisor心跳发送频率(多久发送一次) supervisor.monitor.frequency.secs supervisor检查worker心跳的频率 worker.childopts supervisor启动worker时使用的jvm选项.所有的”%ID%”字串会被替换为对应worker的标识符 worker.heartbeat.frequency.secs worker的心跳发送时间间隔 task.heartbeat.frequency.secs task汇报状态心跳时间间隔 task.refresh.poll.secs task与其他tasks之间链接同步的频率.(如果task被重分配,其他tasks向它发送消息需要刷新连接).一般来讲，重分配发生时其他tasks会理解得到通知。该配置仅仅为了防止未通知的情况。 topology.debug 如果设置成true，Storm将记录发射的每条信息。 topology.optimize master是否在合适时机通过在单个线程内运行多个task以达到优化topologies的目的. topology.workers 执行该topology集群中应当启动的进程数量.每个进程内部将以线程方式执行一定数目的tasks.topology的组件结合该参数和并行度提示来优化性能 topology.ackers topology中启动的acker任务数.Acker保存由spout发送的tuples的记录，并探测tuple何时被完全处理.当Acker探测到tuple被处理完毕时会向spout发送确认信息.通常应当根据topology的吞吐量来确定acker的数目，但一般不需要太多.当设置为0时,相当于禁用了消息可靠性,storm会在spout发送tuples后立即进行确认. topology.message.timeout.secs topology中spout发送消息的最大处理超时时间.如果一条消息在该时间窗口内未被成功ack,Storm会告知spout这条消息失败。而部分spout实现了失败消息重播功能。 topology.kryo.register 注册到Kryo(Storm底层的序列化框架)的序列化方案列表.序列化方案可以是一个类名,或者是com.esotericsoftware.kryo.Serializer的实现. topology.skip.missing.kryo.registrations Storm是否应该跳过它不能识别的kryo序列化方案.如果设置为否task可能会装载失败或者在运行时抛出错误. topology.max.task.parallelism 在一个topology中能够允许的最大组件并行度.该项配置主要用在本地模式中测试线程数限制. topology.max.spout.pending 一个spout task中处于pending状态的最大的tuples数量.该配置应用于单个task,而不是整个spouts或topology. topology.state.synchronization.timeout.secs 组件同步状态源的最大超时时间(保留选项,暂未使用) topology.stats.sample.rate 用来产生task统计信息的tuples抽样百分比 topology.fall.back.on.java.serialization topology中是否使用java的序列化方案 zmq.threads 每个worker进程内zeromq通讯用到的线程数 zmq.linger.millis 当连接关闭时,链接尝试重新发送消息到目标主机的持续时长.这是一个不常用的高级选项,基本上可以忽略. java.library.path JVM启动(如Nimbus,Supervisor和workers)时的java.library.path设置.该选项告诉JVM在哪些路径下定位本地库. 环境准备 从Storm官网下载Storm安装包，本文使用的Storm版本为1.2.2 从Zookeeper官网下载Zookeeper安装包 开始安装配置由于Zookeeper和Storm都是以Java为基础开发的，所以需要Java环境，在Linux服务器上配置Java开发环境，此处不做累述，读者请自行百度。 搭建Zookeeper集群参考 Zookeeper集群搭建博客 搭建Storm集群配置1234wget https://www.apache.org/dyn/closer.lua/storm/apache-storm-1.2.2/apache-storm-1.2.2.tar.gztar -zxvf apache-storm-1.2.2.tar.gzcd apache-storm-1.2.2/confvi storm.yaml 主要的配置项有一下几点： 配置Storm集群的Zookeeper集群主机列表 1234storm.zookeeper.servers: - "master" - "slave1" - "slave2" 如果Zookeeper集群使用的端口与默认端口不同，还需一下配置： 1storm.zookeeper.port: 2182 zookeeper集群的搭建可参考之前的zookeeper集群搭建的博客搭建。 指定Storm数据存储目录 Nimbus和Supervisor守护进程需要在本地磁盘上存储少量状态信息。需要我们手动在每台Supervisor机器上创建此目录，并授予适当的权限。 1storm.local.dir: "/home/hadoop/storm/data" 如果使用相对路径，可以相对于安装Storm的位置（STORM_HOME），或者使用默认值留空。 1$STORM_HOME/data supervisor的worker数量配置 以下配置指定supervisor的工作节点，可以运行的worker数量，每个worker占用一个端口来接收消息，最多分配5个；默认情况下每个节点可以运行4个worker，分别在6700、6701、6702、6703，此处定义几个端口，则就表示可以运行几个worker。 12345supervisor.slots.ports: - 6700 - 6701 - 6702 - 6703 此处为最基本的配置，若需其他对集群的优化配置，请查看官网Storm集群搭建教程，上面有详细的配置方式。（英语较差的童鞋，不要害怕英文文档，试着读，多读几遍，慢慢的大概意思也会了解了，有道是“书读百遍其义自见”） 启动集群 在Nimbus主机上启动nimbus 1bin/storm nimbus 2&gt;&amp;1 &amp; 在每个Storm集群节点上启动supervisor 1bin/storm supervisor 2&gt;&amp;1 &amp; 在Nimbus主机上启动Storm UI 1bin/storm ui 2&gt;&amp;1 &amp; 启动成功之后可在浏览器中，使用http://xxx.xxx.xxx.xxx:8080访问。]]></content>
      <categories>
        <category>Storm</category>
      </categories>
      <tags>
        <tag>Storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti 23张表及7大服务详解]]></title>
    <url>%2F2018%2F07%2F28%2FActiviti-23%E5%BC%A0%E8%A1%A8%E5%8F%8A7%E5%A4%A7%E6%9C%8D%E5%8A%A1%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[近来要做流程项目了，由于上大学的时候学过BPMN，现在重新入手Activiti，感觉还是比较容易的，此文先将Activiti6相关的服务接口及相关表略做记录，方便以后查看。 7大服务介绍 服务名称 描述 RepositoryService Activiti 中每一个不同版本的业务流程的定义都需要使用一些定义文件，部署文件和支持数据 ( 例如 BPMN2.0 XML 文件，表单定义文件，流程定义图像文件等 )，这些文件都存储在 Activiti 内建的 Repository 中。Repository Service 提供了对 repository 的存取服务。 RuntimeService 在 Activiti 中，每当一个流程定义被启动一次之后，都会生成一个相应的流程对象实例。Runtime Service 提供了启动流程、查询流程实例、设置获取流程实例变量等功能。此外它还提供了对流程部署，流程定义和流程实例的存取服务。 TaskService 在 Activiti 中业务流程定义中的每一个执行节点被称为一个 Task，对流程中的数据存取，状态变更等操作均需要在 Task 中完成。Task Service 提供了对用户 Task 和 Form 相关的操作。它提供了运行时任务查询、领取、完成、删除以及变量设置等功能。 IdentityService Activiti 中内置了用户以及组管理的功能，必须使用这些用户和组的信息才能获取到相应的 Task。Identity Service 提供了对 Activiti 系统中的用户和组的管理功能。 ManagementService Management Service 提供了对 Activiti 流程引擎的管理和维护功能，这些功能不在工作流驱动的应用程序中使用，主要用于 Activiti 系统的日常维护。 HistoryService History Service 用于获取正在运行或已经完成的流程实例的信息，与 Runtime Service 中获取的流程信息不同，历史信息包含已经持久化存储的永久信息，并已经被针对查询优化。 FormService Activiti 中的流程和状态 Task 均可以关联业务相关的数据。通过使用 Form Service 可以存取启动和完成任务所需的表单数据并且根据需要来渲染表单。 23张表概览Activiti使用到的表都是ACT_开头的。 ACT_RE_*: ’RE’表示repository(存储)，RepositoryService接口所操作的表。带此前缀的表包含的是静态信息，如，流程定义，流程的资源（图片，规则等）。 ACT_RU_*: ‘RU’表示runtime，运行时表-RuntimeService。这是运行时的表存储着流程变量，用户任务，变量，职责（job）等运行时的数据。Activiti只存储实例执行期间的运行时数据，当流程实例结束时，将删除这些记录。这就保证了这些运行时的表小且快。 ACT_ID_*: ’ID’表示identity (组织机构)，IdentityService接口所操作的表。用户记录，流程中使用到的用户和组。这些表包含标识的信息，如用户，用户组，等等。 ACT_HI_*: ’HI’表示history，历史数据表，HistoryService。就是这些表包含着流程执行的历史相关数据，如结束的流程实例，变量，任务，等等 ACT_GE_*: 全局通用数据及设置(general)，各种情况都使用的数据。 序号 表名 说明 1 act_ge_bytearray 二进制数据表 2 act_ge_property 属性数据表存储整个流程引擎级别的数据,初始化表结构时，会默认插入三条记录， 3 act_hi_actinst 历史节点表 4 act_hi_attachment 历史附件表 5 act_hi_comment 历史意见表 6 act_hi_identitylink 历史流程人员表 7 act_hi_detail 历史详情表，提供历史变量的查询 8 act_hi_procinst 历史流程实例表 9 act_hi_taskinst 历史任务实例表 10 act_hi_varinst 历史变量表 11 act_id_group 用户组信息表 12 act_id_info 用户扩展信息表 13 act_id_membership 用户与用户组对应信息表 14 act_id_user 用户信息表 15 act_re_deployment 部署信息表 16 act_re_model 流程设计模型部署表 17 act_re_procdef 流程定义数据表 18 act_ru_event_subscr throwEvent、catchEvent时间监听信息表 19 act_ru_execution 运行时流程执行实例表 20 act_ru_identitylink 运行时流程人员表，主要存储任务节点与参与者的相关信息 21 act_ru_job 运行时定时任务数据表 22 act_ru_task 运行时任务节点表 23 act_ru_variable 运行时流程变量数据表 23张表详解二进制数据表（act_ge_bytearray）保存流程定义图片和xml、Serializable(序列化)的变量,即保存所有二进制数据，特别注意类路径部署时候，不要把svn等隐藏文件或者其他与流程无关的文件也一起部署到该表中，会造成一些错误（可能导致流程定义无法删除） 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) Y 主键ID REV_ 乐观锁 int Y Version(版本) NAME_ 名称 nvarchar(255) Y 部署的文件名称，如：leave.bpmn.png,leave.bpmn20.xml DEPLOYMENT_ID_ 部署ID nvarchar(64) Y 部署表ID BYTES_ 字节 varbinary(max) Y 部署文件 GENERATED_ 是否是引擎生成 tinyint Y 0为用户生成，1为activiti生成 属性数据表(act_ge_property)属性数据表。存储整个流程引擎级别的数据。 字段名称 字段描述 数据类型 主键 为空 取值说明 NAME_ 名称 nvarchar(64) √ schema.versionschema.historynext.dbid VALUE_ 值 nvarchar(300) √ 5.create(5.) REV_ 乐观锁 int √ version 历史节点表（act_hi_actinst）历史活动信息。这里记录流程流转过的所有节点，与HI_TASKINST不同的是，taskinst只记录usertask内容 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ PROC_DEF_ID_ 流程定义ID nvarchar(64) PROC_INST_ID_ 流程实例ID nvarchar(64) EXECUTION_ID_ 执行实例ID nvarchar(64) ACT_ID_ 节点ID nvarchar(225) 节点定义ID TASK_ID_ 任务实例ID nvarchar(64) √ 任务实例ID 其他节点类型实例ID在这里为空 CALL_PROC_INST_ID_ 调用外部的流程实例ID nvarchar(64) √ 调用外部流程的流程实例ID’ ACT_NAME_ 节点名称 nvarchar(225) √ 节点定义名称 ACT_TYPE_ 节点类型 nvarchar(225) 如startEvent、userTask ASSIGNEE_ 签收人 nvarchar(64) √ 节点签收人 START_TIME_ 开始时间 datetime 2013-09-15 11:30:00 END_TIME_ 结束时间 datetime √ 2013-09-15 11:30:00 DURATION_ 耗时 numeric(19,0) √ 毫秒值 历史附件表( act_hi_attachment ) 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ 主键ID REV_ 乐观锁 integer √ Version USER_ID_ 用户ID nvarchar(255) √ 用户ID NAME_ 名称 nvarchar(255) √ 附件名称 DESCRIPTION_ 描述 nvarchar(4000) √ 描述 TYPE_ 类型 nvarchar(255) √ 附件类型 TASK_ID_ 任务实例ID nvarchar(64) √ 节点实例ID PROC_INST_ID_ 流程实例ID nvarchar(64) √ 流程实例ID URL_ URL_ nvarchar(4000) √ 附件地址 CONTENT_ID_ 字节表的ID nvarchar(64) √ ACT_GE_BYTEARRAY的ID 历史意见表( act_hi_comment ) 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ 主键ID TYPE_ 类型 nvarchar(255) √ 类型：event（事件）comment（意见） TIME_ 时间 datetime 填写时间’ USER_ID_ 用户ID nvarchar(64) √ 填写人 TASK_ID_ 节点任务ID nvarchar(64) √ 节点实例ID PROC_INST_ID_ 流程实例ID nvarchar(255) √ 流程实例ID ACTION_ 行为类型 nvarchar(64) √ 见备注1 MESSAGE_ 基本内容 nvarchar(4000) √ 用于存放流程产生的信息，比如审批意见 FULL_MSG_ 全部内容 varbinary(max) √ 附件地址 历史详情表( act_hi_detail )流程中产生的变量详细，包括控制流程流转的变量，业务表单中填写的流程需要用到的变量等。 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ 主键 TYPE_ 类型 nvarchar(255) 见备注2 PROC_INST_ID_ 流程实例ID nvarchar(64) √ 流程实例ID EXECUTION_ID_ 执行实例ID nvarchar(64) √ 执行实例ID TASK_ID_ 任务实例ID nvarchar(64) √ 任务实例ID ACT_INST_ID_ 节点实例ID nvarchar(64) √ ACT_HI_ACTINST表的ID NAME_ 名称 nvarchar(255) 名称 VAR_TYPE_ 参数类型 nvarchar(255) √ 见备注3 REV_ 乐观锁 int √ Version TIME_ 时间戳 datetime 创建时间 BYTEARRAY_ID_ 字节表ID nvarchar √ ACT_GE_BYTEARRAY表的ID DOUBLE_ DOUBLE_ double precision √ 存储变量类型为Double LONG_ LONG_ numeric √ 存储变量类型为long TEXT_ TEXT_ nvarchar √ 存储变量值类型为String TEXT2_ TEXT2_ nvarchar √ 此处存储的是JPA持久化对象时，才会有值。此值为对象ID 历史流程人员表( act_ru_identitylink )任务参与者数据表。主要存储历史节点参与者的信息 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ ID_ GROUP_ID_ 组ID nvarchar(255) √ 组ID TYPE_ 类型 nvarchar(255) √ 备注4 USER_ID_ 用户ID nvarchar(255) √ 用户ID TASK_ID_ 节点实例ID nvarchar(64) √ 节点实例ID PROC_INST_ID_ 流程实例ID nvarchar(64) √ 流程实例ID 历史流程实例表（act_hi_procinst） 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ 主键ID PROC_INST_ID_ 流程实例ID nvarchar(64) 流程实例ID BUSINESS_KEY_ 业务主键 nvarchar(255) √ 业务主键，业务表单的ID PROC_DEF_ID_ 流程定义ID nvarchar(64) 流程定义ID START_TIME_ 开始时间 datetime 开始时间 END_TIME_ 结束时间 datetime √ 结束时间 DURATION_ 耗时 Numeric(19) √ 耗时 START_USER_ID_ 起草人 nvarchar(255) √ 起草人 START_ACT_ID_ 开始节点ID nvarchar(255) √ 起草环节ID END_ACT_ID_ 结束节点ID nvarchar(255) √ 结束环节ID SUPER_PROCESS_INSTANCE_ID_ 父流程实例ID nvarchar(64) √ 父流程实例ID DELETE_REASON_ 删除原因 nvarchar(4000) √ 删除原因 历史任务实例表( act_hi_taskinst ) 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ 主键ID PROC_DEF_ID_ 流程定义ID nvarchar(64) √ 流程定义ID TASK_DEF_KEY_ 节点定义ID nvarchar(255) √ 节点定义ID PROC_INST_ID_ 流程实例ID nvarchar(64) √ 流程实例ID EXECUTION_ID_ 执行实例ID nvarchar(64) √ 执行实例ID NAME_ 名称 varchar(255) √ 名称 PARENT_TASK_ID_ 父节点实例ID nvarchar(64) √ 父节点实例ID DESCRIPTION_ 描述 nvarchar(400) √ 描述 OWNER_ 实际签收人 任务的拥有者 nvarchar(255) √ 签收人（默认为空，只有在委托时才有值） ASSIGNEE_ 签收人或被委托 nvarchar(255) √ 签收人或被委托 START_TIME_ 开始时间 datetime 开始时间 CLAIM_TIME_ 提醒时间 datetime √ 提醒时间 END_TIME_ 结束时间 datetime √ 结束时间 DURATION_ 耗时 numeric(19) √ 耗时 DELETE_REASON_ 删除原因 nvarchar(4000) √ 删除原因(completed,deleted) PRIORITY_ 优先级别 int √ 优先级别 DUE_DATE_ 过期时间 datetime √ 过期时间，表明任务应在多长时间内完成 FORM_KEY_ 节点定义的formkey nvarchar(255) √ desinger节点定义的form_key属性 历史变量表( act_hi_varinst ) 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ ID_ PROC_INST_ID_ 流程实例ID nvarchar(64) √ 流程实例ID EXECUTION_ID_ 执行实例ID nvarchar(255) √ 执行实例ID TASK_ID_ 任务实例ID nvarchar(64) √ 任务实例ID NAME_ 名称 nvarchar(64) 参数名称(英文) VAR_TYPE_ 参数类型 varchar(255) √ 备注5 REV_ 乐观锁 nvarchar(64) √ 乐观锁 Version BYTEARRAY_ID_ 字节表ID nvarchar(400) √ ACT_GE_BYTEARRAY表的主键 DOUBLE_ DOUBLE_ nvarchar(255) √ 存储DoubleType类型的数据 LONG_ LONG_ nvarchar(255) √ 存储LongType类型的数据 TEXT_ TEXT_ datetime √ 备注6 TEXT2_ TEXT2_ datetime √ 此处存储的是JPA持久化对象时，才会有值。此值为对象ID 用户组信息表( act_id_group ) 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ 主键ID REV_ 乐观锁 int √ 乐观锁Version NAME_ 名称 nvarchar(255) √ 组名称 TYPE_ 类型 nvarchar(255) √ 类型 用户扩展信息表( act_id_info ) 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ 主键ID REV_ 乐观锁 int √ 乐观锁Version USER_ID_ 用户ID nvarchar(64) √ TYPE_ 类型 nvarchar(64) √ KEY_ nvarchar(255) √ VALUE_ nvarchar(255) √ PASSWORD_ Image √ PARENT_ID_ nvarchar(255) √ 用户与分组对应信息表( act_id_membership )用来保存用户的分组信息。 字段名称 字段描述 数据类型 主键 为空 取值说明 USER_ID 用户ID nvarchar(64) √ GROUP_ID 用户组ID nvarchar(64) √ 用户信息表( act_id_user ) 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ 主键ID REV_ 乐观锁 int √ 乐观锁Version FIRST_ 姓 nvarchar(255) √ LAST_ 名 nvarchar(255) √ EMAIL_ EMAIL_ nvarchar(255) √ PWD_ 密码 nvarchar(255) √ PICTURE_ID_ 图片ID nvarchar(64) √ 部署信息表( act_re_deployment )部署流程定义时需要被持久化保存下来的信息。 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ 主键ID NAME_ 部署名称 nvarchar(255) √ 部署文件名 CATEGORY_ 分类 nvarchar(255) √ 类别 DEPLOY_TIME_ 部署时间 datetime √ 部署时间 流程设计模型部署表( act_re_model )流程设计器设计流程后，保存数据到该表。 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ ID_ REV_ 乐观锁 int √ 乐观锁 NAME_ 名称 nvarchar(255) √ 名称 KEY_ KEY_ nvarchar(255) √ 分类，例如：http://www.mossle.com/docs/activiti/ CATEGORY_ 分类 nvarchar(255) √ 分类 CREATE_TIME_ 创建时间 datetime √ 创建时间 LAST_UPDATE_TIME_ 最新修改时间 datetime √ 最新修改时间 VERSION_ 版本 int √ 版本 META_INFO_ META_INFO_ nvarchar(255) √ 以json格式保存流程定义的信息 DEPLOYMENT_ID_ 部署ID nvarchar(255) √ 部署ID EDITOR_SOURCE_VALUE_ID_ datetime √ EDITOR_SOURCE_EXTRA_VALUE_ID_ datetime √ 流程定义数据表( act_re_procdef )业务流程定义数据表。此表和ACT_RE_DEPLOYMENT是多对一的关系，即，一个部署的bar包里可能包含多个流程定义文件，每个流程定义文件都会有一条记录在ACT_REPROCDEF表内，每个流程定义的数据，都会对于ACT_GE_BYTEARRAY表内的一个资源文件和PNG图片文件。和ACT_GE_BYTEARRAY的关联是通过程序用ACT_GE_BYTEARRAY.NAME与ACT_RE_PROCDEF.NAME_完成的，在数据库表结构中没有体现。 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ ID_ REV_ 乐观锁 int √ 乐观锁 CATEGORY_ 分类 nvarchar(255) √ 流程定义的Namespace就是类别 NAME_ 名称 nvarchar(255) √ 名称 KEY_ 定义的KEY nvarchar(255) 流程定义ID VERSION_ 版本 int 版本 DEPLOYMENT_ID_ 部署表ID nvarchar(64) √ 部署表ID RESOURCE_NAME_ bpmn文件名称 nvarchar(4000) √ 流程bpmn文件名称 DGRM_RESOURCE_NAME_ png图片名称 nvarchar(4000) √ 流程图片名称 DESCRIPTION_ 描述 nvarchar(4000) √ 描述 HAS_START_FORM_KEY_ 是否存在开始节点formKey tinyint √ start节点是否存在formKey 0否 1是 SUSPENSION_STATE_ 是否挂起 tinyint √ 1 激活 2挂起 act_ru_event_subscr 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ 事件ID nvarchar(64) √ 事件ID REV_ 版本 int √ 乐观锁Version EVENT_TYPE_ 事件类型 nvarchar(255) 事件类型 EVENT_NAME_ 事件名称 nvarchar(255) √ 事件名称 EXECUTION_ID_ 执行实例ID nvarchar(64) √ 执行实例ID PROC_INST_ID_ 流程实例ID nvarchar(64) √ 流程实例ID ACTIVITY_ID_ 活动实例ID nvarchar(64) √ 活动实例ID CONFIGURATION_ 配置 nvarchar(255) √ 配置 CREATED_ 是否创建 datetime 默认值 当前系统时间戳CURRENT_TIMESTAMP 运行时流程执行实例表( act_ru_execution ) 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ ID_ REV_ 乐观锁 int √ 乐观锁 PROC_INST_ID_ 流程实例ID nvarchar(64) 流程实例ID BUSINESS_KEY_ 业务主键ID nvarchar(255) √ 业务主键ID PARENT_ID_ 父节点实例ID nvarchar(64) √ 父节点实例ID PROC_DEF_ID_ 流程定义ID nvarchar(64) √ 流程定义ID SUPER_EXEC_ SUPER_EXEC_ nvarchar(64) √ SUPER_EXEC_ ACT_ID_ 节点实例ID nvarchar(255) √ 节点实例ID即ACT_HI_ACTINST中ID IS_ACTIVE_ 是否存活 tinyint √ 是否存活 IS_CONCURRENT_ 是否并行 tinyint √ 是否为并行(true/false） IS_SCOPE_ IS_SCOPE_ tinyint √ IS_SCOPE_ IS_EVENT_SCOPE_ IS_EVENT_SCOPE_ tinyint √ IS_EVENT_SCOPE_ SUSPENSION_STATE_ 是否挂起 tinyint √ 挂起状态 1激活 2挂起 CACHED_ENT_STATE_ int √ 运行时流程人员表( act_ru_identitylink )任务参与者数据表。主要存储当前节点参与者的信息。 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ ID_ REV_ 乐观锁 int √ 乐观锁 GROUP_ID_ 组ID nvarchar(64) √ 组ID TYPE_ 类型 nvarchar(255) √ 备注7 USER_ID_ 用户ID nvarchar(64) √ 用户ID TASK_ID_ 节点实例ID nvarchar(64) √ 节点实例ID PROC_INST_ID_ 流程实例ID nvarchar(64) √ 流程实例ID PROC_DEF_ID_ 流程定义ID nvarchar(255) √ 流程定义ID 运行时定时任务数据表( act_ru_job ) 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ 标识 nvarchar(64) √ 标识 REV_ 版本 int √ 版本 TYPE_ 类型 nvarchar(255) 类型 LOCK_EXP_TIME_ 锁定释放时间 datetime √ 锁定释放时间 LOCK_OWNER_ 挂起者 nvarchar(255) √ 挂起者 EXCLUSIVE_ bit √ EXECUTION_ID_ 执行实例ID nvarchar(64) √ 执行实例ID PROCESS_INSTANCE_ID_ 流程实例ID nvarchar(64) √ 流程实例ID PROC_DEF_ID_ 流程定义ID nvarchar(64) √ 流程定义ID RETRIES_ int √ EXCEPTION_STACK_ID_ 异常信息ID nvarchar(64) √ 异常信息ID EXCEPTION_MSG_ 异常信息 nvarchar(4000) √ 异常信息 DUEDATE_ 到期时间 datetime √ 到期时间 REPEAT_ 重复 nvarchar(255) √ 重复 HANDLER_TYPE_ 处理类型 nvarchar(255) √ 处理类型 HANDLER_CFG_ nvarchar(4000) √ 标识 运行时任务节点表( act_ru_task ) 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ ID_ REV_ 乐观锁 int √ 乐观锁 EXECUTION_ID_ 执行实例ID nvarchar(64) √ 执行实例ID PROC_INST_ID_ 流程实例ID nvarchar(64) √ 流程实例ID PROC_DEF_ID_ 流程定义ID nvarchar(64) √ 流程定义ID NAME_ 节点定义名称 nvarchar(255) √ 节点定义名称 PARENT_TASK_ID_ 父节点实例ID nvarchar(64) √ 父节点实例ID DESCRIPTION_ 节点定义描述 nvarchar(4000) √ 节点定义描述 TASK_DEF_KEY_ 节点定义的KEY nvarchar(255) √ 任务定义的ID OWNER_ 实际签收人 nvarchar(255) √ 拥有者（一般情况下为空，只有在委托时才有值） ASSIGNEE_ 签收人或委托人 nvarchar(255) √ 签收人或委托人 DELEGATION_ 委托类型 nvarchar(64) √ 备注8 PRIORITY_ 优先级别 int √ 优先级别，默认为：50 CREATE_TIME_ 创建时间 datetime √ 创建时间 DUE_DATE_ 过期时间 datetime √ 耗时 SUSPENSION_STATE_ 是否挂起 int √ 1代表激活 2代表挂起 运行时流程变量数据表( act_ru_variable ) 字段名称 字段描述 数据类型 主键 为空 取值说明 ID_ ID_ nvarchar(64) √ 主键标识 REV_ 乐观锁 int √ 乐观锁 TYPE_ 类型 nvarchar(255) 备注9 NAME_ 名称 nvarchar(255) 变量名称 EXECUTION_ID_ 执行实例ID nvarchar(64) √ 执行的ID PROC_INST_ID_ 流程实例ID nvarchar(64) √ 流程实例ID TASK_ID_ 节点实例ID nvarchar(64) √ 节点实例ID(Local） BYTEARRAY_ID_ 字节表ID nvarchar(64) √ 字节表的ID（ACT_GE_BYTEARRAY） DOUBLE_ DOUBLE_ float √ 存储变量类型为Double LONG_ LONG_ numeric(19) √ 存储变量类型为long TEXT_ TEXT_ nvarchar(4000) √ ‘存储变量值类型为String 如此处存储持久化对象时，值jpa对象的class TEXT2_ TEXT2_ nvarchar(4000) √ 此处存储的是JPA持久化对象时，才会有值。此值为对象ID]]></content>
      <categories>
        <category>工作流</category>
      </categories>
      <tags>
        <tag>工作流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat源码分析之启动流程分析]]></title>
    <url>%2F2018%2F03%2F21%2FTomcat%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前面的博客介绍了Tomcat的整个架构及各个配置文件及目录的作用，接下来就对Tomcat的源码进行分析了。 Tomcat源码调试环境准备首先下载Tomcat源码，读者可自行去Tomcat官网 下载，若执行力差的同学也可直接从此处pull。 Tomcat源码导入到开发工具中的方法有多种，笔者采用最直接的方式，解压源码包后直接导入到开发工具中，导入之后的源码并不能直接运行，还需要几个依赖包，读者可从此处的lib目录下获取，也可自行搜集。 找好依赖包也并不能让Tomcat源码正常运行，还需要为Bootstrap这个启动类增加几个启动参数。 123456-Dcatalina.home=/Users/chenmin/GitHub/tomcat-Dcatalina.base=/Users/chenmin/GitHub/tomcat-Djava.endorsed.dirs=/Users/chenmin/GitHub/tomcat/endorsed-Djava.io.tmpdir=/Users/chenmin/GitHub/tomcat/temp-Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager-Djava.util.logging.config.file=/Users/chenmin/GitHub/tomcat/conf/logging.properties 上面的参数具体代表的意思就不一一详述了，其实光看名字就知道都是干嘛用的了。 以上准备步骤做好之后，就可以直接运行Bootstrap类，运行Tomcat源码进行调试了。 Tomcat Server的组成整体说明在上面对配置文件的说明中，通过server.xml的解释，我们知道server.xml中最顶级的元素是server，而server.xml中的每一个元素我们都可以把它看做是Tomcat中的某一个部分。所以我们可以参照着server.xml来分析源码。 Tomcat最顶层的容器叫Server，它代表着整个Tomcat服务器。Server中至少要包含一个Service来提供服务。Service包含两部分：Connector和Container。Connector负责网络连接，request/response的创建，并对Socket和request、response进行转换等，Container用于封装和管理Servlet，并处理具体的request请求。 一个Tomcat中只有一个Server，一个Server可以有多个Service来提供服务，一个Service只有一个Container，但是可以有多个Connector（一个服务可以有多个连接）。 各组件详解可结合conf/配置文件说明中的server.xml的说明来看 Server Server代表整个Servlet容器 Service Service是由一个或多个Connector以及一个Engine，负责处理所有Connector所获得的客户请求的集合。 Connector Connector将在某个指定端口上侦听客户请求，并将获得的请求交给Engine来处理，从Engine处获得回应并返回给客户端。 Tomcat有两个默认的Connector，一个直接监听来自浏览器的http请求，一个监听来自其他WebServer的请求。 Coyote Http/1.1 Connector在端口8080上监听来自浏览器的http请求 Coyote AJP/1.3 Connector在端口8009上监听来自其他WebServer的servlet/jsp代理请求。 Engine Engine下可以配置多个虚拟主机，每个虚拟主机都有一个域名，当Engine获得一个请求时，Engine会把该请求匹配到某个Host上，然后把该请求交给该Host来处理。 Engine有一个默认虚拟主机，当请求无法匹配到任何一个Host上的时候，将交给该默认Host来处理。 Host 代表一个虚拟主机，每个虚拟主机和某个网络域名相匹配。每个虚拟主机下都可以部署一个或者多个WebApp，每个WebApp对应于一个Context，有一个ContextPath。当Host获得一个请求时，将把该请求匹配到某个Context上，然后把该请求交给该Context来处理。匹配的方法是“最长匹配”，所以一个path==“”的Context将成为该Host的默认Context，所有无法和其他Context的路径名匹配的请求都将最终和该默认Context匹配。 Context 一个Context对应于一个Web Application（Web应用），一个Web应用有一个或多个Servlet组成，Context在创建的时候将根据配置文件\$CATALINA_HOME/conf/web.xml和\$WEBAPP_HOME/WEB-INF/web.xml载入Servlet类。如果找到，则执行该类，获得请求的回应，并返回。 Tomcat各组件关系图(此图来此网上) 源码分析启动总体流程Tomcat里的Server由org.apache.catalina.startup.Catalina来管理，Catalina是整个Tomcat的管理类，它里面的三个方法load，start，stop分别用来管理整个服务器的生命周期，load方法用于根据conf/server.xml文件创建Server并调用Server的init方法进行初始化，start方法用于启动服务器，stop方法用于停止服务器，start和stop方法在内部分别调用了Server的start和stop方法，load方法内部调用了Server的init方法，这三个方法都会按容器的结构逐层调用相应的方法，比如，Server的start方法中会调用所有的Service中的start方法，Service中的start方法又会调用所有的Service中的start方法，Service中的start方法又会调用所有包含的Connectors和Container的start方法，这样这个服务器就启动了，init和stop方法也一样，这就是整个Tomcat的生命周期的管理方式。Catalina还有个await方法，await方法直接调用了Server的await方法，这个方法的作用是进入一个循环，让主线程不退出。 Tomcat的启动入口上面说过，是org.apache.catalina.startup.Bootstrap，作用类似于一个CatalinaAdaptor，具体的处理过程还是使用Catalina来完成的，这么做的好处是可以把启动的入口和具体的管理类分开，从而可以很方便的创建出多种启动方式，每种启动方式只需要写一个相应的CatalinaAdaptor就可以了。 注：图片比较模糊，如需查看清晰图片，请自行下载resources/images目录中的tomcat启动流程分析.png 或 resources/docs中的Tomcat源码分析.mdl ，使用Rational Rose等工具打开即可。 启动流程详解正常情况下启动Tomcat，就是调用Bootstrap的main方法，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public static void main(String args[]) &#123; if (daemon == null) &#123; // Don't set daemon until init() has completed // 初始化了ClassLoader，并用ClassLoader创建了Catalina实例，赋给catalinaDaemon变量 Bootstrap bootstrap = new Bootstrap(); try &#123; bootstrap.init(); &#125; catch (Throwable t) &#123; handleThrowable(t); t.printStackTrace(); return; &#125; daemon = bootstrap; &#125; else &#123; // When running as a service the call to stop will be on a new // thread so make sure the correct class loader is used to prevent // a range of class not found exceptions. Thread.currentThread().setContextClassLoader(daemon.catalinaLoader); &#125; try &#123; String command = "start"; if (args.length &gt; 0) &#123; command = args[args.length - 1]; &#125; if (command.equals("startd")) &#123; args[args.length - 1] = "start"; daemon.load(args); daemon.start(); &#125; else if (command.equals("stopd")) &#123; args[args.length - 1] = "stop"; daemon.stop(); &#125; else if (command.equals("start")) &#123; daemon.setAwait(true); daemon.load(args); daemon.start(); &#125; else if (command.equals("stop")) &#123; daemon.stopServer(args); &#125; else if (command.equals("configtest")) &#123; daemon.load(args); if (null==daemon.getServer()) &#123; System.exit(1); &#125; System.exit(0); &#125; else &#123; log.warn("Bootstrap: command \"" + command + "\" does not exist."); &#125; &#125; catch (Throwable t) &#123; // Unwrap the Exception for clearer error reporting if (t instanceof InvocationTargetException &amp;&amp; t.getCause() != null) &#123; t = t.getCause(); &#125; handleThrowable(t); t.printStackTrace(); System.exit(1); &#125; &#125; main方法中，首先执行init方法初始化了Tomcat自己的类加载器，并通过类加载器创建Catalina实例，然后赋给catalinaDaemon变量，后续操作都使用catalinaDaemon来执行。 后面默认执行start命令，将调用setAwait(true)，load(args)和start()这三个方法，这三个方法内部都通过反射调用了Catalina的相应方法。 1234// org.apache.catalina.startup.Catalinapublic void setAwait(boolean b) &#123; await = b;&#125; setAwait方法用于设置Server启动完成后是否进入等待状态的标志，如果为true则进入，否则不进入。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697// org.apache.catalina.startup.Catalina/** * Start a new server instance. */public void load() &#123; long t1 = System.nanoTime(); initDirs(); // Before digester - it may be needed initNaming(); // Create and execute our Digester Digester digester = createStartDigester(); InputSource inputSource = null; InputStream inputStream = null; File file = null; try &#123; try &#123; file = configFile(); inputStream = new FileInputStream(file); inputSource = new InputSource(file.toURI().toURL().toString()); &#125; catch (Exception e) &#123; if (log.isDebugEnabled()) &#123; log.debug(sm.getString("catalina.configFail", file), e); &#125; &#125; if (inputStream == null) &#123; try &#123; inputStream = getClass().getClassLoader().getResourceAsStream(getConfigFile()); inputSource = new InputSource(getClass().getClassLoader().getResource(getConfigFile()).toString()); &#125; catch (Exception e) &#123; if (log.isDebugEnabled()) &#123; log.debug(sm.getString("catalina.configFail",getConfigFile()), e); &#125; &#125; &#125; // This should be included in catalina.jar // Alternative: don't bother with xml, just create it manually. if (inputStream == null) &#123; try &#123; inputStream = getClass().getClassLoader().getResourceAsStream("server-embed.xml"); inputSource = new InputSource(getClass().getClassLoader().getResource("server-embed.xml").toString()); &#125; catch (Exception e) &#123; if (log.isDebugEnabled()) &#123; log.debug(sm.getString("catalina.configFail","server-embed.xml"), e); &#125; &#125; &#125; if (inputStream == null || inputSource == null) &#123; if (file == null) &#123; log.warn(sm.getString("catalina.configFail",getConfigFile() + "] or [server-embed.xml]")); &#125; else &#123; log.warn(sm.getString("catalina.configFail",file.getAbsolutePath())); if (file.exists() &amp;&amp; !file.canRead()) &#123; log.warn("Permissions incorrect, read permission is not allowed on the file."); &#125; &#125; return; &#125; try &#123; inputSource.setByteStream(inputStream); digester.push(this); digester.parse(inputSource); &#125; catch (SAXParseException spe) &#123; log.warn("Catalina.start using " + getConfigFile() + ": " + spe.getMessage()); return; &#125; catch (Exception e) &#123; log.warn("Catalina.start using " + getConfigFile() + ": " , e); return; &#125; &#125; finally &#123; if (inputStream != null) &#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123; // Ignore &#125; &#125; &#125; getServer().setCatalina(this); getServer().setCatalinaHome(Bootstrap.getCatalinaHomeFile()); getServer().setCatalinaBase(Bootstrap.getCatalinaBaseFile()); // Stream redirection initStreams(); // Start the new server try &#123; getServer().init(); &#125; catch (LifecycleException e) &#123; if (Boolean.getBoolean("org.apache.catalina.startup.EXIT_ON_INIT_FAILURE")) &#123; throw new java.lang.Error(e); &#125; else &#123; log.error("Catalina.start", e); &#125; &#125; long t2 = System.nanoTime(); if(log.isInfoEnabled()) &#123; log.info("Initialization processed in " + ((t2 - t1) / 1000000) + " ms"); &#125;&#125; Catalina的load方法根据conf/server.xml创建了Server对象，并赋值给server属性（具体是通过开源项目Digester完成的），然后调用了server的init方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445// org.apache.catalina.startup.Catalinapublic void start() &#123; if (getServer() == null) &#123; load(); &#125; if (getServer() == null) &#123; log.fatal("Cannot start server. Server instance is not configured."); return; &#125; long t1 = System.nanoTime(); // Start the new server try &#123; getServer().start(); &#125; catch (LifecycleException e) &#123; log.fatal(sm.getString("catalina.serverStartFail"), e); try &#123; getServer().destroy(); &#125; catch (LifecycleException e1) &#123; log.debug("destroy() failed for failed Server ", e1); &#125; return; &#125; long t2 = System.nanoTime(); if(log.isInfoEnabled()) &#123; log.info("Server startup in " + ((t2 - t1) / 1000000) + " ms"); &#125; // Register shutdown hook if (useShutdownHook) &#123; if (shutdownHook == null) &#123; shutdownHook = new CatalinaShutdownHook(); &#125; Runtime.getRuntime().addShutdownHook(shutdownHook); // If JULI is being used, disable JULI's shutdown hook since // shutdown hooks run in parallel and log messages may be lost // if JULI's hook completes before the CatalinaShutdownHook() LogManager logManager = LogManager.getLogManager(); if (logManager instanceof ClassLoaderLogManager) &#123; ((ClassLoaderLogManager) logManager).setUseShutdownHook(false); &#125; &#125; if (await) &#123; await(); stop(); &#125;&#125; 这里首先判断Server是否已经存在了，如果不存在则调用load方法来初始化Server，然后调用Server的start方法来启动服务器，最后注册了关闭钩子并根据await属性判断是否进入等待状态，之前我们已经将这里的await属性设置为true，所以需要进入等待状态。进入等待状态会调用await和stop两个方法，await方法会直接调用Server的await方法，Server的await方法内部会执行一个while循环，这样程序就停到了await方法，当await方法里的while循环退出时，就会执行stop方法，从而关闭服务器。 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119// org.apache.catalina.core.StandardServer@Overridepublic void await() &#123; // Negative values - don't wait on port - tomcat is embedded or we just don't like ports if( port == -2 ) &#123; // undocumented yet - for embedding apps that are around, alive. return; &#125; if( port==-1 ) &#123; try &#123; awaitThread = Thread.currentThread(); while(!stopAwait) &#123; try &#123; Thread.sleep( 10000 ); &#125; catch( InterruptedException ex ) &#123; // continue and check the flag &#125; &#125; &#125; finally &#123; awaitThread = null; &#125; return; &#125; // Set up a server socket to wait on try &#123; awaitSocket = new ServerSocket(port, 1,InetAddress.getByName(address)); &#125; catch (IOException e) &#123; log.error("StandardServer.await: create[" + address+ ":" + port+ "]: ", e); return; &#125; try &#123; awaitThread = Thread.currentThread(); // Loop waiting for a connection and a valid command while (!stopAwait) &#123; ServerSocket serverSocket = awaitSocket; if (serverSocket == null) &#123; break; &#125; // Wait for the next connection Socket socket = null; StringBuilder command = new StringBuilder(); try &#123; InputStream stream; long acceptStartTime = System.currentTimeMillis(); try &#123; socket = serverSocket.accept(); socket.setSoTimeout(10 * 1000); // Ten seconds stream = socket.getInputStream(); &#125; catch (SocketTimeoutException ste) &#123; // This should never happen but bug 56684 suggests that // it does. log.warn(sm.getString("standardServer.accept.timeout", Long.valueOf(System.currentTimeMillis() - acceptStartTime)), ste); continue; &#125; catch (AccessControlException ace) &#123; log.warn("StandardServer.accept security exception: " + ace.getMessage(), ace); continue; &#125; catch (IOException e) &#123; if (stopAwait) &#123; // Wait was aborted with socket.close() break; &#125; log.error("StandardServer.await: accept: ", e); break; &#125; // Read a set of characters from the socket int expected = 1024; // Cut off to avoid DoS attack while (expected &lt; shutdown.length()) &#123; if (random == null) random = new Random(); expected += (random.nextInt() % 1024); &#125; while (expected &gt; 0) &#123; int ch = -1; try &#123; ch = stream.read(); &#125; catch (IOException e) &#123; log.warn("StandardServer.await: read: ", e); ch = -1; &#125; // Control character or EOF (-1) terminates loop if (ch &lt; 32 || ch == 127) &#123; break; &#125; command.append((char) ch); expected--; &#125; &#125; finally &#123; // Close the socket now that we are done with it try &#123; if (socket != null) &#123; socket.close(); &#125; &#125; catch (IOException e) &#123; // Ignore &#125; &#125; // Match against our command string boolean match = command.toString().equals(shutdown); if (match) &#123; log.info(sm.getString("standardServer.shutdownViaPort")); break; &#125; else log.warn("StandardServer.await: Invalid command '" + command.toString() + "' received"); &#125; &#125; finally &#123; ServerSocket serverSocket = awaitSocket; awaitThread = null; awaitSocket = null; // Close the server socket and return if (serverSocket != null) &#123; try &#123; serverSocket.close(); &#125; catch (IOException e) &#123; // Ignore &#125; &#125; &#125;&#125; #### 参考书籍 看透springMvc源代码分析与实践.pdf 推荐博客 解析XML之Digester]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat架构介绍及配置分析]]></title>
    <url>%2F2018%2F03%2F19%2FTomcat%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D%E5%8F%8A%E9%85%8D%E7%BD%AE%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在之前的项目中，需要对项目做集群，由于项目对系统的并发要求不大，所以就采取Session共享方式实现，虽然根据在网上找的资料完成了集群，但是对Tomcat的Session的共享的底层原理一直比较好奇，正好借此机会，调试一下Tomcat源码，略作分析。 bin 存放启动和关闭Tomcat的脚本文件 conf 存放Tomcat的各种配置文件 lib 存放Tomcat的依赖jar包 logs 存放Tomcat的日志文件 temp 存放Tomcat运行中产生的临时文件 webapps web应用所在目录，即供外界访问的web资源的存放目录 work Tomcat的工作目录 1. conf/配置文件说明1.1 catalina.propertiesTomcat的catalina.properties文件位于%CATALINA_HOME%/conf/目录下面，该文件主要配置tomcat的安全设置、类加载设置、不需要扫描的类设置、字符缓存设置四大块。 安全设置 12package.access=sun.,org.apache.catalina.,org.apache.coyote.,org.apache.jasper.,org.apache.tomcat.package.definition=sun.,java.,org.apache.catalina.,org.apache.coyote.,org.apache.jasper.,org.apache.naming.,org.apache.tomcat. 类加载设置 tomcat的类加载顺序为： Bootstrap —&gt; System —&gt; /WEB-INF/classes —&gt; /WEB-INF/lib/*.jar —&gt; Common 注: Common的配置是通过catalina.properties的commons.loader设置的 1common.loader=&quot;$&#123;catalina.base&#125;/lib&quot;,&quot;$&#123;catalina.base&#125;/lib/*.jar&quot;,&quot;$&#123;catalina.home&#125;/lib&quot;,&quot;$&#123;catalina.home&#125;/lib/*.jar&quot; 类加载顺序： ${catalina.base}/lib 未打包的类和资源文件 ${catalina.base}/lib/*.jar JAR文件 ${catalina.home}/lib 未打包的类和文件 ${catalina.home}/lib/*.jar JAR文件 默认情况下，会加载以下内容： annotations-api.jar — JavaEE注释类 catalina.jar — 执行Tomcat的Catalina Servlet容器部分 catalina-ant.jar — Tomcat Catalina Ant 任务 catalina-ha.jar — 高可用包 catalina-tribes.jar — 组通信包 ecj-\.jar* — Eclipse JDT Java 编译器 el-api.jar — EL 2.2 API. jasper.jar — JSP 运行时编译器 jasper-el.jar — EL表达式的实现 jsp-api.jar — JSP 2.2 API. servlet-api.jar — Servlet 3.0 API. tomcat-api.jar — 由Tomcat定义的几个接口 tomcat-coyote.jar — Tomcat连接器和使用程序类 tomcat-dbcp.jar — 基于Apache Commons Pool和Apache Commons DBCP的数据库连接池 tomcat-i18n-**.jar — 包含其他语言的资源约束的可选JAR，默认捆绑包含在每个单独的应用中，如果不需要国际化，可以删除 tomcat-jdbc.jar — Tomcat JDBC数据库连接池 tomcat-util.jar — Tomcat的各种组件使用的常见类 tomcat7-websocket.jar — WebSocket 1.1 实现 websocket-api.jar — WebSocket 1.1 API 注： CATALINA_HOME是Tomcat的安装目录，CATALINA_BASE是Tomcat的工作目录，一个Tomcat可以通过配置CATALINA_BASE来增加多个工作目录，也就是增加多个实例。多个实例各自可以有自己的conf，logs，temp，webapps。 server.loader和shared.loader 在common.loader加载完毕后，tomcat启动程序会检查catalina.properties文件中配置的server.loader和shared.loader是否设置。如果设置，读取tomcat下对应的server和shared这两个目录的类库。server和shared是对应tomcat目录下的两个目录，在Tomcat中默认是没有，catalina.properties中默认也是没有设置其值。设置方法如下： 12server.loader=$&#123;catalina.base&#125;/server/classes,$&#123;catalina.base&#125;/server/lib/*.jarshared.loader=$&#123;catalina.base&#125;/shared/classes,$&#123;catalina.base&#125;/shared/lib/*.jar 同时需要在tomcat目录下创建server和shared目录结构并将公用的、应用类放到里面。类加载顺序为： Bootstrap —&gt; System —&gt; /WEB-INF/classes —&gt; /WEB-INF/lib/*.jar —&gt; Common —&gt; Server —&gt; Shared 字符缓存设置 12345# String cache configuration.tomcat.util.buf.StringCache.byte.enabled=true#tomcat.util.buf.StringCache.char.enabled=true#tomcat.util.buf.StringCache.trainThreshold=500000#tomcat.util.buf.StringCache.cacheSize=5000 总结： Tomcat可以通过catalina.properties的server和shared，为webapp提供公用类库。使一些公用的、不需要与webapp放在一起的设置信息单独保存，在更新webapp的war的时候无需更改webapp的设置。 1.2 catalina.policy包含由Java Security Manager实现的安全策略声明，它替换了安装java时带有的java.policy文件。这个文件用来防止欺骗代码或JSP执行带有像System.exit(0)这样可能影响容器的破坏性代码，只有当Tomcat用-security命令行参数启动时这个文件才会被使用。 1.3 context.xml这个通用context.xml可被所有的web应用程序使用，这个文件默认地可以设置到何处访问各web应用程序中的web.xml文件。context.xml文件的作用和server.xml中标签作用相同。在tomcat5.5之后，对Context的配置不推荐在server.xml中进行配置，而是在/conf/context.xml中进行独立的配置。因为server.xml是不可动态重加载的资源，服务器一旦启动了以后，要修改这个文件，就得重启服务器才能重新加载。而context.xml文件则不然，tomcat服务器会定时去扫描这个文件。一旦发现文件被修改（时间戳改变了），就会自动重新加载这个文件，而不需要重启服务器。 默认的context.xml如下： 1234&lt;Context&gt; &lt;WatchedResource&gt;WEB-INF/web.xml&lt;/WatchedResource&gt; &lt;WatchedResource&gt;$&#123;catalina.base&#125;/conf/web.xml&lt;/WatchedResource&gt;&lt;/Context&gt; 以下给出一个JNDI数据源的配置： 1234567891011&lt;Resource name="jdbc/mysql" auth="Container" type="com.alibaba.druid.pool.DruidDataSource" maxActive="100" maxIdle="30" maxWait="10000" username="root" password="root" driverClassName="com.mysql.jdbc.Driver" url="jdbc:mysql://localhost:3306/test"/&gt; context.xml的作用范围 tomcat server级别 在/conf/context.xml里配置 Host级别 在/conf/Catalina/${hostName}里添加context.xml，继而进行配置。 web app级别 在/conf/Catalina/\${hostName}里添加\${webappName}.xml，继而进行配置。 1.4 server.xmltomcat的主要配置文件，解析器用这个文件在启动时根据规范创建容器。 默认的server.xml如下： 123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8005" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; Server是顶级元素，代表一个Tomcat实例。可以包含一个或多个Service，每个Service都有自己的Engines和Connectors。 Server元素 className 使用Java实现类的名称。这个类必须实现org.apache.catalina.Server接口。如果没有指定类名，将会使用标准实现。 address server在这个TCP/IP地址上监听一个shutdown命令。如果没有指定地址，将会使用localhost。 port server在这个端口上监听一个shutdown命令。设置为-1表示禁用shutdown命令。 shutdown 连接到指定端口的TCP/IP收到这个命令字符后，将会关闭Tomcat。 Listeners元素 Server可以包含多个监听器。一个监听器监听指定事件，并对其作出响应。 GlobalResourcesLifecycleListener作用于全局资源，保证JNDI对资源的可达性，比如数据库。 1&lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; SSLEngine 使用的SSLEngine名称。off：不适用SSL，on：使用SSL但不指定引擎。默认值是on。会初始化本地SSL引擎，对于使用SSLEnabled属性的APR/native connector来讲，该选项必须可用。 SSLRandomSeed 指定伪随机数生成器（PRNG）的随机数种子源，默认值为builtin。在开发环境下，可能要将其设置为/dev/urandom，以获得更快的启动速度。 FIPSMode 设置为on会请求OpenSSL进入FIPS模式（如果OpenSSL已经处于FIPS模式，将会保留该模式）。该设置为enter会强制OpenSSl进入FIPS模式（如果OpenSSL已经处于FIPS模式，将会产生一个错误）。设置为require要求OpenSSL已经处于FIPS模式（如果OpenSSL当前没有处于FIPS模式将会产生一个错误）。 GlobalNamingResources元素全局命名资源 GlobalNamingResources元素定义了JNDI（Java命名和目录接口）资源，其允许Java软件客户端通过名称搜寻和查找数据。默认配置定义了一个名称为UserDatabase的JNDI，通过“conf/tomcat-users.xml”得到一个用于用户授权的内存数据库。 1234567&lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; 也可以定义其他全句话JNDI资源来实现连接池，比如MySQL数据库。 Services元素 一个Service可以连接一个或多个Connectors到一个引擎。默认配置定义了一个名为“Catalina”的Service，连接了两个Connectors：HTTP和AJP到当前的引擎。 123456789101112131415&lt;Service name="Catalina"&gt; &lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt;&lt;/Service&gt; className 该实现使用的Java类名称。这个类必须实现org.apache.catalina.Service接口。如果没有指定类名称，将会使用标准实现。 name Service的显示名称，如果采用了标准的Catalina组件，将会包含日志信息。每个Service与某个特定的Server关联的名称必须是唯一的。 Connectors元素 一个Connector关联一个TCP端口，负责处理Service与客户端之间的交互。默认配置定义了两个Connectors。 HTTP/1.1 处理HTTP请求，使得Tomcat成为一个HTTP服务器。客户端可以通过Connector向服务器发送HTTP请求，接收服务器端的HTTP响应信息。 1&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; 与生产服务默认使用80端口不同，Tomcat HTTP服务默认在TCP端口8080上运行。可以选择1024到65535之间的任意数字作为端口号来运行Tomcat服务器，前提是该端口没有被任何其他应用使用。connectionTimeOut属性定义了这个connector在链接获得同意之后，获得请求URI line（请求信息）响应的最大等待时间毫秒数。默认为20秒。redirect属性会把SSL请求重定向到TCP的8443端口。 AJP/1.3 Apache JServ Protocol connector处理Tomcat服务器与Apache HTTP服务器之间的交互。 1&lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; 可以将Tomcat和Apache HTTP服务运行在一起，Apache HTTP服务器处理静态请求和PHP；Tomcat服务器负责处理Java Servlet/JSP。 容器 包含了Engine、Host、Context和Cluster的Tomcat称为容器。最高级的是Engine，最底层的是Context。某些组件，比如Realm和Value，也可以放在容器中。 Engine引擎 引擎是容器中最高级别的部分。可以包含一个或多个Host。Tomcat服务器可以配置为运行在多个主机名上，包括虚拟主机。 1&lt;Engine name="Catalina" defaultHost="localhost"&gt; Catalina引擎从HTTP connector接收HTTP请求，并根据请求头部信息中主机名或IP地址重定向到正确的主机上。 backgroundProcessorDelay 这个值表示了在这个引擎和它的子容器上调用backgroundProcess方法之间间隔的秒数，包括所有host和context。值为非负时不会调用子容器（意味着其使用自身的处理线程）。设置为正值会产生一个衍生线程。等待指定的时间之后，该线程会在这个引擎和它的所有子容器上调用backgroundProcess方法。如果没有指定，默认值为10，即会有10秒的延迟。 className 实现该引擎使用的Java类名。该类必须实现org.apache.catalina.Engine接口。如果没有指定，会使用标准值。 defaultHost 默认主机名，定义了处理指向该服务器的请求所在主机的名称，但名称不是在这个文件中配置。 jvmRoute 在负载均衡场景下必须定义该参数，来保证session affinity可用，对于集群中所有Tomcat服务器来讲定义的名称必须是唯一的，该名称将会被添加到生成的会话标示符中，因此，允许前端代理总是将特定会话转发到同一个Tomcat实例。 name Engine的逻辑名称，用在日志和错误信息中。当在相同的Server中使用多个Service元素时，每个Engine必须制定一个唯一的名称。 startStopThreads Engine在启动Host子元素时将会并发使用的线程数。如果设置为0，将会使用Runtime.getRuntime().availableProcessors()的值。设置为负数，将会使用Runtime.getRuntime().availableProcessors() + value的值，如果结果小于1，将会使用1个线程。如果没有指定，默认值为1。 Realm元素 一个Realm（域）就是一个包含user、password和role认证（比如访问控制）的数据库。你可以在任何容器中定义Realm，例如Engine、Host、Context和Cluster。 123&lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt;&lt;/Realm&gt; 默认配置定义了一个Catalina Engine的Realm（UserDatabaseRealm），对用户访问engine的权限进行控制。其使用定义在GlobalNamingResources中，名字为UserDatabase的JNDI。 除了UserDatabaseRealm以外，还有：JDBCRealm（授权用户是否可以通过JDBC驱动连接到关系型数据库）；DataSourceRealm（通过JNDI连接到数据库）；JNDIRealm（连接到一个LDAP目录）；MemoryRealm（将XML文件加载到内存）。 className 使用Java实现类的名称。这个类必须实现org.apache.catalina.Realm接口。 Hosts 一个Host定义了在Engine下的一个虚拟机，反过来其又支持多个Context（web应用）。 1&lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; 默认配置定义了一个名为localhost的主机。appBase属性定义了所有webapp的根目录，在这种情况下是webapps。默认情况下，每一个webapp的URL和它所在的目录名称相同。例如，默认的Tomcat安装目录的webapps下提供了四个web应用：docs、examples、host-manager和manager。只有ROOT是个例外，它用一个空字符串定义。也就是说，它的URL是http://localhost:8080/。unpackWARs属性指定了放到webapps目录下的WAR-file是否应该被解压。对于unpackWARs=“false”，Tomcat将会直接从WAR-file运行应用，而不解压，这可能导致应用运行变慢。autoDeploy属性指定了是否自动部署放到webapps目录下的应用。 appBase 虚拟机应用的根目录。该目录是一个可能包含部署到虚拟机上web应用的路径名。也可能是一个指定的绝对路径名，或者是一个相对于$CATALINA_BASE目录的路径名。如果没有指定，默认会使用webapps。 xmlBase 虚拟机XML根目录。该目录是一个可能包含部署到虚拟机上context XML描述符的路径名。也可能是一个指定的绝对路径名，或者是一个相对于$CATALINA_BASE目录的路径名。如果没有指定，默认会使用conf/目录。 createDirs 如果设置为true，Tomcat将会在启动阶段，尝试创建一个由appBase和xmlBase属性定义的目录。默认值为true。如果设置为true，并且目录创建失败，将会打印出一个错误信息，但是不会终止启动过程。 autoDeploy 该属性的值指明了在Tomcat运行的时候，是否需要定义检查新的或者更新后的web应用。如果为true，Tomcat会定义检查appBase和xmlBase目录，并对找到的新web应用和context XML描述符进行部署。更新web应用或XML上下文描述符将会触发web应用的重载。默认值为true。 backgroundProcessorDeploy 表示在调用这台主机的backgroundProcess方法和它的子容器方法，包括所有的context，之间延迟的秒数。如果延迟值不是负数的话，不会调用子容器（意味着会使用它们自己的处理线程）。设置为正数会产生衍生线程。在等待指定的时间之后，线程将会在该host上调用backgroundProcess方法，包括它的所有子容器。host将会使用后台进程执行web应用部署相关的任务。如果没有指定，默认值为-1，意味着host将会依赖于它的父引擎的后台处理线程。 className 使用的Java实现类的名称。该类必须实现org.apache.catalina.Host接口。 deployIgnore 一个正则表达式，定义了在自动部署和启动时部署的情况下需要忽略的目录。这就允许我们在版本控制系统中保持自己的配置，例如，不会将.svn或者git文件夹部署到appBase目录下。该正则表达式是相对于appBase的。同时也是固定的，意味着是相对于整个文件或目录的名称进行的。因此，foo只会匹配名称为foo的文件或目录，而不会匹配foo.war等名称的文件或目录。如果想让“foo”匹配任意名称，可以使用“.*foo.*”。 deployOnStartup 指定在Tomcat启动时是否需要自动部署host下的web应用。默认值为true。 failCtxlfServletStartFails 设置为true时，如果它的任意一个load-on-startup &gt;= 0的servlet停止自身启动后，停止启动它的每一个子context。每一个子context可能覆盖这个属性。如果没有指定，将会使用默认值false。 name 通常是虚拟主机的网络名称，注册在你的域名服务器上。无论指定的主机名称是什么样的，Tomcat在内部都会将其转换为小写。嵌套在Engine内部的Host，其中必须有一个Host的名称匹配Engine的默认Host设置。 startStopThreads Host在启动子Context元素时会并发使用的线程数。如果自动部署被使用的话将会使用该线程池部署新的Context。值为0时将会使用Runtime.getRuntime().availableProcessors()的值。值为负数时将会使用Runtime.getRuntime().availableProcessors()加上该值得和，小于1时将会使用1个线程。如果没有指定，会使用默认值1。 undeployOldVersion 该选项的值决定Tomcat，即自动部署进程部分，是否会检查并发部署的过时web应用，任何找到的应用都会被移除。只有在autoDeploy为true的情况下才会生效。如果没有指定将会使用默认值false。 Value Value（阀门）作为请求的前置处理程序，可以在请求发送到应用之前拦截HTTP请求。可以定义在任何容器中，比如Engine、Host、Context和Cluster。默认配置中，AccessLogValue会拦截HTTP请求，并在日志文件中创建一个切入点 123&lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; className 设置为org.apache.catalina.ha.tcp.ReplicationValue filter 对于已知文件扩展名或url，可以在请求中使用Value通知cluster没有修改session，对于本次变化cluster没有必要通知session管理者。如果请求匹配该过滤器模型，cluster会假设session没有发生变化。一个filter样例大概是这样的filter=“.*.gif|.*.js|.*.jpeg|.*.jpg|.*.png|.*.htm|.*.html|.*.css|.*.txt”。filter使用java.util.regex的正则表达式。 primaryIndicator 布尔值，如果为true，replication value将会把primaryIndicatorName属性定义的名称插入到request属性中，该值无论是Boolean.TRUE或者Boolean.FALSE，都会被放入request属性中。 primaryIndicatorName 默认值为org.apache.catalina.ha.tcp.isPrimarySession，这个值定义了一个request属性的名称，值是一个布尔值，表示会话所在的服务器是否为主服务器。 statistics 布尔值，如果想让value手机请求的统计数据，设置为true，默认值为false。 RemoteAddrValue 阻截来自特定IP地址的请求。 RemoteHostValue 阻截基于主机名称的请求。 RequestDumperValue 记录了请求的详细信息。 SingleSignOnValue 当置于a下时，允许单点登录到该主机下的所有应用上。 ​ 1.5 tomcat-users.xml用于访问tomcat管理应用程序时的安全性设置，用server.xml中引用的默认的用户数据库域（UserDatabase Realm）使用它，所有的凭证默认都是被注释的，如需授权和访问控制，或配置角色，可参考以下配置。 12345&lt;role rolename="manager"/&gt;&lt;role rolename="manager-gui"/&gt;&lt;role rolename="admin"/&gt;&lt;role rolename="admin-gui"/&gt;&lt;user username="admin" password="admin" roles="admin-gui,admin,manager-gui,manager"/&gt; 这样tomcat7首页上的Server Status、Manager App、Host Manager就都可以点击登录进去。 tomcat6配置： 123&lt;role rolename="admin"/&gt;&lt;role rolename="manager"/&gt;&lt;user username="admin" password="admin" roles="admin,manager"/&gt; 1.6 web.xml默认的web.xml文件可被所有的web应用程序使用，这个web.xml文件会设置jspservlet以支持应用程序处理jsps，并设置一个默认的servlet来处理静态资源和html文件，它还设置默认的回话超时以及像index.jsp，index.html这类欢迎文件，并且它为最通用的扩展文件设置默认的MIME类型。 一般在Java工程中，web.xml用来初始化工程配置信息，比如welcome页面，filter，listener，servlet，servlet-mapping，启动加载级别等等。 当应用程序被部署到tomcat时，它会用[engine name]/[host name]/[context-path name].xml创建与context.xml等效的文件，如用户也在\$CATALINA_BASE/conf/[enginename]/[hostname]/context.xml.default文件，在这个文件中特定主机下的所有web应用程序将对主机器虚拟环境采用一系列默认设置。 下面就详细介绍一下web.xml中常用的标签及其功能。 \&lt;description>，\&lt;display-name>，\&lt;icon> \&lt;description> 1&lt;description&gt;项目描述&lt;/description&gt; &lt;!--对项目作出描述--&gt; \&lt;display-name> 1&lt;display-name&gt;项目名称&lt;/display-name&gt; &lt;!--定义项目的名称--&gt; \&lt;icon>及\&lt;small-icon>，\&lt;large-icon> \&lt;icon> icon元素包含small-icon和large-icon两个子元素，用来指定web站台中小图标和大图标的路径。 1234&lt;!--small-icon元素应指向web站台中某个小图标的路径，大小为16X 16 pixel，但是图像文件必须为GIF或JPEG格式，扩展名必须为.git或.jpg--&gt;&lt;small-icon&gt;/路径/smallicon.gif&lt;/small-icon&gt;&lt;!--large-icon元素应指向web站台中某个大图标路径，大小为32X 32pixel，但是图像文件必须为GIF或JPEG的格式，扩展名必须为.git或.jpg--&gt;&lt;large-icon&gt;/路径/largeicon.jpg&lt;/large-icon&gt; 例如： 123456&lt;display-name&gt;Demo Example&lt;/display-name&gt;&lt;description&gt;JSP 2.0 Demo Example&lt;/description&gt;&lt;icon&gt; &lt;small-icon&gt;/images/small.gif&lt;/small-icon&gt; &lt;large-icon&gt;/images/large.gif&lt;/large-icon&gt;&lt;/icon&gt; \&lt;context-param> \&lt;context-param>元素含有一对参数名和参数值，用作应用的servlet上下文初始化参数。参数名在整个web应用中必须是唯一的。 例如： 1234&lt;context-param&gt; &lt;param-name&gt;name&lt;/param-name&gt; &lt;param-value&gt;haha&lt;/param-value&gt;&lt;/context-param&gt; 此处设定的参数，在JSP页面可以使用\${initParam.name}来获取。 在Servlet中可以使用下列方式获取： 1String name = getServletContext().getInitParamter("name"); \&lt;filter> filter元素用于指定web容器中的过滤器。 在请求和响应对象被servlet处理之前或之后，可以使用过滤器对这两个对象进行操作。通过filter-mapping元素，过滤器被映射到一个servlet或一个URL模式。这个过滤器的filter元素和filter-mapping元素必须具有相同的名称。 filter元素用来声明filter的相关设定，filter元素除了下面介绍的子元素之外，还包括&lt;icon>，\&lt;display-name>，\&lt;description>，\&lt;init-param>，其用途一样。 例如： 12345678&lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt; \&lt;filter-mapping> filter-mapping元素用来声明web应用中的过滤器映射。过滤器可被映射到一个servlet或一个URL模式。将过滤器映射到一个servlet中会造成过滤器作用于servlet上。将过滤器映射到一个URL模式中则可以将过滤器应用于任何资源，只要该资源的URL与URL模式匹配。过滤是按照部署描述符的filter-mapping元素出现的顺序执行的。 filter-mapping元素的两个主要子元素filter-name和url-pattern用来定义Filter对应的URL。还有servlet-name和dispatcher子元素，不是很常用。 特别说明一下dispatcher，设置Filter对应的请求方式，有：REQUEST,INCLUDE,FORWAR,ERROR四种，默认为REQUEST。 例如： 1234&lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; \&lt;servlet> 在web.xml中完成一个最常见的任务是对servlet或JSP页面给出名称和定制的URL。用servlet元素分配名称，使用servlet-mapping元素将定制的URL与刚分配的名称相关联。 例如： 1234&lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;&lt;/servlet&gt; \&lt;servlet-mapping> servlet-mapping元素包含两个子元素servlet-name和url-pattern，用来定义servlet所对应的URL。 例如： 1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; \&lt;listener> listener元素用来注册一个监听器类，可以在web应用中包含该类。使用listener元素，可以收到事件什么时候发生以及用什么作为响应的通知。 listener元素用来定义Listener接口，它的主要子元素为\&lt;listener-class> 例如： 123&lt;listener&gt; &lt;listener-class&gt;com.gnd.web.listener.TestListener&lt;/listener-class&gt;&lt;/listener&gt; \&lt;session-config> session-config包含一个子元素session-timeout，定义web应用中session的有效期限。 例如： 123&lt;session-config&gt; &lt;session-timeout&gt;900&lt;/session-timeout&gt;&lt;/session-config&gt; \&lt;mime-mapping> mime-mapping包含两个子元素extension和mime-type，定义某个扩展名和某一MIME Type做对应。 \&lt;extension>扩展名名称\&lt;/extension> \&lt;mime-type>MIME格式\&lt;/mime-type> 例如： 123456789101112&lt;mime-mapping&gt; &lt;extension&gt;doc&lt;/extension&gt; &lt;mime-type&gt;application/vnd.ms-word&lt;/mime-type&gt;&lt;/mime-mapping&gt;&lt;mime-mapping&gt; &lt;extension&gt;xls&lt;/extension&gt; &lt;mime-type&gt;application/vnd.ms-excel&lt;/mime-type&gt;&lt;/mime-mapping&gt;&lt;mime-mapping&gt; &lt;extension&gt;ppt&lt;/extension&gt; &lt;mime-type&gt;application/vnd.ms-powerpoint&lt;/mime-type&gt;&lt;/mime-mapping&gt; \&lt;welcome-file-list> welcome-file-list包含一个子元素welcome-file，用来定义首页列表。 welcome-file用来指定首页文件名称，服务器会按照设定的顺序来找首页。 例如： 1234&lt;welcome-file-list&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt;&lt;/welcome-file-list&gt; \&lt;error-page> error-page元素包含三个子元素error-code，exception-type和location。 将错误代码后异常的种类对应到web应用资源路径。 例如： 12345678&lt;error-page&gt; &lt;error-code&gt;404&lt;/error-code&gt; &lt;location&gt;error404.jsp&lt;/location&gt;&lt;/error-page&gt;&lt;error-page&gt; &lt;exception-type&gt;java.lang.Exception&lt;/exception-type&gt; &lt;location&gt;error404.jsp&lt;/location&gt;&lt;/error-page&gt; \&lt;jsp-config> jsp-config元素主要用来设定jsp的相关配置，jsp-config包括taglib和jsp-property-group两个子元素，其中taglib元素在JSP1.2时就已经存在，而jsp-property-group是JSP2.0新增的元素。 \&lt;taglib> taglib元素包含两个子元素taglib-uri和taglib-location，用来设定JSP网页用到的TagLibrary路径。 \&lt;taglib-uri>URI\&lt;/taglib-uri> taglib-uri定义TLD文件的URI，JSP网页的taglib指令可以经由这个URI存取到TLD文件。 \&lt;taglib-location>/WEB-INF/lib/xxx.tld\&lt;/taglib-location> TLD文件对应web应用的存放位置。 \&lt;jsp-property-group> jsp-property-group元素包含8个子元素，分别为： \&lt;description>Description\&lt;/description> 此设定的说明 \&lt;display-name>Name\&lt;/display-name> 此设定的名称 \&lt;url-pattern>URL\&lt;/url-pattern> 设定值所影响的范围，如*.jsp \true/false\&lt;/el-ignored> 是否支持EL语法 \&lt;scripting-invalid>true/false\&lt;/scripting-invalid> 是否支持java代码片段&lt;%…%&gt; \&lt;page-encoding>UTF-8\&lt;/page-encoding> 设置JSP页面的编码 \&lt;include-prelude>.jspf\&lt;/include-prelude> 设置JSP页面的抬头，扩展名为.jspf \.jspf\ 设置JSP页面的结尾，扩展名为.jspf 例如： 1234567891011121314&lt;jsp-config&gt; &lt;taglib&gt; &lt;taglib-uri&gt;Taglib&lt;/taglib-uri&gt; &lt;taglib-location&gt;/WEB-INF/tlds/MyTaglib.tld&lt;/taglib-location&gt; &lt;/taglib&gt; &lt;jsp-property-group&gt; &lt;description&gt;Configuration JSP example&lt;/description&gt; &lt;display-name&gt;JspConfig&lt;/display-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;el-ignored&gt;true&lt;/el-ignored&gt; &lt;page-encoding&gt;UTF-8&lt;/page-encoding&gt; &lt;scripting-invalid&gt;true&lt;/scripting-invalid&gt; &lt;/jsp-property-group&gt; &lt;/jsp-config&gt; \&lt;resource-ref> resource-ref元素包含五个子元素description，res-ref-name，res-type，res-auth，res-sharing-scope，利用JNDI取得应用可利用资源。 \&lt;res-auth>Application/Container\&lt;/res-auth> 资源由Application或Container来许可。 \Shareable|Unshareable\ 资源是否可以共享，默认值为Shareable 例如： 12345&lt;resource-ref&gt; &lt;res-ref-name&gt;jdbc/Druid&lt;/res-ref-name&gt; &lt;res-type&gt;com.alibaba.druid.pool.DruidDataSource&lt;/res-type&gt; &lt;res-auth&gt;Container&lt;/res-auth&gt; &lt;/resource-ref&gt; 1.7 loggin.propertiesJULI记录器使用默认日志配置，它默认地使用ConsoleHandler和fileHandler设置应用程序或者程序包的日志级别。 2. 启动流程分析2.1 Idea调试Tomcat源码环境搭建首先下载Tomcat源码，读者可自行去Tomcat官网 下载，若执行力差的同学也可直接从此处pull。 Tomcat源码导入到开发工具中的方法有多种，笔者采用最直接的方式，解压源码包后直接导入到开发工具中，导入之后的源码并不能直接运行，还需要几个依赖包，读者可从此处的lib目录下获取，也可自行搜集。 找好依赖包也并不能让Tomcat源码正常运行，还需要为Bootstrap这个启动类增加几个启动参数。 123456-Dcatalina.home=/Users/chenmin/GitHub/tomcat-Dcatalina.base=/Users/chenmin/GitHub/tomcat-Djava.endorsed.dirs=/Users/chenmin/GitHub/tomcat/endorsed-Djava.io.tmpdir=/Users/chenmin/GitHub/tomcat/temp-Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager-Djava.util.logging.config.file=/Users/chenmin/GitHub/tomcat/conf/logging.properties 上面的参数具体代表的意思就不一一详述了，其实光看名字就知道都是干嘛用的了。 以上准备步骤做好之后，就可以直接运行Bootstrap类，运行Tomcat源码进行调试了。 2.2 Tomcat Server的组成2.2.1 整体说明在上面对配置文件的说明中，通过server.xml的解释，我们知道server.xml中最顶级的元素是server，而server.xml中的每一个元素我们都可以把它看做是Tomcat中的某一个部分。所以我们可以参照着server.xml来分析源码。 Tomcat最顶层的容器叫Server，它代表着整个Tomcat服务器。Server中至少要包含一个Service来提供服务。Service包含两部分：Connector和Container。Connector负责网络连接，request/response的创建，并对Socket和request、response进行转换等，Container用于封装和管理Servlet，并处理具体的request请求。 一个Tomcat中只有一个Server，一个Server可以有多个Service来提供服务，一个Service只有一个Container，但是可以有多个Connector（一个服务可以有多个连接）。 2.2.2 各组件详解可结合conf/配置文件说明中的server.xml的说明来看 Server Server代表整个Servlet容器 Service Service是由一个或多个Connector以及一个Engine，负责处理所有Connector所获得的客户请求的集合。 Connector Connector将在某个指定端口上侦听客户请求，并将获得的请求交给Engine来处理，从Engine处获得回应并返回给客户端。 Tomcat有两个默认的Connector，一个直接监听来自浏览器的http请求，一个监听来自其他WebServer的请求。 Coyote Http/1.1 Connector在端口8080上监听来自浏览器的http请求 Coyote AJP/1.3 Connector在端口8009上监听来自其他WebServer的servlet/jsp代理请求。 Engine Engine下可以配置多个虚拟主机，每个虚拟主机都有一个域名，当Engine获得一个请求时，Engine会把该请求匹配到某个Host上，然后把该请求交给该Host来处理。 Engine有一个默认虚拟主机，当请求无法匹配到任何一个Host上的时候，将交给该默认Host来处理。 Host 代表一个虚拟主机，每个虚拟主机和某个网络域名相匹配。每个虚拟主机下都可以部署一个或者多个WebApp，每个WebApp对应于一个Context，有一个ContextPath。当Host获得一个请求时，将把该请求匹配到某个Context上，然后把该请求交给该Context来处理。匹配的方法是“最长匹配”，所以一个path==“”的Context将成为该Host的默认Context，所有无法和其他Context的路径名匹配的请求都将最终和该默认Context匹配。 Context 一个Context对应于一个Web Application（Web应用），一个Web应用有一个或多个Servlet组成，Context在创建的时候将根据配置文件\$CATALINA_HOME/conf/web.xml和\$WEBAPP_HOME/WEB-INF/web.xml载入Servlet类。如果找到，则执行该类，获得请求的回应，并返回。 Tomcat各组件关系图(此图来此网上)]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对前后台分离的思考]]></title>
    <url>%2F2018%2F03%2F05%2F%E5%AF%B9%E5%89%8D%E5%90%8E%E5%8F%B0%E5%88%86%E7%A6%BB%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[在为期一年多的前后端分离项目的开发中，对这种新型的项目开发模式也算是有了一定的了解，此文对这种开发模式的感悟略作记录。 传统的javaweb项目，在开发的过程中，没有明确的分工，后台人员即要写后台，也要做数据库，更要写页面，而且传统的javaweb项目，大多都是jsp，有时候没有明确的规范，jsp页面加入大量的java代码，导致项目前后台杂乱不堪。 随着时代的发展，各种前后台框架的出现，前段知识大量增加，如果还保持着传统项目架构，后端人员工作量大大增加，需要学习的知识也同步增加，最终造成的结果就是啥都懂一点，啥都不精。 慢慢的，前后端分离架构出现了，前端人员专心研究前端的事，后端人员专心提高后端的事，正所谓术业有专攻。 正文前后端分离，大体上就是前端页面和后端的交互只通过json。页面的跳转等都由前端控制，后端只负责为页面提供数据。 在公司为期将近一年的开发中，各种新项目，老项目都渐渐的采用前后端分离架构，对这种架构模式也有了一点初步的认识，接下来就说说我在项目中对前后端分离的各种体会。 首先，先说说在开发中，因为前后端分离产生的一些问题。 在开发中，因为基本上前端都是那种特别纯粹的前端人员，也就是只懂前端，不了解java，不了解oracle，不了解业务，不了解网络协议等等各种基础知识即特性，在开发中出现了各种问题，比如请求中cookie丢失不知如何处理，功能开发完成之后不知如何测试，不懂业务导致不知道自己做出的页面到底对不对等等各种问题，而且由于后台只提供数据，不做页面跳转，所以在和传统项目做SSO单点登录的时候更麻烦。 当然，前后台分离也并不是没有好处。 开发人员的职能划分更加明确，前后端人员各自考虑自己职能范围内的事，比如前端人员可以专心提高页面的用户体验，而后端人员则专注于接口开发和后台性能 前后端能够同步进行，事先定义好接口，前后端同步进行，到后面只需要进行对接联调即可 前台基本上采用静态页面，响应速度快 前后端分离了，可以分开部署，也可以分开做负载处理 针对前后端分离架构的项目准备工作由于前后端分离，前后端由不同的人员去开发，所以项目的准备工作一定要做到位。 项目必须要有详细的API，并且能够测试数据，以便前端人员能够在最短的时间内拿到正确的API，swagger就挺不错的，后端API有改动时，能够实时反映出来。 对于页面功能，最好有明确的模型图 在项目开始时，前后端人员必须都对业务有所了解，“脱离业务的项目架构都是耍流氓”，忘记出自哪里了。 目前大概只有这些体会了，后面有更深的理解，会继续补充。]]></content>
      <categories>
        <category>思考</category>
      </categories>
      <tags>
        <tag>项目架构</tag>
        <tag>前后端分离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis基础配置]]></title>
    <url>%2F2018%2F02%2F08%2FRedis%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Redis常用配置总结 基本配置 Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程1daemonize no 当Redis以守护进程方式运行时，Redis会默认把pid写入/var/run/redis.pid文件，可以通过pidfile指定 1pidfile /var/run/redis.pid 指定Redis监听端口，默认端口为6379 1port 6379 绑定主机地址 1bind 127.0.0.1 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 1timeout 300 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose 1loglevel verbose 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null 1logfile stdout 设置数据库的数量，默认数据库有16个（0-15），默认使用0，可以使用SELECT \&lt;dbid> 命令在连接上指定数据库id 1databases 16 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 1save &lt;seconds&gt; &lt;changes&gt; Redis默认配置文件中提供了三个条件 123save 900 1save 300 10save 60 10000 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但是会导致数据库文件变大 1rdbcompression yes 指定本地数据库文件名，默认值为dump.rdb 1dbfilename dump.rdb 指定本地数据库存放目录 1dir ./ 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 1slaveof &lt;masterip&gt; &lt;masterport&gt; 当master服务设置了密码保护时，slav服务连接master的密码 1masterauth &lt;master-password&gt; 如果配置了连接密码，客户端在链接Redis时需要通过AUTH \&lt;password>命令提供密码，默认关闭 1requirepass foobared 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置maxclients 0，表示不做限制。当客户端连接数达到限制时，Redis会关闭新的连接并像客户端返回max number of clients reached错误信息 1maxclients 128 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理后，仍然达到最大内存限制，将无法再进行写操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放到swap区 1maxmemory &lt;bytes&gt; 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面的save条件同步的，所以有的数据会在一段时间内只存在于内存中，默认为no 1appendonly no 指定更新日志文件名，默认为appendonly.aof 1appendfilename &quot;appendonly.aof&quot; 指定更新日志条件，共有3个可选值 no：表示等操作系统进行数据缓存同步到磁盘（快） always：表示每次更新操作后手动调用fsync() 将数据写到磁盘（慢，安全） everysec：表示每次同步一次（折衷，默认值） 1appendfsync everysec 指定是否启用虚拟内存机制，默认值为no，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动缓存到内存中 1vm-enabled no 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 1vm-swap-file /tmp/redis.swap 将所有大于vm-max-memory的数据存入虚拟内存，无论vm-max-memory设置多小，所有索引数据都是内存存储的（Redis的索引数据就是keys），也就是说，当vm-max-memory设置为0的时候，其实是所有value都存在于磁盘。默认值为0 1vm-max-memory 0 Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的数据大小来设定的，如果存储很多小对象，page大小最好设置为32或者64bytes，如果存储很多的大对象，则可以使用更大的page，如果不确定，就使用默认值 1vm-page-size 32 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是存放在内存中的，在磁盘上每8个pages将消耗1byte的内存 1vm-pages 134217728 设置访问swap文件的线程数，最好不要超过机器的核数，如果设置为0，那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟，默认值为4 1vm-max-threads 4 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启 1glueoutputbuf yes 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 12hash-max-zipmap-entries 64hash-max-zipmap-value 512 指定是否激活重置哈希，默认为开启 1activerehashing yes 常用操作（高级）Redis官网命令详解 事务操作Redis的事务也有两种，乐观锁和悲观锁。 悲观锁，直接给这个key加锁，这个key只能当前连接可以操作。 乐观锁，给这个key加锁，只要这个key的值没有更改就可以了。 Redis的事务中，默认启用的是乐观锁，只负责监测key有没有变动。 12345watch key1 key2 监听key有没有变化，如果有变化，则事务取消，在multi之前使用unwatch key1 key2 不加具体key时，取消所有key的监听。multi 开启事务...discard/exec 取消事务/提交事务 注意：如果在exec时，命令语法有问题，这时所有的语句都得不到执行。如果语法本身没问题，但是适用的对象有问题，exec之后，会执行正确的语句，并跳过有问题的语句。 消息的发布与订阅使用办法： 订阅端：subscribe 频道名称 psubscribe 支持表达式匹配的频道 返回值为订阅到消息的客户端数量 发布端：publish 频道名称 发布内容 Redis持久化配置 持久化 把数据存储于断电后不会丢失的设备中，通常是硬盘 常见的持久化方式 主从：通过主服务器往内存中写，从服务器做保存和持久化 日志：操作生成相关日志，并通过日志来恢复数据，couchDB对于数据内容，不修改，只追加，则文件本身就是日志，不会丢失数据。 rdb快照持久化 rdb工作原理 每隔N分钟或N次写操作后，从内存dump数据形成rdb文件，压缩放在备份目录 rdb快照相关参数 12345678save 900 1 #刷新快照到磁盘中，必须满足两者要求才会触发，即900秒之内至少1个关键字发生变化save 300 10 #必须是300秒之内至少10个关键字发生变化save 60 10000 #必须是60秒之内至少10000个关键字发生变化stop-writes-on-bgsave-error yes #后台存储错误停止写rdbrdbcompression yes #使用LZF压缩rdb文件rdbchecksum yes #导入rdb恢复时数据时，要不要校验rdb的完整性dbfilename dump.rdb #设置rdb文件名dir ./ #设置工作目录，rdb文件会写入该目录 rdb的缺陷 在上一个保存点刚结束，下个保存点还没到时如果断电，将会丢失1-N分钟的数据 rdb的优势 由于导出的是一个内存的二进制文件，所以rdb文件的恢复速度超级快 aof日志持久化 aof工作原理 redis客户端连接redis服务器后所进行的每一条命令的操作都逐条记录到aof日志中，在恢复数据时，只需要将日志中记录的命令都依次执行一遍即可。 aof配置参数 123456789appendonly yes #是否打开aof日志功能appendfilename &quot;appendonly.aof&quot; #设置aof文件名appendfsync everysec #折衷方案，每秒写一次appendfsync no #写入工作交给操作系统，由操作系统判断缓冲区大小，统一写入到aof，同步频率低，速度快appendfsync always #每一个命令都立即同步到aof，安全，速度慢no-appendfsync-on-rewrite no #正在到处rbd快照的过程中，要不要停止同步aofauto-aof-rewrite-percentage 100 #aof文件大小比起上次重写时的大小，增长率100%时进行重写auto-aof-rewrite-min-size 64mb #aof文件，至少超过64M时进行重写# 上面两个aof重写规则同时满足aof才会进行重写 aof的缺陷 由于项目使用redis，就是图redis的读写速度快，但是如果频繁写磁盘，也会拉低效率的，而且越往后，aof日志文件会越来越大的。 aof的优势 使用日志记录操作，能有效的保证数据的完整性，就算太巧合了，在刚执行了命令还没来得及同步aof时断电了，那也只会丢失当前的一条命令。 aof重写 把内存中的数据，逆化成命令写到aof日志里，以解决aof日志过大的问题。 总结1、在dump过程中，aof如果停止同步，数据不会丢失，因为所有的操作会缓存在队列里，dump完成后，统一操作 2、如果rdb和aof文件都存在，它会采用谁优先就用谁来恢复数据，也就是会用aof 3、对于rdb和aof两种持久化方式，没有绝对的谁好谁坏，所以可以两者同时用，效果更优 4、rdb和aof相比，rdb的数据恢复更快，因为rdb的数据是内存映射，可以直接载入到内存，而aof是一条条的命令，需要逐条执行]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis集群搭建]]></title>
    <url>%2F2018%2F02%2F08%2FRedis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Redis的各种集群搭建方式介绍 Redis主从复制此处使用 4.0.2 的版本，搭建一主两从的Redis集群。 环境准备 从此处下载redis-4.0.2.tar.gz，解压之后，编译源码进行安装。 1234$ wget http://download.redis.io/releases/redis-4.0.2.tar.gz$ tar -zxvf redis-4.0.2.tar.gz$ cd redis-4.0.2$ make &amp;&amp; make install 在用户家目录下新建redis相关目录 12345$ cd ~$ make redis$ cd redis$ mkdir master# mkdir slave 然后拷贝redis-4.0.2目录中的redis.conf配置文件到master，修改为redis_master.conf，slave中拷贝两份，分别命名为redis_slave1.conf，redis_slave2.conf。 接下来修改配置文件内容（只贴出关键几个点，其他辅助内容请读者自行修改）：redis_master.conf 12port 7000daemonize yes redis_slave1.conf 123port 7001daemonize yesslaveof localhost 7000 redis_slave2.conf 123port 7002daemonize yesslaveof localhost 7000 分别启动三个节点： 123$ ./redis-4.0.2/src/redis-server ./master/redis_master.conf$ ./redis-4.0.2/src/redis-server ./slave/redis_slave1.conf$ ./redis-4.0.2/src/redis-server ./slave/redis_slave2.conf 登录进master节点，查看主从模式是否正常启动(主节点上能显示出两个从节点即可) 12$ ./redis-4.0.2/src/redis-cli&gt; info replication 三主三从三哨兵集群模式redis编译安装和上面一样 环境准备master 1192.168.10.100:6380,192.168.10.100:6381,192.168.10.100:6382 slave 1192.168.10.100:6383,192.168.10.100:6384,192.168.10.100:6385 sentinel 1192.168.10.100:26380,192.168.10.100:26381,192.168.10.100:26382 修改配置文件手动在服务器上新建6380,6381,6382,6383,6384,6385几个目录，将redis.conf配置文件每个目录拷贝一份（批量拷贝文件时，最好参考linux中xargs命令；当然，也可以cp多执行几次）。 redis.conf配置文件修改 1234567891011121314151617181920# 端口分别为6380,6381,6382,6383,6384,6385port 6380# 默认端口为127.0.0.1，改为本机地址则为任意服务器都可以访问，若只指定服务器访问，则改为指定服务器ip即可，由于当前是一台服务器上的伪集群，所以配置本机ip地址。bind 192.168.10.100# Redis后台运行daemonize yes# pidfile文件对应存放目录(redis节点进程号)pidfile /home/admin/redis/cluster/6380/redis.pid# 操作日志logfile &quot;/home/admin/redis/cluster/6380/redis.log&quot;# 数据文件存放目录dir /home/admin/redis/cluster/6380/# 是否开启集群(重点)cluster-enabled yes# 集群节点配置，集群首次启动自动生成cluster-config-file nodes.conf# 集群节点连接超时时间cluster-node-timeout 15000# aof日志开启，可做为日志记录，也可借此恢复数据appendonly yes 其他节点类似。 然后启动每一个节点 123456$ ./redis-4.0.2/src/redis-server ./cluster/7000/redis.conf$ ./redis-4.0.2/src/redis-server ./cluster/7001/redis.conf$ ./redis-4.0.2/src/redis-server ./cluster/7002/redis.conf$ ./redis-4.0.2/src/redis-server ./cluster/7003/redis.conf$ ./redis-4.0.2/src/redis-server ./cluster/7004/redis.conf$ ./redis-4.0.2/src/redis-server ./cluster/7005/redis.conf 创建集群这里创建集群借助于redis自己提供的一个集群创建工具redis-trib.rb（依赖于ruby环境），Redis 5.*的集群构建工具依赖于g++环境 1$ ./redis-4.0.2/src/redis-trib.rb create --replicas 1 192.168.10.100:6380 192.168.10.100:6381 192.168.10.100:6382 192.168.10.100:6383 192.168.10.100:6384 192.168.10.100:6385 根据提示完成集群创建 接下来验证集群是否搭建成功，连接其中一个节点 1234567891011121314$ ./redis-4.0.2/src/redis-cli -h 192.168.10.110 -p 6380&gt; cluster nodesdcebbc47abd482363f221020dd1be714a498b841 192.168.10.110:6382 master - 01524568524063 3 connected 10923-1638333eaf24ca33b4f5bcc37c2a7434bddaf5432f057 192.168.10.110:6380 myself,master - 0 0 1connected 0-546051ed0849bf29de0221eb3b9b4ccbebfd341593ad 192.168.10.110:6384 slave409b146c1fc86acfd6198c491cf77eaf8c8c7c04 0 1524568525066 5 connectede29d4537e924f0e29f5155536a636b35a44a8c24 192.168.10.110:6383 slave33eaf24ca33b4f5bcc37c2a7434bddaf5432f057 0 1524568523562 4 connecteddc4f070c42f9002e1c54bb6019ee4c34331570cc 192.168.10.110:6385 slavedcebbc47abd482363f221020dd1be714a498b841 0 1524568523062 6 connected409b146c1fc86acfd6198c491cf77eaf8c8c7c04 192.168.10.110:6381 master - 01524568524063 2 connected 5461-10922 输入info replication可查看节点信息。 哨兵搭建新建sentinel/26380,26381,26382目录，将redis家目录下的sentinel.conf文件拷贝到每个目录中 sentinel.conf 123456789bind 192.168.10.100port 26380daemonize yesdir &quot;/home/admin/redis/cluster/sentinel/26380&quot;# 故障转移配置# 表示哨兵集群中，至少有两个节点认为Redis节点挂掉，则将节点从集群中剔除sentinel monitor mymaster 192.168.10.100 6380 2sentinel config-epoch mymaster 0sentinel leader-epoch mymaster 0 其他的类似 启动哨兵 123$ ./redis-4.0.2/src/redis-sentinel ./cluster/sentinel/26380/sentinel.conf$ ./redis-4.0.2/src/redis-sentinel ./cluster/sentinel/26381/sentinel.conf$ ./redis-4.0.2/src/redis-sentinel ./cluster/sentinel/26382/sentinel.conf 查看哨兵节点信息 12345678$ ./redis-4.0.2/src/redis-cli -h 192.168.10.110 -p 26380&gt; info Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=cpicmaster,status=ok,address=192.168.10.110:6380,slaves=1,sentinels=3]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[针对SpringBoot封装的Quartz starter模块]]></title>
    <url>%2F2018%2F01%2F04%2F%E9%92%88%E5%AF%B9SpringBoot%E5%B0%81%E8%A3%85%E7%9A%84Quartz-starter%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[针对公司业务要求，针对springboot，对quartz做了简单的封装，将其做成SpringBoot的一个Starter模块。主要功能有： 任务配置动态更新，增加，停止，立即执行 任务立即执行 quartz集群节点是否开启实现可配置化 后续功能继续增加中。。。 以下是在项目中具体使用方法: 1、导入spring-boot-starter-quartz包 maven 12345&lt;dependency&gt; &lt;groupId&gt;com.github.quartz&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt; gradle 1compile('com.github.quartz:spring-boot-starter-quartz:1.0') 2、开启Quartz自动配置目前提供了@EnableQuartz，@EnableQuartzBean，@EnableQuartzDataBase三个开启自动配置注解。 @EnableQuartz：开启所有的自动配置 @EnableQuartzBean：开启quartz远程调用客户端配置 @EnableQuartzDataBase：开启quartz远程调用客户端及quartz相关基础Bean的配置 3、任务配置表脚本可在发布包的根目录中获得 Quartz集群的相关表可在Quartz的发布包org.quartz.impl.jdbcjobstore目录下找到相关SQL。 Quartz官方源码地址：【https://github.com/quartz-scheduler/quartz/blob/master/quartz-core/src/main/resources/org/quartz/impl/jdbcjobstore】 以下以Oracle的脚本为例 任务配置表（QRTZ_TIMED_TASK） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263-- CREATE TABLECREATE TABLE QRTZ_TIMED_TASK( TASK_NAME VARCHAR2(200), TASK_DESC VARCHAR2(500), TASK_EXPRES VARCHAR2(100), TASK_METHOD VARCHAR2(200), TASK_CLASS VARCHAR2(200), TASK_GROUP VARCHAR2(200) DEFAULT 0, STATUS VARCHAR2(100) DEFAULT 'U', CREATE_TIME DATE DEFAULT SYSDATE, CREATER VARCHAR2(200), MODIFY_TIME DATE DEFAULT SYSDATE, MODIFIER VARCHAR2(200));-- ADD COMMENTS TO THE COLUMNSCOMMENT ON COLUMN QRTZ_TIMED_TASK.TASK_NAMEIS '任务名称';COMMENT ON COLUMN QRTZ_TIMED_TASK.TASK_DESCIS '任务描述';COMMENT ON COLUMN QRTZ_TIMED_TASK.TASK_EXPRESIS '任务执行表达式';COMMENT ON COLUMN QRTZ_TIMED_TASK.TASK_METHODIS '任务执行方法';COMMENT ON COLUMN QRTZ_TIMED_TASK.TASK_CLASSIS '任务接口路径';COMMENT ON COLUMN QRTZ_TIMED_TASK.TASK_GROUPIS '任务分组';COMMENT ON COLUMN QRTZ_TIMED_TASK.STATUSIS '任务状态';COMMENT ON COLUMN QRTZ_TIMED_TASK.CREATE_TIMEIS '创建时间';COMMENT ON COLUMN QRTZ_TIMED_TASK.CREATERIS '创建人员';COMMENT ON COLUMN QRTZ_TIMED_TASK.MODIFY_TIMEIS '修改时间';COMMENT ON COLUMN QRTZ_TIMED_TASK.MODIFIERIS '修改人员';-- CREATE/RECREATE PRIMARY, UNIQUE AND FOREIGN KEY CONSTRAINTSALTER TABLE QRTZ_TIMED_TASK ADD PRIMARY KEY (TASK_NAME) USING INDEX PCTFREE 10 INITRANS 2 MAXTRANS 255 STORAGE ( INITIAL 64K NEXT 1M MINEXTENTS 1 MAXEXTENTS UNLIMITED );-- CREATE INDEXCREATE INDEX IDX_TIMED_STATUS ON QRTZ_TIMED_TASK (STATUS) PCTFREE 10 INITRANS 2 MAXTRANS 255 STORAGE ( INITIAL 64K NEXT 1M MINEXTENTS 1 MAXEXTENTS UNLIMITED ); 任务参数配置表（QRTZ_TIMED_TASK_PARAM） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748-- CREATE TABLECREATE TABLE QRTZ_TIMED_TASK_PARAM( PARAM_KEY VARCHAR2(100) NOT NULL, PARAM_VALUE VARCHAR2(1000) NOT NULL, PARAM_TYPE VARCHAR2(100), PARAM_DESC VARCHAR2(1000), TASK_NAME VARCHAR2(200) NOT NULL, SORT_ID INTEGER DEFAULT 0);-- ADD COMMENTS TO THE COLUMNSCOMMENT ON COLUMN QRTZ_TIMED_TASK_PARAM.PARAM_KEYIS '参数代码';COMMENT ON COLUMN QRTZ_TIMED_TASK_PARAM.PARAM_VALUEIS '参数值';COMMENT ON COLUMN QRTZ_TIMED_TASK_PARAM.PARAM_TYPEIS '参数类型(不填默认为STRING类型)';COMMENT ON COLUMN QRTZ_TIMED_TASK_PARAM.PARAM_DESCIS '参数描述';COMMENT ON COLUMN QRTZ_TIMED_TASK_PARAM.TASK_NAMEIS '任务名称';COMMENT ON COLUMN QRTZ_TIMED_TASK_PARAM.SORT_IDIS '参数顺序';-- CREATE/RECREATE PRIMARY, UNIQUE AND FOREIGN KEY CONSTRAINTSALTER TABLE QRTZ_TIMED_TASK_PARAM ADD PRIMARY KEY (PARAM_KEY, TASK_NAME) USING INDEX PCTFREE 10 INITRANS 2 MAXTRANS 255 STORAGE ( INITIAL 64K NEXT 1M MINEXTENTS 1 MAXEXTENTS UNLIMITED );-- CREATE INDEXCREATE INDEX IDX_TIMED_TASK_PARAM_NAME ON QRTZ_TIMED_TASK_PARAM (TASK_NAME) PCTFREE 10 INITRANS 2 MAXTRANS 255 STORAGE ( INITIAL 64K NEXT 1M MINEXTENTS 1 MAXEXTENTS UNLIMITED ); 解释： QRTZ_TIMED_TASK.TASK_NAME : 任务名称，任务在调度工厂中的唯一标识，再配合参数表的配置，可实现一个接口，配置多个任务的功能 QRTZ_TIMED_TASK.STATUS : 表示任务状态，分为四种状态，U表示有效运行，即此任务在工程启动之后即可正常运行；E表示无效任务，即此任务无效，不会自动运行；D表示此任务要删除，调度工厂删除任务后，任务状态改为E；S表示将启动此任务，任务启动成功后，状态改为U QRTZ_TIMED_TASK.TASK_CLASS : 任务类路径，类必须加入到Spring上下文中，可支持配置接口，实现类，或者普通类。 QRTZ_TIMED_TASK_PARAM.SORT_ID : 参数顺序，默认使用LinkedHashMap存储，可通过参数顺序，实现通用接口，不同参数配置而实现一个接口多任务配置 4、开发任务接口任务的开发需按照以下标准开发： 任务接口需大写 I 开头，大写 SV 结尾 接口实现类需去掉接口的 I 开头，然后在 SV 后加 Impl 接口方法参数必须为Map 如： 12345678public interface IHelloSV &#123; void hello(); void hello(Map param);&#125;public class HelloSVImpl implements IHelloSV &#123; public void hello() &#123;&#125; public void hello(Map param) &#123;&#125;&#125; 5、任务配置在配置任务时，按照以下要求配置： 优先配置接口类 如需配置接口参数，在参数表中指定参数名，参数值，并指定task_name 参数配置时，参数类型可为空，默认使用Map\&lt;String, String> 接收，当指定参数类型时， 使用Map\&lt;String, Object> 接收，在代码中可使用强制类型转换 参数类型只支持基本类型，配置时使用全路径 如： 123456INSERT INTO QRTZ_TIMED_TASK (TASK_NAME, TASK_DESC, TASK_EXPRES, TASK_METHOD, TASK_CLASS, TASK_GROUP, STATUS)VALUES ('hello1', '测试1', '0/10 * * * * ?', 'hello', 'com.IHelloSV', 'hello', 'U');INSERT INTO QRTZ_TIMED_TASK (TASK_NAME, TASK_DESC, TASK_EXPRES, TASK_METHOD, TASK_CLASS, TASK_GROUP, STATUS)VALUES ('hello2', '测试2', '0/10 * * * * ?', 'hello', 'com.IHelloSV', 'hello', 'U');INSERT INTO QRTZ_TIMED_TASK_PARAM (PARAM_KEY, PARAM_VALUE, PARAM_TYPE, PARAM_DESC, TASK_NAME)VALUES ('name', 'admin', 'java.lang.String', '测试参数', 'hello2'); 6、quartz配置此项目默认采用quartz单机配置方式。具体配置可在发布包根目录下的quartz.properties中查看。如需使用集群配置，可在自己项目的classpath下新建quartz.properties文件进行配置。 7、任务动态更新 新增任务 在QRTZ_TIMED_TASK表中新增任务配置之后，将STATUS字段改为S即可。 删除任务 将QRTZ_TIMED_TASK表要删除的数据的STATUS字段改为D即可。 修改任务 任务只支持修改以下几项： QRTZ_TIMED_TASK.TASK_EXPRES,QRTZ_TIMED_TASK_PARAM.PARAM_KEY,QRTZ_TIMED_TASK_PARAM.PARAM_VALUE,QRTZ_TIMED_TASK_PARAM.PARAM_TYPE,QRTZ_TIMED_TASK_PARAM.PARAM_DESC, 注： 当只修改了QRTZ_TIMED_TASK时，只有TASK_EXPRES生效；修改了QRTZ_TIMED_TASK_PARAM配置之后，QRTZ_TIMED_TASK的其他配置都是可以修改的。 8、Quartz集群相关表介绍 qrtz_fired_triggers 触发器与任务关联表,存储与已触发的Trigger相关的状态信息，以及相联Job的执行信息。 qrtz_simple_triggers 存储简单的Trigger，包括重复次数，间隔，以及已触发的次数 qrtz_simprop_triggers qrtz_cron_triggers 存储CronTrigger，包括Cron表达式和时区信息 qrtz_blob_triggers Trigger作为Blob类型存储(用于Quartz用户用JDBC创建他们自己定制的Trigger类型，JobStore 并不知道如何存储实例的时候) qrtz_triggers 存储已配置的 Trigger的信息 qrtz_job_details 存储每一个已配置的Job的详细信息 qrtz_calendars 以Blob类型存储Quartz的Calendar日历信息， quartz可配置一个日历来指定一个时间范围 qrtz_paused_trigger_grps 存储已暂停的Trigger组的信息 qrtz_locks 存储程序的非观锁的信息(假如使用了悲观锁) qrtz_scheduler_state 存储少量的有关 Scheduler的状态信息，和别的 Scheduler 实例(假如是用于一个集群中) 9、quartz时间表达式时间格式：s&gt;m&gt;h&gt;d&gt;m&gt;w(?)&gt;y(?) 对应：秒&gt;分&gt;小时&gt;日&gt;月&gt;周&gt;年 Cron表达式的符号、格式 特殊字符 含义 ＊ 匹配所有的值。如：＊在分钟的字段域里表示 每分钟 ? 只在日期域和星期域中使用。它被用来指定“非明确的值” - 指定一个范围。如：“10-12”在小时域意味着“在10点到12点之间” , 指定几个可选值。如：“MON,WED,FRI”在星期域里表示“星期一、星期三、星期五” / 指定增量。如：“0/15”在秒域表示在每分钟的第0秒开始，每15秒执行一次。符号“*”在“/”前面等价于0在“/”前面 L 表示day-of-month和day-of-week域，但在两个字段中的意思不同，例如day-of-month域中表示一个月的最后一天。如果在day-of-week域表示“7”或者“SAT”，如果在day-of-week域中前面加上数字，表示一个月的最后几天，例如“6L”就表示一个月的最后一个星期五 W 只允许日期域出现。这个字符用于指定日期的最近工作日。例如：如果你在日期域中写“15W”，表示：这个月15号最近的工作日。所以，如果15号是周六，则任务会在14号触发。如果15刚好是周日，则任务会在周一也就是16号触发。如果是在日期域填写“1W”即使1号是周六，那么任务也只会在下周一，也就是3号触发，“W”字符指定的最近工作日是不能跨月份的。字符“W”只能配合一个单独的数值使用，不能够是一个数字段，如：1-15W是错误的 LW L和W可以在日期域中联合使用，LW表示这个月最后一周的工作日 # 只允许在星期域中出现。这个字符用于指定本月的某某天。例如：“6#3”表示本月第三周的星期五（6表示星期五，3表示第三周）。“2#1”表示本月第一周的星期一。“4#5”表示第五周的星期三 C 允许在日期域和星期域出现。这个字符依靠一个指定的“日历”。也就是说这个表达式的值依赖于相关的“日历”的计算结果，如果没有“日历”关联，则等价于所有包含的“日历”。如：日期域是“5C”表示关联“日历”中第一天，或者这个月开始的第一天的后5天。星期域是“1C”表示关联“日历”中第一天，或者星期的第一天的后1天，也就是周日的后一天（周一） Cron表达式特殊字符意义对应表 字段 允许值 允许的特殊字符 秒 0-59 , - * / 分 0-59 , - * / 小时 0-23 , - * / 月内日期 1-31 , - * ? / L W C 月 1-12或JAN-DEC , - * / 周内日期 1-7或SUN-SAT , - * ? / L C # 年（可选） 留空，1970-2099 , - * / 时间表达式在线生成器：http://cron.qqe2.com/]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot启动原理分析]]></title>
    <url>%2F2017%2F12%2F09%2FSpringBoot%E5%90%AF%E5%8A%A8%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言用了差不多两年的SpringBoot了，可以说对SpringBoot已经很熟了，但是仔细一想SpringBoot的启动流程，还是让自己有点懵逼，不得不说是自己工作和学习的失误，所以以此文对SpringBoot的启动流程略作记录。 此文的SpringBoot启动流程分析是基于SpringBoot 1.x的，SpringBoot 2.x的启动流程与1.x的略有不同，后续再进行补充分析。 正文核心注解@SpringBootApplication每个SpringBoot应用，都有一个入口类，标注@SpringBootApplication注解。 123456@SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 点开@SpringBootApplication的源码，可以看到这个注解其实包含了@SpringBootConfiguration，@EnableAutoConfiguration，@ComponentScan三个注解。 下面对这三个注解简单解释解释。 @SpringBootConfiguration 对于这个注解不做解释，将这个注解点进去，发现还有@Configuration注解，对于@Configuration注解，用过Spring或SpringBoot的基本上都不陌生，标注了@Configuration的类相当于Spring中的配置XML，不过SpringBoot社区推荐使用JavaConfig，所以@Configuration就构建出了一个基础JavaConfig的Ioc容器。 @EnableAutoConfiguration Spring中有很多Enable*的注解，表示开启某项东西，如@EnableSchuduling。所以看这个注解的名字就知道是开启自动配置。这是一个复合注解，其中最主要的还是@Import，借助于EnableAutoConfigurationImportSelector，将所有符合自动配置条件的Bean加载到Ioc容器里。 SpringBoot加载自动配置的方式有两种（目前我知道的）： 在classpath下新建META-INF/spring.factories文件，将标注了@Configuration的类的全路径配置到此文件中，如： 123org.springframework.boot.autoconfigure.EnableAutoConfiguration=\ com.quartz.config.QuartzBeanConfiguration,\ com.quartz.config.QuartzAutoConfiguration 在启动时，通过SpringFactoriesLoader工具类，将所有META-INF目录下的spring.factories文件中的配置类加载到Ioc容器里。 使用@Import，将配置类加载到Ioc容器里。 123456@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(&#123;QuartzAutoConfiguration.class&#125;)public @interface EnableQuartz &#123;&#125; 使用@Import导入的类必须满足以下任意一个要求： 导入的类使用@Configuration进行标注 导入的类中至少有一个使用@Bean标准的方法 导入的类实现了ImportSelector接口 导入的类实现了ImportBeanDefinitionRegistrar接口 @ComponentScan 看到这个注解，可以回想一下以前使用SpringMVC时，xml配置文件里的一个标签 1&lt;context:component-scan base-package="" /&gt; 不过这个注解一般不需要手动指定扫描的包路径，它默认会从标注了@ComponentScan的类所在包往下查找，将标注了如@Component，@Service等Bean加载到Ioc容器里。 自动配置核心类SpringFactoriesLoader上面在说@EnableAutoConfiguration的时候有说META-INF下的spring.factories文件，那么这个文件是怎么被spring加载到的呢，其实就是SpringFactoriesLoader类。 SpringFactoriesLoader是一个供Spring内部使用的通用工厂装载器，SpringFactoriesLoader里有两个方法， 1234// 加载工厂类并实例化public static &lt;T&gt; List&lt;T&gt; loadFactories(Class&lt;T&gt; factoryClass, ClassLoader classLoader) &#123;&#125;// 加载工厂类的类名public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader) &#123;&#125; 在这个SpringBoot应用启动过程中，SpringFactoriesLoader做了以下几件事： 加载所有META-INF/spring.factories中的Initializer 加载所有META-INF/spring.factories中的Listener 加载EnvironmentPostProcessor（允许在Spring应用构建之前定制环境配置） 接下来加载Properties和YAML的PropertySourceLoader（针对SpringBoot的两种配置文件的加载器） 各种异常情况的FailureAnalyzer（异常解释器） 加载SpringBoot内部实现的各种AutoConfiguration 模板引擎TemplateAvailabilityProvider（如Freemarker、Thymeleaf、Jsp、Velocity等） 总得来说，SpringFactoriesLoader和@EnableAutoConfiguration配合起来，整体功能就是查找spring.factories文件，加载自动配置类。 整体启动流程在我们执行入口类的main方法之后，运行SpringApplication.run，后面new了一个SpringApplication对象，然后执行它的run方法。 123public static ConfigurableApplicationContext run(Object[] sources, String[] args) &#123; return new SpringApplication(sources).run(args);&#125; 初始化SpringApplication类创建一个SpringApplication对象时，会调用它自己的initialize方法 1234567891011121314private void initialize(Object[] sources) &#123; if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; // 根据标志类javax.servlet.Servlet,org.springframework.web.context.ConfigurableWebApplicationContext是否存在，判断是否是web环境 this.webEnvironment = deduceWebEnvironment(); // 通过SpringFactoriesLoader，获取到所有META-INF/spring.factories中的ApplicationContextInitializer，并实例化 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); // 通过SpringFactoriesLoader，获取到所有META-INF/spring.factories中的ApplicationListener，并实例化 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); // 获取执行当前main方法的类，也就是启动类 this.mainApplicationClass = deduceMainApplicationClass();&#125; 注 ： 各方法内部执行逻辑就不做说明了，比较简单，需要的读者可自行点进源码查看 执行核心run方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public ConfigurableApplicationContext run(String... args) &#123; // 启动任务执行的时间监听器 StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; // 设置系统java.awt.headless属性，确定是否开启headless模式(默认开启headless模式) configureHeadlessProperty(); // 通过SpringFactoriesLoader，获取到所有META-INF/spring.factories下的SpringApplicationRunListeners并实例化 SpringApplicationRunListeners listeners = getRunListeners(args); // 开始广播启动 listeners.started(); try &#123; // 创建SpringBoot默认启动参数对象 ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 根据启动参数创建并配置Environment(所有有效的配置，如Profile)，并遍历所有的listeners，广播启动环境已准备 ConfigurableEnvironment environment = prepareEnvironment(listeners,applicationArguments); // 打印启动图案 Banner printedBanner = printBanner(environment); // 根据标志类(上面有提到过)，创建对应类型的ApplicationContext context = createApplicationContext(); // 创建异常解析器(当启动失败时，由此解析器处理失败结果) analyzers = new FailureAnalyzers(context); // 准备Spring上下文环境 // 在这个方法中，主要完成了以下几件事： // 1、设置SpringBoot的环境配置(Environment) // 2、注册Spring Bean名称的序列化器BeanNameGenerator，并设置资源加载器ResourceLoader // 3、加载ApplicationContextInitializer初始化器，并进行初始化 // 4、统一将上面的Environment、BeanNameGenerator、ResourceLoader使用默认的Bean注册器进行注册 prepareContext(context, environment, listeners, applicationArguments,printedBanner); // 注册一个关闭Spring容器的钩子 refreshContext(context); // 获取当前所有ApplicationRunner和CommandLineRunner接口的实现类，执行其run方法 // ApplicationRunner和CommandLineRunner功能基本一样，在Spring容器启动完成时执行，唯一不同的是ApplicationRunner的run方法入参是ApplicationArguments，而CommandLineRunner是String数组 afterRefresh(context, applicationArguments); // 通知所有listener，Spring容器启动完成 listeners.finished(context, null); // 停止时间监听器 stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; return context; &#125; catch (Throwable ex) &#123; // 启动有异常时，调用异常解析器解析异常信息，根据异常级别，判断是否退出Spring容器 handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; run方法整体执行流程总结———————————————————未完待续—————————————————]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker高级应用]]></title>
    <url>%2F2017%2F10%2F11%2FDocker%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[资源隔离Linux内核从2.4.19开始引入namespace的概念，其目的是将某个特定的全局系统资源（global system resource）通过抽象方法使得namespace中的进程看起来拥有它们自己的隔离的全局系统资源实例。 namespace 系统调用参数 隔离内容 在容器语境下的隔离效果 UTS CLONE_NEWUTS 主机名和域名 每个容器可以有自己的hostname和domainname IPC CLONE_NEWIPC 信号量、消息队列和共享内存 每个容器有其自己的System V IPC和POSIX消息队列文件系统，因此，只有在同一个IPC的进程之间才能互相通信 PID CLONE_NEWPID 进程编号 每个PID中的namespace中的进程可以有其独立的PID；每个容器可以有其PID为1的root进程；也使得容器可以在不同的host之间迁移，因为namespace中的进程ID和host无关了。这也使得容器中的每个进程有两个PID：容器中的PID和host上的PID Network CLONE_NEWNET 网络设备、网络栈、端口等 每个容器都有其独立的网络设备，IP地址，IP路由表，/proc/net目录，端口号等。这也使得多个容器内的同一个应用都绑定在各自容器的80端口上 Mount CLONE_NEWNS 挂载点（文件系统） 每个容器能看到不同的文件系统层次结构 User CLONE_NEWUSER 用户和组ID空间 在User中的进程的用户和组ID可以和在host上不通。每个container可以有不同的user和group id；一个host上的非特权用户可以成为User中的特权用户 Docker的资源隔离也是通过这六种方式实现的，在容器启动时，Docker会创建这六种namespace实例，然后把容器中的所有进程放到这些namespace中，使得Docker容器中只能看到隔离的系统资源。 网络模式docker目前支持四种网络工作的方式，分别为host，container，none，bridge。下面简单介绍下这几种网络模式。 host模式 Docker使用了Linux的Namespaces技术来进行资源隔离，如网卡、路由、进程等。如果启动容器的时候使用host模式，那么容器不会自己去创建一个独立的Network Namespace，而是与主机共用一个Network Namespace。容器也不会虚拟出自己的网卡、IP等，而是使用宿主机的IP和端口。 container模式 container模式指定创建的新的容器和已经存在的一个容器共享一个Network Namespace。container模式通过-net=container:NAME_OR_ID指定共享的容器。 none模式 在这种模式下，容器拥有自己的Network Namespace，但是不做任何网络配置，需要我们自己给容器添加网卡、IP等。 bridge模式 bridge模式是Docker默认的网络设置，此模式会为每一个容器分配Network Namespace、设置IP等，并将一个主机上的Docker容器连接到虚拟网桥上，实现容器和容器的主机的互连。​]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lombok常用注解]]></title>
    <url>%2F2017%2F09%2F07%2FLombok%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Project Lombok is a java library that automatically plugs into your editor and build tools, spicing up your java.Never write another getter or equals method again. Early access to future java features such as val, and much more. 这是lombok官网的解释，大概意思是说Lombok项目是一个java库，会自动处理代码的编译，比如你不用写getter方法，它就会自动帮你实现。 下面简单介绍一些在开发中常用的注解。 Lombok常用注解@Getter可标注到类或属性上，标注到类上表示此类中的所有属性生成getter方法，标注到某个属性上，表示此属性生成getter方法。 @Setter和@Getter类似，可标注到类或属性上，标注到类上表示此类中的所有属性生成setter方法，标注到某个属性上，表示此属性生成setter方法。 @ToString只能标注到类上，相当于是重写此类的toString方法。 @EqualsAndHashCode只能标注到类上，相当于是重写此类的hashCode和equals方法。 @NoArgsConstructor只能标注到类上，生成无参的构造方法。 @Data只能标注到类上，综合@Getter，@Setter，@ToString，@EqualsAndHashCode，@NoArgsConstructor五个注解的功能。 @Value只能标注到类上，综合@Getter，@Setter，@ToString，@EqualsAndHashCode，@NoArgsConstructor五个注解的功能，和@Data不同的是，默认将所有属性定义成final的，也就是只会生成getter方法，不会生成setter方法，如果不需要final，则给属性加上@NonFinal注解即可。 @AllArgsConstructor只能标注到类上，生成包含所有属性的构造方法，使用此注解时建议和@NoArgsConstructor结合使用，否则此类将没有无参的构造方法。 @RequiredArgsConstructor只能标注到类上，会生成一个包含常量，和标识了@NotNull的变量 的构造方法。生成的构造方法是private，如何想要对外提供使用可以使用staticName选项生成一个static方法。如： 1234@RequiredArgsConstructor(staticName = "passwd")public class User &#123; @NonNull private String password;&#125; 上面代码编译后对应下面的代码 12345678public class User &#123; private User(String password) &#123; this.password = password; &#125; public static User passwd(String password) &#123; return new User(password); &#125;&#125; @Builder只能标注到类上，将生成类的一个当前流程的一种链式构造工厂，如下： 1User buildUser = User.builder().password("haha").username("gaga").build(); 可配合@Singular注解使用，@Singular注解使用在jdk内部集合类型的属性，Map类型的属性以及Guava的com.google.common.collect 的属性上。例如 未标注@Singular的属性，一般setter时，会直接覆盖原来的引用，标注了@Singular的属性，集合属性支持添加操作，会在属性原来的基础上增加。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public static class UserBuilder &#123; private String username; private String password; private ArrayList&lt;String&gt; projects; UserBuilder() &#123; &#125; public User.UserBuilder username(String username) &#123; this.username = username; return this; &#125; public User.UserBuilder password(String password) &#123; this.password = password; return this; &#125; public User.UserBuilder project(String project) &#123; if (this.projects == null) this.projects = new ArrayList&lt;String&gt;(); this.projects.add(project); return this; &#125; public User.UserBuilder projects(Collection&lt;? extends String&gt; projects) &#123; if (this.projects == null) this.projects = new ArrayList&lt;String&gt;(); this.projects.addAll(projects); return this; &#125; public User.UserBuilder clearProjects() &#123; if (this.projects != null) this.projects.clear(); return this; &#125; public User build() &#123; Set&lt;String&gt; projects; switch (this.projects == null ? 0 : this.projects.size()) &#123; case 0: projects = java.util.Collections.emptySet(); break; case 1: projects = java.util.Collections.singleton(this.projects.get(0)); break; default: projects = new java.util.LinkedHashSet&lt;String&gt;(this.projects.size() &lt; 1073741824 ? 1 + this.projects.size() + (this.projects.size() - 3) / 3 : Integer.MAX_VALUE); projects.addAll(this.projects); projects = java.util.Collections.unmodifiableSet(projects); &#125; return new User(username, password, projects); &#125; public String toString() &#123; return "User.UserBuilder(username=" + this.username + ", password=" + this.password + ", projects=" + this.projects + ")"; &#125; &#125; @Accessors可标注在类或属性上，当然最实用的功能还是标注到类上。 标注到类上，chain属性设置为true时，类的所有属性的setter方法返回值将为this，用来支持setter方法的链式写法。如： 1new User().setPassword("gaga").setUsername("haha"); fluent属性设置为true时，类的所有getter，setter方法将省略get和set前缀，获取属性值直接使用属性名相同的无参方法，设置属性值使用属性名相同的有参方法，并且返回值为this。如： 123User user = new User().password("gaga").username("haha");String password = user.password();String username = user.username(); 标注到属性上，使用prefix设置需要省略的属性生成getter，setter方法时的前缀，且属性必须为驼峰式命名。 如： 1234@Accessors(prefix = "a")@Getter@Setterprivate String aUsername = "gaga"; 编译之后为 123456public String getUsername() &#123; return aUsername;&#125;public void setUsername(String aUsername) &#123; this.aUsername = aUsername;&#125; 以上一些常用的lombok的用法介绍完了，在日常的开发或者自己的练习中，使用lombok并结合各版本的jdk特性，将更大的提高开发效率，提高开发质量。]]></content>
      <categories>
        <category>开发工具框架</category>
      </categories>
      <tags>
        <tag>开发工具框架</tag>
        <tag>Lombok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile]]></title>
    <url>%2F2017%2F06%2F18%2FDockerfile%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Dockerfile是一个文本格式的配置文件，用户可以使用Dockerfile快速创建自定义的镜像。 基本结构Dockerfile由一行行命令语句组成，并且支持以#开头的注释行。 一般Dockerfile文件分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令。 1234567891011121314# This dockerfile uses the ubuntu image# VERSION 2 - EDITION 1# Author:docker_user# Command format: Instruction [arguments / command] ..# 第一行必须制定基于的基础镜像FROM ubuntu# 维护者信息MAINTAINER docker_user docker_user@email.com# 镜像的操作指令RUN echo "deb http://archive.ubuntu.com/ubuntu/ raring main universe" &gt;&gt; /etc/apt/sources.listRUN apt-get update &amp;&amp; apt-get install -y nginxRUN echo "\ndaemon off;" &gt;&gt; /etc/nginx/nginx.conf# 容器启动时执行指令CMD /usr/sbin/nginx Dockerfile文件编写时，一开始必须指明所基于的镜像名称，接下来一般会说明维护者信息 后面则是镜像操作指令，例如RUN指令，镜像增加新的一层，并提交。最后是CMD指令，来指定运行容器时的操作命令。 以下有两个摘自书上的Dockerfile例子： 123456# Ngnix# # VERSION 0.0.1FROM ubuntuMAINTAINER Victor Vieux &lt;victor@docker.com&gt;RUN apt-get update &amp;&amp; apt-get install -y inotify-tools nginx apache2 openssh-server 此Dockerfile文件是在ubuntu父镜像基础上安装inotify-tools、nginx、apache2、openssh-server软件，从而创建一个新的Nginx镜像 注 ：inotify-tools是为linux下inotify文件监控工具提供的一套c的开发接口库函数，同时还提供了一系列的命令行工具，这些工具可以用来监控文件系统的事件。 12345678910111213# Firefox over VNC# # VERSION 0.3FROM ubuntu# Install vnc, xvfb in order to reate a 'fake' display and firefoxRUN apt-get update &amp;&amp; apt-get install -y xllvnc xvfb firefoxRUN mkdir /.vnc# Setup a passwordRUN xllvnc -storepasswd 1234 ~/.vnc/passwd# Autostart firefox (might not be the best way, but it does the trick)RUN bash -c 'echo "firefox" &gt;&gt; /.bashrc'EXPOSE 5900CMD ["xllvnc", "-forever", "-usepw", "-create"] 此Dockerfile基于ubuntu父镜像，安装filefox和vnc软件，启动后，用户可以通过5900端口通过vnc方式使用firefox。 指令指令的一般格式为INSTRUCTION arguments，指令包括FROM、MAINTAINER、RUN等。 Dockerfile指令说明 指令 说明 FROM 指定所创建镜像的基础镜像 MAINTAINER 指定维护者信息 RUN 运行命令 CMD 指定启动容器时默认执行的命令 LABEL 指定生成镜像的元数据标签信息 EXPOSE 声明镜像内服务所监听的端口 ENV 指定容器环境变量 ADD 复制指定的 \&lt;src> 路径下的内容到容器中的 \&lt;dest> 路径下，\&lt;src> 可以为URL；如果为tar文件，会自动解压到 \&lt;dest> 路径下 COPY 复制本地主机的 \&lt;src> 路径下的内容到镜像中的 \&lt;dest> 路径下；一般情况下推荐使用COPY而不是ADD ENTRYPOINT 指定镜像的默认入口 VOLUME 创建数据卷挂载点 USER 指定运行容器时的用户名或UID WORKDIR 配置工作目录 ARG 指定镜像内使用的参数 （例如版本号信息等） ONBUILD 配置当所创建的镜像作为其他镜像的基础镜像时，所执行的创建操作指令 STOPSIGNAL 容器退出的信号值 HEALTHCHECK 如何进行健康检查 SHELL 指定使用shell时的默认shell类型 FROM1格式为 FROM &lt;image&gt; 或FROM&lt;image&gt;:&lt;tag&gt; 第一条指令必须为FROM指令。并且，如果在同一个Dockerfile中创建多个镜像时，可以使用多个FROM指令（每个镜像一次）。 MAINTAINER1格式为 MAINTAINER &lt;name&gt;, 指定维护者信息 RUN1格式为 RUN &lt;command&gt; 或 RUN ["executable", "param1", "param2"] RUN 将在shell终端中运行命令，即 /bin/sh -c RUN [“executable”, “param1”, “param2”]则使用exec执行。 指定使用其他终端可以通过第二种方式实现，例如 RUN [“/bin/bash”, “-c”, “echo hello”]。 每条RUN指令将在当前镜像基础上执行指令命令，并提交为新的镜像。当命令较长时可以用 \ 来换行。 CMD支持三种格式 使用exec执行，推荐方式 1CMD ["executable", "param1", "param2"] 在/bin/sh中执行，提供给需要交互的应用 1CMD command param1 param2 提供给ENTRYPOINT的默认参数 1CMD ["param1", "param2"] 指定启动容器时执行的命令，每个Dockerfile只能有一条CMD命令。如果指定了多条命令，只有最后一条会被执行。 如果用户启动容器时指定了运行的命令，则会覆盖掉CMD指定的命令。 EXPOSE1格式为 EXPOSE &lt;port&gt; [&lt;port&gt;...] 例如：EXPOSE 22 80 8443 就是告诉Docker服务器容器暴露的端口号，供互联系统使用。在启动容器时需要通过-P或者-p来指定端口映射。 ENV1格式为 ENV &lt;key&gt; &lt;value&gt; 指定一个环境变量，会被后续RUN指令使用，并在容器运行时保持。例如： 1234ENV PG_MAJOR 9.3ENV PG_VERSION 9.3.4RUN curl -SL http://example.com/postgres-$PG_VERSION.tar.xz | tar -xJC /usr/src/postgress &amp;&amp; ...ENV PATH /usr/local/postgres-$PG_MAJOR/bin:$PATH ADD1格式为 ADD &lt;src&gt; &lt;dest&gt; 该命令将复制指定的到容器中的。其中可以是Dockerfile所在目录的一个相对路径（文件或目录）；也可以是一个URL；还可以是一个tar文件（自动解压为目录）。 COPY1格式为 COPY &lt;src&gt; &lt;dest&gt; 复制本地主机的（为Dockerfile所在目录的相对路径，文件或目录）为容器中的。目标路径不存在时，会自动创建。 当使用本地目录为源目录时，推荐使用COPY ENTRYPOINT 使用exec执行，推荐方式 1ENTRYPOINT ["executable", "param1", "param2"] 在shell中执行 1ENTRYPOINT command param1 param2 配置容器启动后执行的命令，并且不可被docker run提供的参数覆盖 每个Dockerfile中只能有一个ENTRYPOINT，当制定多个ENTRYPOINT时，只有最后一个生效。 VOLUME1格式为 VOLUME ["/data"] 创建一个可以从本地主机或其他容器挂载的挂载点，一般用来存放数据库和需要保持的数据等。 USER1格式为 USER daemon 指定运行容器时的用户名或UID，后续的RUN也会使用指定的用户。 当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户，例如： 1RUN groupadd -r postgres &amp;&amp; useradd -r -g postgres postgres 要临时获取管理员权限可以使用gosu，不推荐sudo WORKDIR1格式为 WORKDIR /path/to/workdir 为后续RUN、CMD、ENTRYPOINT指令配置工作目录。 可以使用多个WORKDIR指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。例如: 1234WORKDIR /aWORKDIR bWORKDIR cRUN pwd 上面指令最终结果为：/a/b/c ONBUILD1格式为 ONBUILD [INSTRUCTION] 配置当所创建的镜像作为其他新创建镜像的基础镜像时，所执行的操作指令。例如： 1234[...]ONBUILD ADD . /app/srcONBUILD RUN /usr/local/bin/python-build --dir /app/src[...] Dockerfile使用上面的内容创建了镜像image-A，如果基于image-A创建新的镜像时，新的Dockerfile中使用FROM image-A指定基础镜像时，会自动执行ONBUILD指令内容，等价于在Dockerfile后面添加了两条指令，如： 1234FROM image-A# Automatically run the followingADD . /app/srcRUN /usr/local/bin/python-build --dir /app/src 使用ONBUILD指令的镜像，推荐在标签中注明，例如ruby:1.9-onbuild。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门]]></title>
    <url>%2F2017%2F06%2F16%2FDocker%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[一直听说虚拟化、Docker这些概念，但是一直没有机会，刚好公司项目要使用Docker部署，公司也没有这方面的人员了解，花几天时间突击一下这方面知识。 Docker简介Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。 Docker的主要目标是“Build,Ship and Run Any App, Anywhere”，即通过对应用组件的封装（Packaging）、分发（Distribution）、部署（Deployment）、运行（Runtime）等生命周期的管理，达到应用组件级别的“一次封装，到处运行”（有点类似于java）。这里的应用组件，即可以是一个Web应用，也可以是一套数据库服务，甚至是一个操作系统或者编译器。 Docker的应用场景 Web 应用的自动化打包和发布。 自动化测试和持续集成、发布 在服务型环境中部署和调整数据库或其他的后台应用 从头编译或者扩展现有的OpenShift或Cloud Foundry平台来搭建自己的PaaS环境 Docker的优点 简化程序 Docker让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的Linux机器上，便可以实现虚拟化。Docker改变了虚拟化的方式，使开发者可以直接将自己的成果放入Docker中进行管理。过去需要数天乃至数周的任务，在Docker容器的处理下，只需要数秒就能完成。 避免选择恐惧症 Docker镜像中包含了运行环境和配置，所以Docker可以简化部署多种应用实例工作。比如Web应用、后台应用、数据库应用、大数据应用比如Hadoop集群、消息队列等等都可以打包成一个镜像部署。 节省开支 云计算时代的到来，使开发者不必为了追求效果而配置高额的硬件，Docker改变了高性能必然高价格的思维定势。Docker与云的结合，让云空间得到更充分的利用，不仅解决了硬件管理的问题，也改变了虚拟化的方式。 Centos的Docker安装与启动 检查Linux版本 1[docker@localhost ~]$ uname -r Docker要求Centos系统的内核版本高于3.10 安装Docker 切换到root用户，更新系统 1[root@localhost ~]# yum update 安装Docker 1[root@localhost ~]# yum -y install docker Docker软件包和依赖包已经包含在默认的Centos-Extras软件源里了。 如果这种方式不能安装，也可使用下面的命令进行安装 1[root@localhost ~]# curl -fsSL https://get.docker.com/ | sh 执行这个脚本后会添加docker.repo源并安装Docker 注：若安装失败，重新使用上面命令安装时有时会报错，只需要去家目录下的.docker目录中将docker的相关文件删除，然后重新执行命令下载即可。 启动Docker服务 1[root@localhost ~]# service docker start 测试 1[docker@localhost ~]$ docker run hello-world 由于本地没有hello-world这个镜像，所以会下载一个hello-world的镜像，并在容器中运行 Docker的基本使用 查看Docker常用命令 1[docker@localhost ~]$ docker 或者 1[docker@localhost ~]$ docker --help 如我们需要查看其中某个命令的使用方法，可使用以下命令 1[docker@localhost ~]$ docker run --help 运行一个web应用 我们在Docker容器中运行一个Python Flask应用来运行一个web应用 1[docker@localhost ~]$ docker run -d -P training/webapp python app.py 我们先来看看之前执行docker run –help命令后的结果吧 1docker run [OPTIONS] IMAGE [COMMAND] [ARG...] OPTIONS: 代表run命令的一些参数 IMAGE: 镜像名 COMMAND: 运行镜像之后要执行的命令 ARG…: 命令需要的一些参数 好了，我们现在来看看刚刚我们运行一个web应用的命令 -d, –detach=false Run container in background and print container ID 让容器在后台运行，默认是关闭的 -P, –publish-all=false Publish all exposed ports to random ports 让容器内部使用的网络端口映射到我们使用的主机上，默认是关闭的 注意: 我们这里用的是大写的-P 小写的-p手动将容器端口映射到宿主机上的端口，如 1[docker@localhost ~]$ docker run -d -p 5000:5000 training/webapp python app.py 查看WEB应用容器查看正在运行的容器123[docker@localhost ~]$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf5d5071807a8 training/webapp "python app.py" 13 seconds ago Up 12 seconds 0.0.0.0:32768-&gt;5000/tcp prickly_davinci 查看所有已构建的容器1docker ps -a 包括正在运行，已停止的等多个容器。 结果中有容器ID，镜像名，端口，容器名等信息，其中端口显示了prickly_davinci容器端口的映射情况，此时映射的端口是容器自动做的映射，如果我们运行时没使用-P，而是使用-p手动映射，此处则显示手动指定的端口。其次容器名称此处为容器自动指定的，我们可以通过–name来手动指定，如 1[docker@localhost ~]$ docker run -d -p 5000:5000 --name webapp training/webapp python app.py 上面默认都是绑定tcp端口，如果要绑定UDP端口，可以在端口后面加上/udp 1[docker@localhost ~]$ docker run -d -p 5000:5000/udp --name webapp training/webapp python app.py 查看容器端口映射 使用容器ID查看容器端口映射情况 12[docker@localhost ~]$ docker port f5d5071807a85000/tcp -&gt; 0.0.0.0:32768 使用容器名称查看端口映射情况 12[docker@localhost ~]$ docker port prickly_davinci5000/tcp -&gt; 0.0.0.0:32768 查看具体某个端口的映射情况 12[docker@localhost docker]$ docker port tomcat 80800.0.0.0:8080 接下来凡是使用容器标识操作的都使用容器名称，并且容器ID也支持相同的命令操 查看WEB应用程序日志1[docker@localhost ~]$ docker logs -f modest_banach -f: 让docker logs像使用tail -f一样来输出容器内部的标准输出 查看WEB应用程序容器的进程1[docker@localhost ~]$ docker top modest_banach 检查WEB应用程序1[docker@localhost ~]$ docker inspect modest_banach 停止WEB应用程序1[docker@localhost ~]$ docker stop modest_banach 启动WEB应用容器1[docker@localhost ~]$ docker start modest_banach 重启WEB应用容器1[docker@localhost ~]$ docker restart modest_banach 注：正在运行的容器我们可以使用restart来重启 移除WEB应用容器1[docker@localhost ~]$ docker rm modest_banach 注：移除容器时，容器必须是停止状态。 Docker镜像的使用查看本地镜像列表12[docker@localhost ~]$ docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE 各个选项说明： REPOSITORY: 表示镜像的仓库源 TAG: 镜像的标签 IMAGE ID: 镜像ID CREATED: 镜像创建时间 SIZE: 镜像大小 同一个仓库源可以有多个TAG，代表这个仓库源的不同个版本，如ubuntu仓库源里，有15.10,14.04等多个不同的版本，我们可以使用REPOSITORY:TAG来定义不同的镜像，如 1[docker@localhost ~]$ docker run -t -i ubuntu:15.10 /bin/bash 如果不指定镜像的版本标签，docker将默认使用latest镜像 获取一个新的镜像1[docker@localhost ~]$ docker pull ubuntu:15.10 查找镜像12[docker@localhost ~]$ docker search httpdNAME DESCRIPTION STARS OFFICIAL AUTOMATED NAME: 镜像仓库源的名称 DESCRIPTION: 镜像的描述 OFFICIAL: 是否是docker官方发布 拖取镜像1[docker@localhost ~]$ docker pull httpd 运行镜像1[docker@localhost ~]$ docker run httpd 自定义镜像创建镜像当我们从docker镜像仓库中下载的镜像不能满足我们的需求时，我们可以通过以下两种方式对镜像进行更改： 1、从已经创建的容器中更新镜像，并且提交这个镜像 2、使用Dockerfile指令来创建一个新的镜像 更新镜像在更新镜像之前，我们先用以下命令启动容器，在容器中使用apt-get update命令更新，完成操作后使用exit退出容器。 12[docker@localhost ~]$ docker run -t -i ubuntu:15.10 /bin/bashroot@2d60a31b8bdf:/# apt-get update 提交容器副本12[docker@localhost ~]$ docker commit -m="has update" -a="ubuntu/update" 2d60a31b8bdf ubuntu:v2ea547a1aa6de52e24092ff3ca13ae7ae58cd35123e2e58e6f3d784208af7ef5e -m: 提交的描述信息 -a: 指定镜像作者 2d60a31b8bdf: 容器ID runoob/ubuntu:v2: 指定要创建的目标镜像名 构建镜像创建Dockerfile，使用docker build命令来创建一个新的镜像 1234567891011[docker@localhost docker]$ cat DockerfileFROM centos:6.7MAINTAINER Fisher "artislong@haha.com"RUN /bin/echo 'root:123456' |chpasswdRUN useradd dockerRUN /bin/echo 'docker:123456' |chpasswdRUN /bin/echo -e "LANG=\"en_US.UTF-8\"" &gt;/etc/default/localEXPOSE 22EXPOSE 80CMD /usr/sbin/sshd -D Dockerfile是一个文本格式的配置文件，它由一行行命令语句（指令）组成，并且支持以#开头的注释行 每个指令都会在镜像上创建一个新的层，每个指令的前缀都必须大写。 第一条FROM，指定使用哪个镜像源 RUN指令告诉docker在镜像内执行命令，安装了什么。。。 然后我们通过Dockerfile文件来构建一个镜像 1[docker@localhost docker]$ docker build -t runoob/centos:6.7 . 千万不要忽略最后面的 “.”，它表示使用当前目录下的Dockerfile文件 -t: 指定要创建的目标镜像名 ​ 我们可以使用新的镜像来创建容器 123[docker@localhost docker]$ docker run -t -i runoob/centos:6.7 /bin/bash[root@ebd742bf9af0 /]# id dockeruid=500(docker) gid=500(docker) groups=500(docker) 从上面看到新镜像已经包含了我们创建的用户docker 设置镜像标签1[docker@localhost docker]$ docker tag f38a8f197ee4 runoob/centos:dev docker tag 镜像ID，镜像源名和新的标签名 Docker安装Nginx创建Nginx目录，用于存放后面相关文件1[docker@localhost ~]$ mkdir -p ~/nginx/www ~/nginx/logs ~/nginx/conf www目录将映射为nginx容器配置的虚拟目录 logs目录将映射为nginx容器的日志目录 conf目录里的配置文件将映射为nginx容器的配置文件 查找Docker Hub上的nginx镜像1[docker@localhost nginx]$ docker search nginx 拉取官方nginx镜像1[docker@localhost nginx]$ docker pull nginx 查看nginx本地镜像1[docker@localhost nginx]$ docker images nginx 使用nginx镜像运行容器1[docker@localhost nginx]$ docker run -i -t -d -p 80:8081 --name nginx -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -d nginx -p 80:8081: 将容器的80端口映射到宿主机的8081端口 -name nginx: 将容器命名为nginx -v $PWD/www:/www: 将主机中当前目录下的www目录挂载到容器的/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf: 将主机中当前目录下的nginx.conf挂载到容器的/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs: 将主机中当前目录下的logs挂载到容器的/wwwlogs 查看容器启动情况1[docker@localhost nginx]$ docker ps 通过浏览器访问访问路径为: http://主机ip:8081/ ，就可访问nginx Docker安装Tomcat创建tomcat的相关目录1[docker@localhost ~]$ mkdir -p ~/tomcat/webapps ~/tomcat/logs ~/tomcat/conf 查找Docker Hub上的tomcat镜像1[docker@localhost ~]$ docker search tomcat 拉取官方tomcat镜像1[docker@localhost ~]$ docker pull tomcat 创建测试文件 在~/tomcat/webapps目录下创建test目录 1[docker@localhost webapps]$ mkdir test 进入test目录，编写测试页面 1[docker@localhost test]$ vi index.html index.html文件内容： 12345678910&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;docker中的tomcat测试&lt;/title&gt; &lt;/head&gt; &lt;body&gt; Hello, World! &lt;br&gt; 哈哈哈哈，运行成功啦啦啦啦啦 &lt;/body&gt;&lt;/html&gt; 运行tomcat容器 1[docker@localhost tomcat]$ docker run --name tomcat -p 8080:8080 -v $PWD/webapps/test:/usr/local/tomcat/webapps/test -d tomcat 命令说明： -v $PWD/webapps/test:/usr/local/tomcat/webapps/test: 将主机中当前目录下的test挂载到容器的/test 启动成功后，在浏览器访问：http://主机ip:8080/test/index.html即可访问刚才编写的测试页面]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置]]></title>
    <url>%2F2017%2F06%2F07%2FNginx%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[在真正开始配置之前，先说一下Nginx的配置文件配置的基础知识。（Linux和Windows的配置一样，不分开说了） Nginx的配置文件在安装目录下的conf目录中，一些默认配置都在这个目录下。 nginx.conf 的注释符号为 # 打开nginx.conf文件，可以大概浏览一下，配置文件基本可以分为几个模块 12345678910111213141516171819202122232425... #全局块events &#123; #events块 ...&#125;http #http块&#123; ... #http全局块 server #server块 &#123; ... #server全局块 location [PATTERN] #location块 &#123; ... &#125; location [PATTERN] &#123; ... &#125; &#125; server &#123; ... &#125; ... #http全局块&#125; 全局块 配置影像nginx的全局指令。一般有nginx的进程数，错误日志文件路径，nginx的主进程号等 events块 配置Nginx的工作模式，每个进程的最大连接数等 http块 可以嵌套多个server，配置代理，缓存，日志等功能以及第三方模块的配置。如文件引入，mime-type定义，连接超时时间，单连接请求数等等 server块 配置虚拟主机的相关参数，一个http中可以有多个server location块 配置请求的路由，以及各种页面的处理情况 附上一个比较完整的Nginx配置文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137#定义Nginx运行的用户和用户组user www www;#nginx进程数，建议设置为等于CPU总核心数。worker_processes 8;#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]error_log /var/log/nginx/error.log info;#进程文件pid /var/run/nginx.pid;#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。worker_rlimit_nofile 65535;#工作模式与连接数上限events &#123; #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。 use epoll; #单个进程最大连接数（最大连接数=连接数*进程数） worker_connections 65535;&#125;#设定http服务器http &#123; include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream; #默认文件类型 #charset utf-8; #默认编码 server_names_hash_bucket_size 128; #服务器名字的hash表大小 client_header_buffer_size 32k; #上传文件大小限制 large_client_header_buffers 4 64k; #设定请求缓 client_max_body_size 8m; #设定请求缓 sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。 tcp_nopush on; #防止网络阻塞 tcp_nodelay on; #防止网络阻塞 keepalive_timeout 120; #长连接超时时间，单位是秒 #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用 upstream blog.test.com &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3; &#125; #虚拟主机的配置 server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.test.com test.com; index index.html index.htm index.php; root /data/www/test; location ~ .*\.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*\.(js|css)?$ &#123; expires 1h; &#125; #日志格式设定 log_format access '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" $http_x_forwarded_for'; #定义本虚拟主机的访问日志 access_log /var/log/nginx/testaccess.log access; #对 "/" 启用反向代理 location / &#123; proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; client_max_body_size 10m; #允许客户端请求的最大单文件字节数 client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数， proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 &#125; #设定查看Nginx状态的地址 location /NginxStatus &#123; stub_status on; access_log on; auth_basic "NginxStatus"; auth_basic_user_file conf/htpasswd; #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。 &#125; #本地动静分离反向代理配置 #所有jsp的页面均交由tomcat或resin处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; #所有静态文件由nginx直接读取不经过tomcat或resin location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$ &#123; expires 15d; &#125; location ~ .*.(js|css)?$ &#123; expires 1h; &#125; &#125;&#125; 注：配置中的IP读者可改为自己实际的IP地址 接下来附上在实际应用中积累的一些配置 请求体缓存目录 1client_body_temp_path /app/appdata/temp; 请求体缓存大小 1client_max_body_size 1000M; 代理缓存目录 1proxy_temp_path /app/appdata/proxy_temp; 代理连接超时时间 1proxy_connect_timeout 180; 代理读数据超时时间 1proxy_read_timeout 180; 代理发送数据超时时间 1proxy_send_timeout 180; 代理缓存大小 1234proxy_buffers 4 1024M;proxy_buffer_size 128M;proxy_busy_buffers_size 2048M;proxy_temp_file_write_size 2048M; 关闭nginx版本号显示 1server_tokens off; cookie丢失配置 1234location /apps/ajax &#123; proxy_pass http://localhost:8081/payplatform; proxy_cookie_path /payplatform /apps/ajax;&#125; 注: 此种方式只适应于请求直接转发到实地址的方式，不适用转发到upstream模式。 配置Nginx文件管理服务 123456789server &#123; listen 8088; server_name file; location / &#123; root /Users/admin/share; add_header Cache-Control "no-cache, must-revalidate"; autoindex on; &#125;&#125; 在配置部分，强调一个重要的问题，Nginx配置文件中，空格很重要。]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx+Tomcat+Redis实现Session共享]]></title>
    <url>%2F2017%2F06%2F07%2FSession%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[之前的博文中简单的介绍了一下Nginx的负载均衡配置，比较简单，但是如果实现多台服务器之间的session共享就是一个难题了。 经过查资料，找到了几种解决session共享的方案。 不适用session，换作cookie 1能把session改成cookie，就能避开session的一些弊端，也有资料表明在集群系统中不能使用session。但是博主思考再三，公司项目的session中存储一些比较重要的信息，在以后的业务中也会使用session中的数据，所以直接使用cookie这种方案果断舍弃。 应用服务器自行实现共享 1让服务器自行实现session共享，就需要提供一个后端服务器都能访问的公共容器来存储session，比如redis或者memcache，当系统需要获取session时，直接从redis或memcache中获取即可。 以上两种方式都与Nginx没多大关系了。下面说说使用nginx如何处理 ip_hash 1234之前的博客中对upstream的几种方式做了介绍，相信大家还记得ip_hash的介绍吧，每个请求按访问ip的hash结果分配，这样每个访问固定访问一个后端服务器。这样一来这个ip下的某个客户端和某个后端服务器就能建立稳固的session。这样每个客户端都只对应一个服务器，那就不存在需要共享session的需要了，不过只用ip这个因子来分配后端，所以还是存在一些缺陷，不能在以下情况下使用：1、nginx不是最前端的服务器。ip_hash要求nginx一定是最前端的服务器，否则nginx就得不到正确的ip，也就不能根据ip来分配后端了。比如squid(一个高性能的代理缓存服务器)作为最前端，那么nginx只能获取到squid所在服务器的ip地址，这种分流方式肯定会混乱的。2、nginx的后端还有其他方式的负载均衡。如果nginx后端又有其他的负载均衡，将请求又通过另外的方式分流了，那么某个客户端的请求肯定不能定位到同一台服务器上。 upstream_hash 12为了解决ip_hash的一些问题，可以使用upstream_hash这个第三方模块，这个模块大多数情况下是用作url_hash的，但是并不妨碍将它用来做session共享；这种方式不是很理解，就不做累述了，以后再慢慢研究。读者可自行查找资料学习。 来自于网络上的方案介绍完了，接下来说说博主项目中的实际操作。 博主最初的打算是使用redis来缓存系统数据，刚好也可以实现session共享。可惜，客户公司方面服务器资源不够，不让使用redis，上面第二种方案瞬间被阉割掉了，有点不爽。这里必须吐槽吐槽客户公司。 由于不让使用redis，所以只能使用第三种方式了，这里就不做太多的累述了，比较简单，配置nginx负载均衡的时候将upstream的方式配置为ip_hash即可，具体配置方式在上篇“Nginx负载均衡配置”中已有例子，可做参考。 简单的解释一下公司项目架构，公司项目采用前后台分离的架构，前端页面使用angularJS实现一种单页面应用，后台服务则使用SpringBoot为前端提供数据服务，后台开发者只需要关注后端逻辑，然后将前端需要的数据转为json传给前端，而不需要去考虑页面的跳转等，而前端人员也不需要关注后台逻辑，可以全身心的提供前端的用户体验度，最主要的是前后台分离后，系统开发职责划分的更加清晰。 关于前后台分离方案，这个博客讲的比较好，读者可做参考。 这样就完了？没有，这就完了这篇博客也太水了，虽然客户公司不让使用redis，但是博主还是自己抽时间使用nginx+tomcat+redis来自己实现session共享。 ——————————————————————这是一个分隔线——————————————————————- 1、软件准备因为是自己玩，所以直接在windows上开工了。 nginx-1.11.5，apache-tomcat-7.0.55，redis-2.6.12(windows版) 读者可从这里下载。其中有三个jar包最为重要： commons-pool-1.6.jar，jedis-2.1.0.jar，tomcat-redis-session-manager-tomcat7.jar，在软件包中的tomcat的lib目录下可找到。 2、配置tomcat在tomcat中的context.xml文件中加入以下内容 123456&lt;Valve className="com.radiadesign.catalina.session.RedisSessionHandlerValve" /&gt;&lt;Manager className="com.radiadesign.catalina.session.RedisSessionManager" host="localhost" port="6379" database="0" maxInactiveInterval="60" /&gt; 将配置好的tomcat三份，分别命名为apache-tomcat-7.0.55-1，apache-tomcat-7.0.55-2，apache-tomcat-7.0.55-3，然后去将每个tomcat的端口改掉，分别改为8081，8082，8083 3、配置Nginx将三个tomcat服务器用nginx代理， 12345upstream localhost &#123; server localhost:8081 weight=1; server localhost:8082 weight=1; server localhost:8083 weight=1; &#125; 4、测试页面在tomcat的webapp目录下新建test目录，在test中新建index.jsp，然后给三个tomcat都拷贝一份 123456789101112&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;!DOCTYPE html&gt;&lt;html lang="zh-CN"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt;&lt;/head&gt;&lt;body&gt;&lt;% out.println(request.getSession().getId());%&gt;&lt;/body&gt;&lt;/html&gt; 这可能是可与Hello，World媲美的页面了。 5、启动测试先启动redis，在启动三个tomcat，最后再启动nginx，然后访问页面。 有两种访问方式： 直接访问三个tomcat，【http://localhost:808x/test/index.jsp】，查看页面打印出的sessionId是否一致。 多次访问nginx，【http://localhost:80/test/index.jsp】，同时配置Nginx时将upstream配置为轮询，使用上面路径访问时会将请求轮流转发到三台服务器上，确实此时页面上的sessionId是否一致 好了，这种session共享完成。 这种Session共享是基于Tomcat完成的，不会侵入项目。当前还有一种实现Session共享的方式，Spring全家桶中，Spring Session框架就是专门做Session管控的。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>Session</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx入门]]></title>
    <url>%2F2017%2F06%2F06%2FNginx%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Nginx (“engine x”) 是一个高性能的HTTP和反向代理服务器，也是一个IMAP/POP3/SMTP服务器。Nginx是由Igor Sysoev为俄罗斯访问量第二的Rambler.ru站点开发的，第一个公开版本0.1.0发布于2004年10月4日。其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。2011年6月1日，nginx 1.0.4发布。Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。由俄罗斯的程序设计师Igor Sysoev所开发，供俄国大型的入口网站及搜索引擎Rambler（俄文：Рамблер）使用。其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好，中国大陆使用nginx网站用户有：百度、京东、新浪、网易、腾讯、淘宝等。 Nginx服务器的安装windowns版Nginx下载地址：http://nginx.org/en/docs/windows.html windows上安装Nginx比较简单，Nginx官方已经提供了打包好的.exe的运行文件，不需要用户自己去编译运行。直接打开上面的地址，下载好windows版的nginx，解压后双击nginx.exe或者在命令窗口运行nginx.exe即可。 因为Nginx默认端口是80端口，所以启动成功之后在浏览器地址栏输入localhost就可以看到Nginx的欢迎页面。 linux版的Nginx下载地址：http://nginx.org/ 下载nginx之前，请确保自己的linux系统已经安装了g++，gcc。因为nginx是纯C语言编写，在linux下安装时需要去编译源码安装。 解压Nginx源码包 1&gt; tar -zxvf nginx-1.11.5.tar.gz 设置一下nginx配置信息 123&gt; chmod -R 755 nginx-1.11.5&gt; cd nginx-1.11.5&gt; ./configure --prefix=/usr/local/nginx #此处设置prefix，是设置nginx的安装路径，可通过./configure --help查看其它参数项 编译安装 1&gt; make | make install #将源码文件编译成可执行文件和各种库文件，并将其复制到上面设置的安装目录中 编译安装中的常见问题 缺少Nginx组件 1234$ wget http://www.openssl.org/source/openssl-fips-2.0.10.tar.gz$ tar zxvf openssl-fips-2.0.10.tar.gz$ cd openssl-fips-2.0.10$ ./config &amp;&amp; make &amp;&amp; make install 1234$ wget http://zlib.net/zlib-1.2.11.tar.gz$ tar zxvf zlib-1.2.11.tar.gz$ cd zlib-1.2.11$ ./configure &amp;&amp; make &amp;&amp; make install 1234$ wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.40.tar.gz$ tar zxvf pcre-8.40.tar.gz$ cd pcre-8.40$ ./configure &amp;&amp; make &amp;&amp; make install 缺少g++环境 1$ yum install gcc-c++ 报错了，error while loading shared libraries: libpcre.so.1: cannot open shared object file: No such file or directory 12$ whereis libpcre.so.1$ ln -s /usr/local/lib/libpcre.so.1 /lib64 启动nginx 12#这一步可以不指定nginx配置文件(nginx.conf文件在默认目录下时可不指定)&gt; /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf 还有最重要的一步，打开Nginx的防火墙端口 123&gt; vi /etc/sysconfig/iptables&gt; 添加端口，如： -A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT&gt; /etc/init.d/iptables restart #重启防火墙，让修改生效 在自己本机的浏览器中输入localhost就可以看到Nginx的欢迎页面。 Nginx其他常用命令参数 校验配置文件 1&gt; nginx -t 重启 1&gt; nginx -s reload 安全停止 1&gt; nginx -s quit 其他参数可使用’man nginx’命令查看，就不一一列举了。 注: Nginx停止也可以通过杀死Nginx进程的方式停止，Nginx默认会启动两个进程，master和worker，直接杀死进程时需要kill这两个进程。master和worker的区别在以后的文章中再做说明。]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx负载均衡配置]]></title>
    <url>%2F2017%2F06%2F05%2FNginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Nginx的负载均衡是通过upstream实现的，在前面也有介绍过，下面对Nginx常用的upstream方式 nginx的upstream的几种方式 轮询（默认） 每个请求按照时间顺序逐一分配到不同的后端服务器，如果后端服务器冗机，能自动剔除。 ip_hash 每个请求按访问ip的hash结果分配，这样每个访问固定访问一个后端服务器。 weight 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 fair(第三方) 按后端服务器的响应时间来分配请求，响应时间短的优先分配。 url_hash(第三方) 按访问URL的hash结果来分配请求，使每个URL定向到同一个后端服务器，后端服务器为缓存时比较适用。另外，在upstream中加入hash语句后，server语句不能写入weight等其他参数。 例如： 123456upstream blog.test.com &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3;&#125; 总结一下，负载均衡简单的理解其实可以看做是用户请求Nginx，Nginx将用户的请求URL按照配置的方式截取，然后按照配置的upstream的方式请求后端服务器。]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot动态数据源切换]]></title>
    <url>%2F2017%2F06%2F01%2FSpringBoot%E5%8A%A8%E6%80%81%E6%95%B0%E6%8D%AE%E6%BA%90%E5%88%87%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[最近项目中需要配置两个数据源，并且在不同的包下动态切换，为此，参考网上动态切换数据源的博客，实现了满足项目的数据源动态切换功能。 1、Spring的开发者还是挺有先见之明的，为我们提供了扩展Spring的AbstractRoutingDataSource抽象类，我们来看它的源码 1234567891011121314151617181920212223242526272829 /** * Retrieve the current target DataSource. Determines the * &#123;@link #determineCurrentLookupKey() current lookup key&#125;, performs * a lookup in the &#123;@link #setTargetDataSources targetDataSources&#125; map, * falls back to the specified * &#123;@link #setDefaultTargetDataSource default target DataSource&#125; if necessary. * @see #determineCurrentLookupKey() */protected DataSource determineTargetDataSource() &#123; Assert.notNull(this.resolvedDataSources, "DataSource router not initialized"); Object lookupKey = determineCurrentLookupKey(); DataSource dataSource = this.resolvedDataSources.get(lookupKey); if (dataSource == null &amp;&amp; (this.lenientFallback || lookupKey == null)) &#123; dataSource = this.resolvedDefaultDataSource; &#125; if (dataSource == null) &#123; throw new IllegalStateException("Cannot determine target DataSource for lookup key [" + lookupKey + "]"); &#125; return dataSource;&#125;/** * Determine the current lookup key. This will typically be * implemented to check a thread-bound transaction context. * &lt;p&gt;Allows for arbitrary keys. The returned key needs * to match the stored lookup key type, as resolved by the * &#123;@link #resolveSpecifiedLookupKey&#125; method. */protected abstract Object determineCurrentLookupKey(); 源码注释解释的很清楚，determineTargetDataSource 方法通过数据源的标识获取当前数据源；determineCurrentLookupKey方法则是获取数据源标识。（作为英语彩笔，有道词典这种翻译软件还是特别好使的） 所以，我们实现动态切换数据源，需要实现determineCurrentLookupKey方法，动态提供数据源标识即可。 2、自定义DynamicDataSource类，继承AbstractRoutingDataSource，并实现determineCurrentLookupKey方法。 123456789101112public class DynamicDataSource extends AbstractRoutingDataSource &#123; @Override protected Object determineCurrentLookupKey() &#123; /** * DynamicDataSourceContextHolder代码中使用setDataSource * 设置当前的数据源，在路由类中使用getDataSource进行获取， * 交给AbstractRoutingDataSource进行注入使用。 */ return DynamicDataSourceContextHolder.getDataSource(); &#125;&#125; 3、创建统一数据源管理类DynamicDataSourceContextHolder 12345678910111213141516171819202122public class DynamicDataSourceContextHolder &#123; // 线程本地环境 private static final ThreadLocal&lt;String&gt; dataSources = new ThreadLocal&lt;String&gt;(); // 管理所有的数据源Id public static List&lt;String&gt; dataSourceIds = new ArrayList&lt;String&gt;(); public static void setDataSource(String dataSource) &#123; dataSources.set(dataSource); &#125; public static String getDataSource() &#123; return dataSources.get(); &#125; public static void clearDataSource() &#123; dataSources.remove(); &#125; // 判断指定的DataSource当前是否存在 public static boolean containsDataSource(String dataSourceId) &#123; return dataSourceIds.contains(dataSourceId); &#125;&#125; 4、重点来了，创建动态数据源注册器DynamicDataSourceRegister 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071 public class DynamicDataSourceRegister implements ImportBeanDefinitionRegistrar, EnvironmentAware &#123; // 默认数据连接池 public static final Object DATASOURCE_TYPE_DEFAULT = "org.apache.tomcat.jdbc.pool.DataSource"; private Class&lt;? extends DataSource&gt; dataSourceType; // 默认数据源 private DataSource defaultDataSource; private Map&lt;String, DataSource&gt; dataSourceMaps = new HashMap&lt;String, DataSource&gt;(); /** * 加载多数据源配置 * @param environment */ @Override public void setEnvironment(Environment environment) &#123; initDefaultDataSource(environment); &#125; /** * 初始化默认数据源 * @param environment */ private void initDefaultDataSource(Environment environment) &#123; RelaxedPropertyResolver propertyResolver = new RelaxedPropertyResolver(environment, "spring.datasource."); try &#123; if(propertyResolver.getProperty("type") == null) &#123; dataSourceType = (Class&lt;? extends DataSource&gt;)Class.forName(DATASOURCE_TYPE_DEFAULT.toString()); &#125; else &#123; dataSourceType = (Class&lt;? extends DataSource&gt;)Class.forName(propertyResolver.getProperty("type")); &#125; &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; // 创建数据源 String jndiName = propertyResolver.getProperty("jndi-name"); String[] jndiNames = jndiName.split(","); defaultDataSource = new JndiDataSourceLookup().getDataSource(jndiNames[0]); dataSourceMaps.put("AAA", defaultDataSource); DataSource dataSource1 = new JndiDataSourceLookup().getDataSource(jndiNames[1]); dataSourceMaps.put("BBB", dataSource1); &#125; @Override public void registerBeanDefinitions(AnnotationMetadata annotationMetadata, BeanDefinitionRegistry beanDefinitionRegistry) &#123; Map&lt;String, Object&gt; targetDataSources = new HashMap&lt;String, Object&gt;(); // 将主数据源添加到更多数据源中 targetDataSources.put("dataSource", defaultDataSource); DynamicDataSourceContextHolder.dataSourceIds.add("dataSource"); // 添加更多数据源 targetDataSources.putAll(dataSourceMaps); for(String key : dataSourceMaps.keySet()) &#123; DynamicDataSourceContextHolder.dataSourceIds.add(key); &#125; // 创建DynamicDataSource GenericBeanDefinition beanDefinition = new GenericBeanDefinition(); beanDefinition.setBeanClass(DynamicDataSource.class); beanDefinition.setSynthetic(true); MutablePropertyValues mutablePropertyValues = beanDefinition.getPropertyValues(); mutablePropertyValues.addPropertyValue("defaultTargetDataSource", defaultDataSource); mutablePropertyValues.addPropertyValue("targetDataSources", targetDataSources); beanDefinitionRegistry.registerBeanDefinition("dataSource", beanDefinition); &#125;&#125; 好了，这么一坨代码丢在这儿，相信读者也看着费劲，接下来对动态数据源注册器略作解释 EnvironmentAware接口提供了一个setEnvironment(Environment environment)方法，通过这个方法我们可以从application.properties配置文件中获取到所有数据源的配置信息，然后创建数据源并加载到内存中 ImportBeanDefinitionRegistrar接口，光看接口名字大概都能猜到是做什么的，对，就是注册Bean的。该接口用于在系统处理@Configuration class时注册更多的bean。是bean定义级别的操作，而非@Bean method/instance级别的。该接口提供了registerBeanDefinitions方法，该方法是在Spring加载bean时被Spring调用。通过setEnvironment方法，已经将配置文件中所有的数据源获取到了，然后在registerBeanDefinitions方法中将所有数据源注册到Spring容器中。 5、将动态数据源注册器导入到Spring容器中 1234567@SpringBootApplication@Import(&#123;DynamicDataSourceRegister.class&#125;)public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 需要注意的是，使用@Import导入的类必须满足符合以下的某一个条件： 导入的类使用@Configuration进行标注 导入的类中至少有一个使用@Bean标准的方法 导入的类实现了ImportSelector接口 导入的类实现了ImportBeanDefinitionRegistrar接口 到这一步了，是不是就完了呢，当然不是，以上这些步骤只是为切换数据源提供了基础 6、新建一个TargetDataSource注解 123456@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface TargetDataSource &#123; String value();&#125; 此注解用来标记当前的方法的数据源的，在需要指定数据源的方法上标记@TargetDataSource(“AAA”)注解即可，还没完，继续往下看。 7、新建数据源切换AOP切面 123456789101112131415161718192021222324@Aspect@Order(-1) //保证此AOP在@Transactional之前执行@Componentpublic class DynamicDataSourceAspect &#123; private transient static final Logger logger = LoggerFactory.getLogger(DynamicDataSourceAspect.class); // 通过注解切换数据源（细粒度） @Around("@annotation(targetDataSource)") public Object changeDataSource(ProceedingJoinPoint joinPoint, TargetDataSource targetDataSource) throws Throwable &#123; Object object = null; String dataSourceId = targetDataSource.value(); if(DynamicDataSourceContextHolder.containsDataSource(dataSourceId)) &#123; logger.info("系统将使用&#123;&#125;数据源", dataSourceId); DynamicDataSourceContextHolder.setDataSource(dataSourceId); &#125; else &#123; logger.debug("数据源&#123;&#125;不存在，将使用默认数据源&#123;&#125;", dataSourceId, joinPoint.getSignature()); &#125; object=joinPoint.proceed(); DynamicDataSourceContextHolder.clearDataSource(); return object; &#125;&#125; 解释解释，这个切面呢，就是切标记了targetDataSource注解的方法，根据targetDataSource注解的value值设置系统当前的数据源。使用注解方式算是一种细粒度的控制，可切换多个数据源；粗粒度的就是直接切某一个包路径，而且只能是两个数据源互切。两种方式各有各的好处，看业务需要。不过总的来说，能解决问题的方法就是好方法。 最后附一下JNDI数据源在application.properties文件中的配置 1spring.datasource.jndi-name=java:comp/env/jdbc/AAA,java:comp/env/jdbc/BBB 其实，JNDI数据源也可以直接配置到application.properties文件中，或者两种模式都支持，此处不做累述。 ————————————————华丽的分割线—————————————————- 在项目的进展中，此数据源切换已被改造，增加了Druid数据源加密功能，因为是多数据源加密，和官网的有些不一样，代码就不一一累述，读者若有需要，可自行研究或联系博主获取]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>多数据源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基本-数据类型缓存解析]]></title>
    <url>%2F2016%2F12%2F22%2FJava%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E7%BC%93%E5%AD%98%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[此文对Jdk的常用基础类的缓存机制进行简单分析。 基本类型缓存解析Integer缓存解析：123456789101112131415161718192021222324252627282930private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty("java.lang.Integer.IntegerCache.high"); if (integerCacheHighPropValue != null) &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low)); &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); &#125; private IntegerCache() &#123;&#125; &#125;public static Integer valueOf(int i) &#123; assert IntegerCache.high &gt;= 127; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 1、使用自动装箱（Integer i = 1）方式创建Integer对象时，会使用valueOf进行Integer对象的初始化，此时，会调用IntegerCache.high，这是需要对IntegerCache这个静态内部类进行初始化。2、IntegerCache类中有一个cache数组，在加载IntegerCache的时候，会将-128到127的Integer对象都创建了，并存到cache数组中，然后在判断当前初始化的Integer对象的值是否在-128到127之间，如果是，就直接从cache缓存中取，如果不存在，则new一个新的Integer对象。3、之后再使用自动装箱的方式创建Integer对象时，值在-128到127之间时会直接从cache缓存中取。 所以，使用自动装箱的方式创建的Integer对象，两者进行比较时，只要其值相等就是ture。而不在-128到127之间的，比较时会新new一个对象，而导致比较结果为false注意：Integer的最低值是固定的，只能是-128，而最高值是可以通过jvm参数设置的。在执行java程序的时候加上-XX:AutoBoxCacheMax=参数即可。 Long及Byte、Character缓存解析12345678910111213141516private static class LongCache &#123; private LongCache()&#123;&#125; static final Long cache[] = new Long[-(-128) + 127 + 1]; static &#123; for(int i = 0; i &lt; cache.length; i++) cache[i] = new Long(i - 128); &#125;&#125;public static Long valueOf(long l) &#123; final int offset = 128; if (l &gt;= -128 &amp;&amp; l &lt;= 127) &#123; // will cache return LongCache.cache[(int)l + offset]; &#125; return new Long(l);&#125; Long的缓存机制（LongCache）与Integer的类似，还有Character（CharacterCache），Byte（ByteCache）的缓存机制也是类似。不过只有Integer的最大值可以通过jvm参数设置，其他的都固定的。其中，Byte，Short，Long 的范围： -128 到 127；Character, 范围是 0 到 127。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot核心]]></title>
    <url>%2F2016%2F12%2F18%2FSpring-Boot%E6%A0%B8%E5%BF%83%2F</url>
    <content type="text"><![CDATA[一、Spring Boot基本配置1、入口类和@SpringBootApplicationSpring Boot通常有一个名为*Application的入口类，入口类中有一个main方法，这个main方法其实就是一个标准的Java应用程序的入口方法。在main方法中使用SpringApplication.run(Chapter01Application.class, args),启动Spring Boot应用项目。 2、关闭特定的自动配置通过@SpringBootApplication源码可以看出，关闭特定的自动配置应该使用@SpringBootApplication注解的exclude参数，例如:@SpringBootApplication(exclude={DataSourceAutoConfiguration.class}) 3、定制Banner在Spring Boot启动的时候会有一个默认启动图案，这个图案是可以自定义的。1）我们在src/main/resources下新建一个banner.txt2）通过http://patorjk.com/software/taag网站生成字符，将生成的字符复制到banner.txt文件中3）自动程序，这时控制台图案将变成刚才生成的图案 4、关闭banner在main方法中修改为(Spring Boot:1.4.0)： 123SpringApplication application = new SpringApplication(Chapter1Application.class); application.setBannerMode(Mode.OFF); application.run(args); 或者 123new SpringApplicationBuilder(Chapter1Application.class) // .bannerMode(Mode.OFF) // .run(args); 5、Spring Boot配置文件Spring Boot使用一个全局的配置文件application.properties或application.yml，放置在src/main/resources目录或者类路径的/config下。Spring Boot不仅支持常规的properties配置文件，还支持yaml语言的配置文件。yaml是以数据为中心的语言，在配置数据的时候具有面向对象的特征。Spring Boot的全局配置文件的作用是对一些默认配置值进行修改。例如：修改tomcat端口为8080-&gt;8888，默认的访问路径为”/“-&gt;”/helloboot”。可以在application.properties中添加： 12server.port=9090 server.context-path=/helloBoot 6、官方starter pomspring-boot-starter &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spring Boot核心starter，包含自动配置、日志、yaml配置文件的支持spring-boot-starter-actuator &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 准生产特性，用来监控和管理应用spring-boot-starter-remote-shell &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 提供基于ssh协议的监控和管理spring-boot-starter-amqp &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 使用spring-rabbit来支持AMQPspring-boot-starter-aop &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 使用spring-aop和AspectJ支持面向切面变成spring-boot-starter-batch &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Spring Batch的支持spring-boot-starter-cache &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Spring Cache抽象的支持spring-boot-starter-cloud-connectors &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对云平台（Cloud Foundry，Heroku）提供的服务提供简化的连接方法spring-boot-starter-data-elasticsearch &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-data-elasticsearch对Elasticsearch的支持spring-boot-starter-data-gemfire &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-data-gemfire对分布式存储GenFile的支持spring-boot-starter-data-jpa &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对JPA的支持，包含spring-data-jpa，spring-orm和Hibernatespring-boot-starter-data-mongodb &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-data-mongodb，对MongoDB进行支持spring-boot-starter-data-rest &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-data-rest-webmvc将Spring Data Repository暴露REST形式的服务spring-boot-starter-data-solr &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-data-solr对Apache Solr数据检索平台的支持spring-boot-starter-freemarker &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对FreeMarker模板引擎的支持spring-boot-starter-groovy-templates &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Groovy模板引擎的支持spring-boot-starter-hateoas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-hateoas 通过spring-hateoas对基于HATEOAS的REST形式的网络服务的支持spring-boot-starter-hornetq &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过HornetQ对JMS的支持spring-boot-starter-integration &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对系统集成框架spring-integration的支持spring-boot-starter-jdbc &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对JDBC数据库的支持spring-boot-starter-jersey &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Jersery REST形式的网络服务的支持spring-boot-starter-jta-atomikos &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过Atomikos对分布式事务的支持spring-boot-starter-jta-bitronix &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过Bitronix对分布式事务的支持spring-boot-starter-mail &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对javax.mail的支持spring-boot-starter-mobile &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对spring-mobile的支持spring-boot-starter-mustache &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Mustache模板引擎的支持spring-boot-starter-redis &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对键值对内存数据库Redis的支持，包含spring-reidsspring-boot-starter-security &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对spring-security的支持spring-boot-starter-social-faceboot &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-social-faceboot对Facebook的支持spring-boot-starter-social-twitter &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-social-twitter对Twitter的支持spring-boot-starter-test &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对常用的测试框架Junit，Hamcrest和Mockito的支持，包含spring-test模板spring-boot-starter-thymeleaf &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Thymeleaf模板引擎的支持，包含于Spring整合的配置spring-boot-starter-velocity &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Velocity模板引擎的支持spring-boot-starter-web &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Web项目开发的支持，包含Tomcat和spring-webmvcspring-boot-starter-Tomcat &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Spring Boot默认的Servlet容器Tomcatspring-boot-starter-Jetty &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 使用Jetty作为Servlet容器替换Tomcatspring-boot-starter-undertow &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 使用Undertow作为Servlet容器替换Tomcatspring-boot-starter-logging &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Spring Boot默认的日志框架Logbackspring-boot-starter-log4j &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 支持使用Log4j日志框架spring-boot-starter-websocket &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对WebSocket开发的支持spring-boot-starter-ws &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对Spring Web Services的支持 还有第三方为Spring Boot所写的starter pom,这里不做介绍 7、使用xml配置Spring Boot提倡零配置，即无xml配置，但是在实际项目中，可能有些特殊要求，使得开发者必须使用xml配置，这时我们可以通过Spring提供的@ImportResource来加载xml配置，例如： 1@ImportResource(&#123;"classpath:context.xml”&#125;) 8、命令行参数配置Spring Boot可以是基于jar包运行的，打成jar包的程序可以直接通过java -jar xx.jar来运行可以通过java -jar xx.jar —server.port=8888来修改Tomcat端口号 9、常规属性配置在常规Spring环境下，注入properties文件里的值得方式，通过@PropertySource指明properties文件的位置，然后通过@Value注入值。在Spring Boot里，只需要在application.properties定义属性，直接使用@Value注入即可。例如：在application.properties文件中添加属性： 12book.author=cmbook.name=spring boot 在com.gnd.springboot.config.init路径下新建PropertiesTests属性配置类，使用@Value注入book属性 12345678910111213141516171819@Componentpublic class PropertiesTests &#123; @Value("book.author") private String author; @Value("book.name") private String name; public String getAuthor() &#123; return author; &#125; public void setAuthor(String author) &#123; this.author = author; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 10、类型安全的配置（基于properties）Spring Boot提供了基于类型安全的配置方式，通过@ConfigurationProperties将properties属性和一个Bean及其属性关联，从而实现类型安全的配置。所以，常规属性配置可以修改为： 123456789101112131415161718@Component@ConfigurationProperties(prefix = "book")public class PropertiesTests &#123; private String author; private String name; public String getAuthor() &#123; return author; &#125; public void setAuthor(String author) &#123; this.author = author; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 11、日志配置Spring Boot支持Java Util Logging、Log4J、Log4J2和Logback作为日志框架，无论使用哪种日志框架，Spring Boot已为当前使用日志框架的控制台输出及文件输出做好了配置。默认情况下，Spring Boot使用Logback作为日志框架。日志级别:logging.file=/home/cm/mylog.log配置日志文件，格式为logging.level.包名=级别：logging.level.org.springframework.web=DEBUG 12、Profile配置Profile是Spring用来针对不同的环境对不同的配置提供支持的，全局Profile配置使用application-{profile}.properties(如application-prod.properties),通过在application.properties中设置spring.profiles.active=prod来指定活动的Profile例如：我们分为生产(prod)和开发(dev)环境，在生产环境下端口号为80，开发环境为8888。两种配置文件分别为： 12application-prod.properties: server.port=80application-dev.properties: server.port=8888 然后在application.properties增加： 1spring.profiles.active=dev(prod) 通过Profile可以灵活切换Spring Boot项目的配置了。 二、Spring Boot运行原理Spring Boot关于自动配置的源码在spring-boot-autoconfigure-1.4.0.RELEASE.jar内，主要包含了以下配置：若想知道Spring Boot为我们做了哪些自动配置，可以通过通过三种方式查看以启用和未启用的自动配置的报告：1）运行jar时增加—debug参数：java -jar xx.jar —debug2)在application.properties中设置属性：debug=true（这个方便点）3）在开发工具启动参数中配置 1、Spring Boot运行原理解析： 对@SpringBootApplication注解说明： @SpringBootApplication是一个组合注解，它的核心功能是由@EnableAutoConfiguration注解提供的。查看@EnableAutoConfiguration源码这里@Import注解导入配置功能，EnableAutoConfigurationImportSelector使用SpringFactoriesLoader.loadFactoryNames方法来扫描具有META-INF/spring.factories文件的jar包，而spring-boot-autoconfigure-1.4.0.RELEASE.jar里就有一个spring.factories文件，次问价中声明了有哪些自动配置。​ 任意打开一个AutoConfiguration文件，一般都有以下条件注解，在spring-boot-autoconfigure-1.4.0.RELEASE.jar的org.springframework.boot.autoconfigure.condition包下，条件注解如下： @ConditionalOnBean： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当容器里有指定的Bean的条件下 @ConditionalOnClass: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当类路径下有指定的类的条件下 @ConditionalOnExpression： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 基于SpEL表达式作为判断条件 @ConditionalOnJava： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 基于JVM版本作为判断条件 @ConditionalOnJndi： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在JNDI存在的条件下查找指定的位置 @ConditionalOnMissingBean： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当容器里没有指定Bean的情况下 @ConditionalOnMissingClass： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当类路径下没有指定的类的条件下 @ConditionalOnNotWebApplication： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当前项目不是Web项目的条件下 @ConditionalOnProperty： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 指定的属性是否有指定的值 @ConditionalOnResource： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 类路径是否有指定的值 @ConditionalOnSingleCandidate： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当指定Bean在容器中只有一个，或者虽然有多个但是指定首选的Bean @ConditionalOnWebApplication： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当前项目是Web项目的条件下这些注解都是使用了@Conditional元注解，不过是使用了不同的条件而已。 2、分析http的编码配置配置参数 HttpEncodingProperties的源码如下：这里的配置类可以直接在application.properties中以spring.http.encoding 为前缀配置，比如：如果需要修改默认编码方式，可通过spring.http.encoding.charset=gbk 配置。根据条件配置CharacterEncodingFilter的Bean，源码如下: 3、自定义自动配置（包装成starter pom）1）新建maven工程spring-boot-starter-hello，在pom.xml中添加如下配置: 12345678910111213141516&lt;properties&gt; &lt;spring-framework.version&gt;1.4.0.RELEASE&lt;/spring-framework.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2) 新建属性配置类HellpServiceProperties 1234567891011@ConfigurationProperties(prefix = "hello")public class HelloServiceProperties &#123; private static final String MSG = "world"; private String msg = MSG; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125;&#125; 此种配置方式为类型安全的属性获取。在application.properties中通过hello.msg= 来设置，若不设置，默认为hello.msg=world 3）新建依据类HelloService（此类可以是第三方类库的类） 123456789101112public class HelloService &#123; private String msg; public String sayHello() &#123; return "Hello " + msg; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125;&#125; 4）新建自动配置类 123456789101112131415@Configuration@EnableConfigurationProperties(HelloServiceProperties.class)@ConditionalOnClass(HelloService.class)@ConditionalOnProperty(prefix = "hello", value = "enabled", matchIfMissing = true)public class HelloServiceAutoConfiguration &#123; @Autowired private HelloServiceProperties helloServiceProperties; @Bean @ConditionalOnMissingBean(HelloService.class) public HelloService helloService() &#123; HelloService helloService = new HelloService(); helloService.setMsg(helloServiceProperties.getMsg()); return helloService; &#125;&#125; 根据HelloServiceProperties提供的参数，并通过@ConditionalOnClass来判断HelloService这个类在类路径中是否存在，且当这个容器中没有这个Bean的情况下自动配置这个Bean。 5）注册自动配置 在src/main/resources中新建META-INF/spring.factories文件，内容为 1org.springframework.boot.autoconfigure.EnableAutoConfiguration=\ com.gnd.springboot.config.HelloServiceAutoConfiguration&lt;br&gt; 其中“\”是为了在换行之后仍能读到属性，若有多个自动配置，以“,”分隔 6）测试自定义自动配置 新建一个maven web工程，添加如下依赖: 12345678910111213141516&lt;properties&gt; &lt;spring-framework.version&gt;1.4.0.RELEASE&lt;/spring-framework.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;spring-boot-starter-hello&lt;/groupId&gt; &lt;artifactId&gt;com.gnd.springboot&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; spring-boot-starter-hello为之前新建的自定义自动配置starter pom新建测试启动类​12345678910111213@RestController@SpringBootApplicationpublic class Chapter11Application &#123; @Autowired private HelloService helloService; @RequestMapping("/test") public String index() &#123; return helloService.sayHello(); &#125; public static void main(String[] args)&#123; SpringApplication.run(Chapter11Application.class, args); &#125;&#125; 运行测试工程之后，浏览器输入”http://localhost:8080/test“测试，测试结果如下:新建application.properties配置文件，内容为 1hello.msg=haha 重启工程，浏览器输入”http://localhost:8080/test“测试，测试结果如下:]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基础-Jdk各版本区别]]></title>
    <url>%2F2016%2F12%2F18%2FJDK%E5%90%84%E7%89%88%E6%9C%AC%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[从2013年开始自学Java起，到现在已经有三个年头了，Jdk当前各个版本在自学还是工作中都有涉及，此文对每个版本的特性略作记载。 jdk5新特性1、自动装箱和拆箱2、枚举3、静态导入4、可变参数5、內省 内省是Java语言对Bean类属性、事件的一种缺省处理方法。例如类A中有属性那么，那我们可以通过getName，setName来得到其值或者设置新的值。通过getName/setName来访问name属性，这就是默认的规则。Java中提供了一套API用来访问某个属性的getter，setter方法，通过这些API可以使你不需要了解这个规则，这些API存放于包java.beans中。 一般的做法是通过类Introspector来获取某个对象的BeanInfo信息，然后通过BeanInfo来获取属性的描述器（PropertyDescriptor），通过这个属性描述器就可以获取某个属性对应的getter/setter方法，然后我们就可以通过反射机制来调用这些方法。 6、泛型7、For-Each循环jdk6新特性1、Desktop类和SystemTray类 AWT新增加了两个雷：Desktop，SystemTray。 Desktop可以用来打开系统默认浏览器指定的URL，打开系统默认邮件客户端给指定的邮件账号发邮件，用默认应用程序打开或编辑文件（比如，用记事本打开txt文件），用系统默认的打印机打印文档 SystemTray可以用来在系统托盘区创建一个托盘程序 2、使用JAXB2来实现对象与XML之间的映射 也就是对象与XML之间的映射（OXM），也可以通过XMLBeans和Castor等来实现同样的功能。 3、StAX StAX是The Streaming API for XML的缩写，一种利用拉模式解析(pull-parsing)XML文档的API.StAX通过提供一种基于事件迭代器(Iterator)的API让 程序员去控制xml文档解析过程,程序遍历这个事件迭代器去处理每一个解析事件，解析事件可以看做是程序拉出来的，也就是程序促使解析器产生一个解析事件 然后处理该事件，之后又促使解析器产生下一个解析事件，如此循环直到碰到文档结束符； SAX也是基于事件处理xml文档，但却 是用推模式解析，解析器解析完整个xml文档后，才产生解析事件，然后推给程序去处理这些事件；DOM 采用的方式是将整个xml文档映射到一颗内存树，这样就可以很容易地得到父节点和子结点以及兄弟节点的数据，但如果文档很大，将会严重影响性能。 4、使用Compiler API 使用JDK6的Compiler API去动态的编译Java源文件，Compiler API结合反射功能就可以实现动态的产生Java代码并编译执行这些代码。 5、轻量级Http Server API6、插入式注解处理API7、用Console开发控制台程序8、对脚本语言的支持如：ruby，groovy，javascript9、Common Annotationsjdk7新特性1、switch中可以使用字符串2、泛型的自动判断3、自定义自动关闭类（实现AutoCloseable接口）4、新增一些取环境信息的工具方法（System中的方法）5、Boolean类型反转，空指针安全，参数与位运算6、两个char间的equals7、安全的加减乘除1、对Java集合（Collections）的增强支持12345List&lt;String&gt; list=["item"]; //向List集合中添加元素String item=list[0]; //从List集合中获取元素Set&lt;String&gt; set=&#123;"item"&#125;; //向Set集合对象中添加元Map&lt;String,Integer&gt; map=&#123;"key":1&#125;; //向Map集合中添加对象int value=map["key"]; //从Map集合中获取对象 但是经过自己测试，按照上面的使用方法，并不能创建集合。 2、int支持二进制数据3、在try catch异常捕捉中，一个catch可以写多个异常类型1234567Connection conn = null;try &#123; Class.forName("com.mysql.jdbc.Driver"); conn = DriverManager.getConnection("","","");&#125; catch(ClassNotFoundException|SQLException ex) &#123; ex.printStackTrace();&#125; 4、try catch中资源定义好之后try catch自动关闭12345678910try (BufferedReader in = new BufferedReader(new FileReader("in.txt")); BufferedWriter out = new BufferedWriter(new FileWriter("out.txt"))) &#123; int charRead; while ((charRead = in.read()) != -1) &#123; System.out.printf("%c ", (char)charRead); out.write(charRead); &#125;&#125; catch (IOException ex) &#123; ex.printStackTrace();&#125; jdk8新特性1、接口的默认方法Java 8允许我们给接口添加一个非抽象的方法实现，只需要使用default关键字即可，这个特征又叫做扩展方法，示例如下： 123456public interface Formula &#123; double calculate(int a); default double sqrt(int a) &#123; return Math.sqrt(a); &#125;&#125; Formula接口在拥有calculate方法之外同时还定义了sqrt方法，实现了Formula接口的子类只需要实现一个calculate方法，默认方法sqrt将在子类上可以直接使用。 12345678 Formula formula = new Formula() &#123;@Overridepublic double calculate(int a) &#123; return sqrt(a * 100); &#125; &#125;; System.out.println(formula.calculate(100)); // 100.0 System.out.println(formula.sqrt(16)); // 4.0 文中的formula被实现为一个匿名类的实例，该代码非常 2、Lambda表达式1234567List&lt;String&gt; names = Arrays.asList("tom","jace","mike");Collections.sort(names, new Comparator&lt;String&gt;() &#123; @Override public int compare(String o1, String o2) &#123; return o2.compareTo(o1); &#125;&#125;); 只需要给静态方法Collections.sort传入一个List对象以及一个比较器来指定顺序排列。通常做法都是创建一个匿名的比较器对象，然后将其传递给sort方法。在Java 8中提供了更简洁的语法，lambda表达式： 123Collections.sort(names, (String a, String b) -&gt; &#123; return b.compareTo(a);&#125;); 还可以更简洁： 1Collections.sort(names, (String a, String b) -&gt; b.compareTo(a)); 去掉大括号以及return关键字 1Collections.sort(names, (a,b) -&gt; b.compareTo(a)); Java编译器可以自动推导出参数类型，所以可以不用再写一次类型。 3、函数式接口Lambda表达式是如何在java的类型系统中表示的呢？每一个lambda表达式都对应着一个类型，通常是接口类型。而“函数式接口”是指仅仅只包含一个抽象方法的接口，每一个该类型的lambda表达式都会被匹配到这个抽象方法。因为默认方法不算抽象方法，所以也可以给自己的函数式接口添加默认方法。我们可以将lambda表达式当做一个抽象方法的接口类型，确保自己的接口一定达到这个要求，你只需要给你的接口添加@FunctionalInterface注解，编译器如果发现标注了这个注解的接口有多于一个抽象方法的时候就会报错。也就是说@FunctionalInterface注解标注的接口只能有一个抽象方法。例如： 1234567@FunctionalInterfacepublic interface Converter&lt;F, T&gt; &#123; T convert(F from);&#125;Converter&lt;String, Integer&gt; converter = (from) -&gt; Integer.valueOf(from);Integer converted = converter.convert("123");System.out.println(converted); 以上代码不需要@FunctionalInterface注解也是正确的。 4、方法与构造函数引用上面的代码也可以通过静态方法引用来表示： 123Converter&lt;String, Integer&gt; converter = Integer::valueOf;Integer converted = converter.convert("123");System.out.println(converted); Java8允许使用::关键字来传递方法或者构造函数引用，上面的代码展示了如何引用一个静态方法，我们也可以引用一个对象的方法： 12345678910public class Person &#123; String firstName; String lastName; Person() &#123; &#125; public Person(String firstName, String lastName) &#123; this.firstName = firstName; this.lastName = lastName; &#125;&#125; 指定一个用来创建Person对象的对象工厂接口： 123public interface PersonFactory&lt;P extends Person&gt; &#123; P create(String fisrtName, String lastName);&#125; 创建Person对象 12PersonFactory&lt;Person&gt; personFactory = Person::new;Person person = personFactory.create("Peter","Parker”); 我们只需要使用Person::new 来获取Person类构造函数的引用，Java编译器就会自动根据PersonFactory.create方法的签名来选择合适的构造函数。 5、Lambda作用域在lambda表达式中访问外层作用域和老版本的匿名对象中的方式很相似。你可以直接访问标记了final的外层局部变量，或者实例的字段以及静态变量。 6、访问局部变量我们可以直接在lambda表达式中访问外层的局部变量 123final int num = 1;Converter&lt;Integer, String&gt; stringConverter = (from) -&gt; String.valueOf(from + num);stringConverter.convert(2); 但是和匿名对象不同的是，这里的变量num可以不用声明为final，该代码同样正确。 7、访问对象字段与静态变量和本地不良不同的是，lambda内部对于实例的字段以及静态变量是即可读又可写。该行为和匿名对象是一致的： 123456789101112static int outerStaticNum;int outerNum;public void testScopes() &#123; Converter stringConverter1 = (from) -&gt; &#123; outerNum = 23; return String.valueOf(from); &#125;; Converter stringConverter2 = (from) -&gt; &#123; outerStaticNum = 72; return String.valueOf(from); &#125;;&#125; 8、访问接口的默认方法9、Date API10、Annotation注解]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot入门]]></title>
    <url>%2F2016%2F12%2F13%2FSpring-Boot%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[一、Spring Boot简介 Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。通过这种方式使得开发人员使用Spring开发极大的简便了配置过程，基本上实现了零配置。 Spring Boot有以下几个优点： 1、 没有代码生成，不需要XML配置文件 2、 内嵌Tomcat，Jetty或者Undertow服务器，不需要额外部署web工程到Servlet容器 3、 可以独立运行Spring应用程序 4、 提供了Maven，Gradle两种方法搭建Spring Boot工程 5、 无缝整合其他开源框架（只需要添加开源框架的依赖包，Spring Boot自动完成整合） 6、 提供可以直接在生产环境中使用的功能，如性能指标、应用信息和应用健康检查 二、Spring Boot入门工程搭建：1、采用Spring官网提供的SPRING INITIALIZR进行搭建。可以选择Maven Project或者Gradle Project来搭建，然后选择Spring Boot版本，输入Group，Artifact，以及需要的依赖包，然后点击Generate Project，会生成一个Artifact.zip压缩包，将Artifact工程导入常用的开发工具即可。 2、使用开发工具手动构建Spring Boot工程（本文采用Intellij Idea 2016.3）1、新建一个Maven的web工程2、在pom.xml文件中添加Spring Boot的相关依赖添加父级依赖，这样当前的项目就是Spring Boot项目了。spring-boot-starter-parent是一个特殊的starer，它用来提供相关的maven默认依赖，使用它之后，当前项目的的常用依赖包就可以省去version标签。 123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt; 添加spring-boot-starter依赖，spring-boot-starter是Spring Boot核心starter，包含自动配置、日志、yaml配置文件的支持。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 然后在dependencies中添加Web支持的starter pom。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; spring-boot-starter-web会自动添加它所依赖的jar包 然后添加Spring Boot的编译插件，便于使用Spring Boot命令操作工程 1234567&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt;&lt;/plugin&gt; 3、简单测试新建包路径com.gnd.chapter01，在com.gnd.chapter01包路径下新建Chapter01Application.java入口类，编写入口方法 123456@SpringBootApplicationpublic class Chapter01Application &#123; public static void main(String[] args)&#123; SpringApplication.run(Chapter01Application.class, args); &#125;&#125; 注：@SpringBootApplication是一个组合注解，查看其源码，@SpringBootApplication组合了@SpringBootConfiguration，@EnableAutoConfiguration，@ComponentScan三个注解，@SpringBootConfiguration表示当前类是一个启动应用程序的入口；@EnableAutoConfiguration注解开启自动配置，让Spring Boot根据类路径中的jar包依赖为当前项目进行自动配置(例如:添加了spring-boot-starter-web依赖，会自动添加tomcat和SpringMVC的依赖)；@ComponentScan会以Application入口类所在目录为根目录，自动扫描工程中标注了@Component注解的类。 然后新建目录controller，在其中新建一个HelloController测试类。 1234567@RestControllerpublic class HelloController &#123; @RequestMapping("/hello") public String index() &#123; return "Hello, World!"; &#125;&#125; @RestController也是一个组合注解，组合了@Controller，@ResponseBody两个注解 4、运行使用Spring Boot命令运行工程，mvn spring-boot:run，或者直接运行Chapter01Application类，在浏览器中访问http://localhost:8080/hello即可访问HelloController。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper集群搭建]]></title>
    <url>%2F2016%2F07%2F05%2FZookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[本文的所有配置及集群的搭建，都是基于zookeeper-3.4.10的。 zoo.cfg配置详解 参数名 说明 clientPort 客户端连接Server的端口，即对外服务端口，一般设置为2181 dataDir 存储快照文件snapshot的目录。默认情况下，事务日志也会存储在这里。建议同时配置参数dataLogDir，事务日志的写性能直接影响zk性能 tickTime zk中的一个时间单元，zk中所有时间都是以这个时间单元为基础，进行整数倍配置的。例如，session的最小超时时间是2*tickTime dataLogDir 事务日志输出目录。尽量给事务日志的输出配置单独的磁盘或是挂载点，这将极大的提升zk性能（No Java System Property） globalOutstandingLimit 最大请求堆积数。默认是1000。zk运行的时候，尽管server已经没有空闲来处理更多的客户端请求了，但还是允许客户端将请求提交到服务器上来，以提高吞吐性能。当然，为了防止Server内存溢出，这个请求堆积数还是需要限制下的。(Java System Property:zookeeper.globalOutstandingLimit) preAllocSize 预先开辟磁盘空间，用于后续写入事务日志。默认是64M，每个事务日志大小就是64M。如果zk的快照频率较大的话，建议适当减小这个参数。（Java System Property:zookeeper.preAllocSize） snapCount 每进行snapCount次事务日志输出后，出发一次快照(snapshot)，此时，zk会生成一个snapshot.文件，同时创建一个新的事务日志文件log.\。默认是100000.(真正的代码实现中，会进行一定的随机数处理，以避免所有服务器在同一时间进行快照而影响性能)。(Java System Property:zookeeper.snapCount) traceFile 用于记录所有请求的log，一般调试过程中可以使用，但是生产环境不建议使用，会严重影响性能。(Java System Property:zookeeper.requestTraceFile) maxClientCnxns 单个客户端与单台服务器之间的连接数的限制，是IP级别的，默认是60，如果设置为0，那么表明不作任何限制。请注意这个限制的使用范围，仅仅是单台客户端机器与单台zk服务器直接的连接数限制，不是针对指定客户端IP，也不是zk集群的连接数限制，也不是单台zk对所有客户端的连接数限制。 clientPortAddress 对于多网卡的机器，可以为每个IP指定不同的监听端口。默认情况是所有IP都监听clientPort指定的端口。 minSessionTimeoutmaxSessionTimeout Session超时时间限制，如果客户端设置的超时时间不在这个范围，那么会被强制设置为最大或最小时间。默认的Session超时时间是在2*tickTime~20*tickTime这个范文 fsync.warningthresholdms 事务日志输出时，如果调用fsync方法超过指定的超时时间，那么会在日志中输出警告信息。默认是1000ms。( Java system property: fsync.warningthresholdms) autopurge.purgeInterval 在上文中已经提到，3.4.0及之后版本，ZK提供了自动清理事务日志和快照文件的功能，这个参数指定了清理频率，单位是小时，需要配置一个1或更大的整数，默认是0，表示不开启自动清理功能。(No Java system property) autopurge.snapRetainCount 这个参数和上面的参数搭配使用，这个参数指定了需要保留的文件数目。默认是保留3个。(No Java system property) electionAlg 在之前的版本中， 这个参数配置是允许我们选择leader选举算法，但是由于在以后的版本中，只会留下一种“TCP-based version of fast leader election”算法，所以这个参数目前看来没有用了，这里也不详细展开说了。(No Java system property) initLimit Follower在启动过程中，会从Leader同步所有最新数据，然后确定自己能够对外服务的起始状态。Leader允许F在 initLimit 时间内完成这个工作。通常情况下，我们不用太在意这个参数的设置。如果ZK集群的数据量确实很大了，F在启动的时候，从Leader上同步数据的时间也会相应变长，因此在这种情况下，有必要适当调大这个参数了。(No Java system property) syncLimit 在运行过程中，Leader负责与ZK集群中所有机器进行通信，例如通过一些心跳检测机制，来检测机器的存活状态。如果L发出心跳包在syncLimit之后，还没有从F那里收到响应，那么就认为这个F已经不在线了。注意：不要把这个参数设置得过大，否则可能会掩盖一些问题。(No Java system property) leaderServes 默认情况下，Leader是会接受客户端连接，并提供正常的读写服务。但是，如果你想让Leader专注于集群中机器的协调，那么可以将这个参数设置为no，这样一来，会大大提高写操作的性能。(Java system property: zookeeper.leaderServes) server.x=[hostname]:nnnnn[:nnnnn] 这里的x是一个数字，与myid文件中的id是一致的。右边可以配置两个端口，第一个端口用于F和L之间的数据同步和其它通信，第二个端口用于Leader选举过程中投票通信。 (No Java system property) group.x=nnnnn[:nnnnn]weight.x=nnnnn 对机器分组和权重设置，可以 参见这里(No Java system property) cnxTimeout Leader选举过程中，打开一次连接的超时时间，默认是5s。(Java system property: zookeeper.cnxTimeout) zookeeper.DigestAuthenticationProvider.superDigest ZK权限设置相关，具体参见 《 使用super 身份对有权限的节点进行操作 》 和 《 ZooKeeper 权限控制 》 skipACL 对所有客户端请求都不作ACL检查。如果之前节点上设置有权限限制，一旦服务器上打开这个开头，那么也将失效。(Java system property: zookeeper.skipACL) forceSync 这个参数确定了是否需要在事务日志提交的时候调用 FileChannel .force来保证数据完全同步到磁盘。(Java system property:zookeeper.forceSync) jute.maxbuffer 每个节点最大数据量，是默认是1M。这个限制必须在server和client端都进行设置才会生效。(Java system property:jute.maxbuffer) zoo.cfg配置要求类型配置项描述最低配置clientPort监听客户端连接的端口，默认值为2181dataDir存储持久数据的本地文件系统位置tickTime基本事件单元，以毫秒为单位，用来控制心跳和超时，默认情况下超时时间为两倍的tickTime高级配置dataLogDir事件日志写入的目录maxClientCnxns限制连接到Zookeeper的客户端数量，并且限制并发连接数量，它通过ip区分不同的客户端minSessionTimeout与maxSessionTimeout最小会话超时时间和最大的会话超时时间，在默认情况下，最小的会话超时时间为两倍的tickTime时间，最大的会话超时时间为20倍的会话超时时间，系统启动时会显示相应的信息。默认为-1集群配置initLimit参数设定了允许所有Follower与Leader进行连接并同步的时间，如果在设定的时间段内，半数以上的Follower未能完成同步，Leader便会宣布放弃领导地位，进行另一次的Leader选举。如果zk集群环境数量确实很大，同步数据的时间会很变长，因此这种情况下可以适当调大该参数。默认为10syncLimit参数设定了允许一个Follower与一个Leader进行同步的时间，如果在设定的时间段内，Follower未完成同步，它将会被集群丢弃。所有连接到这个Follower的客户端将连接到另外一个Followerserver.A=B:C:D其中A是一个数字，表示这个是第几号服务器；B是这个服务器的IP地址或者主机名称；C表示的是Follower与Leader交换信息的端口，默认值为2888；D表示的是Leader选举端口，默认值为3888 集群搭建软件准备由于zookeeper是基于Java开发的，所以需要Java环境，需要的童鞋，请自行百度，安装Java环境 1234wget http://ftp.mirror.tw/pub/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gztar -zxvf zookeeper-3.4.10.tar.gzcd zookeeper-3.4.10/confmv zoo_sample.cfg 注意： zookeeper默认配置文件为zoo_sample.cfg，需要自定义配置时，需要将此配置文件修改为zoo.cfg，注意，zoo.cfg和zoo_sample.cfg文件不能同时存在 集群配置 zoo.cfg对此配置文件的配置项不做解释，每项具体含义，上面都有详细解释，读者可自行查阅1234567891011tickTime=2000initLimit=10syncLimit=5dataDir=/home/zk/zookeeper-3.4.10/data/dataLogDir=/home/zk/zookeeper-3.4.10/logs/clientPort=2181autopurge.snapRetainCount=500autopurge.purgeInterval=24server.1=192.168.11.12:2888:3888server.2=192.168.11.13:2888:3888server.3=192.168.11.14:2888:3888 然后将配置文件同步到其他两台服务器上。推荐使用scp命令，如： 1scp /home/zk/zookeeper-3.4.10/conf/zoo.cfg zk@192.168.11.12:/home/zk/zookeeper-3.4.10/conf 创建ServerID标识（敲黑板了，此处是重点） 在192.168.11.12服务器的/home/zk/zookeeper-3.4.10/data目录下，新建myid文件，输入1；其他服务器上类似，myid与server.x=192.168.11.12:2888:3888的x匹配。 1echo "1" &gt; /home/zk/zookeeper-3.4.10/data/myid 启动集群在三台服务器上执行以下命令。 1sh zkServer.sh start 注意： 启动zookeeper常见问题有以下几点： 启动第一台zk节点时，查看日志，可以看见有异常，因为其他节点未启动，zk检查线程未找到zk集群的其他节点，所以报错。将其他节点起起来即可。 节点启动成功，但是不能正常连接，请开发zk集群涉及到的防火墙端口 启动节点报错，极有可能是zoo.cfg配置文件配置有误，请检查配置文件配置项是否正确 其他问题请自行百度（解决问题是一个程序员最基本的能力） 如果一些童鞋的服务器或虚拟机资源不足，可使用zookeeper的伪集群方式部署，思路：通过在同一台机器上，启动不同端口的zookeeper，即可构成集群，此处就不再累述了。]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
</search>
