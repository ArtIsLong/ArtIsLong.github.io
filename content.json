[{"title":"storm集群搭建","date":"2018-08-07T05:45:58.000Z","path":"2018/08/07/storm集群搭建/","text":"基本配置详解 配置项 配置说明 storm.zookeeper.servers ZooKeeper服务器列表 storm.zookeeper.port ZooKeeper连接端口 storm.local.dir storm使用的本地文件系统目录(必须存在并且storm进程可读写) storm.cluster.mode Storm集群运行模式([distributed\\ local]) storm.local.mode.zmq Local模式下是否使用ZeroMQ作消息系统，如果设置为false则使用java消息系统。默认为false storm.zookeeper.root ZooKeeper中Storm的根目录位置 storm.zookeeper.session.timeout 客户端连接ZooKeeper超时时间 storm.id 运行中拓扑的id,由storm name和一个唯一随机数组成。 nimbus.host nimbus服务器地址 nimbus.thrift.port nimbus的thrift监听端口 nimbus.childopts 通过storm-deploy项目部署时指定给nimbus进程的jvm选项 nimbus.task.timeout.secs 心跳超时时间，超时后nimbus会认为task死掉并重分配给另一个地址。 nimbus.monitor.freq.secs nimbus检查心跳和重分配任务的时间间隔.注意如果是机器宕掉nimbus会立即接管并处理。 nimbus.supervisor.timeout.secs supervisor的心跳超时时间,一旦超过nimbus会认为该supervisor已死并停止为它分发新任务. nimbus.task.launch.secs task启动时的一个特殊超时设置.在启动后第一次心跳前会使用该值来临时替代nimbus.task.timeout.secs. nimbus.reassign 当发现task失败时nimbus是否重新分配执行。默认为真，不建议修改。 nimbus.file.copy.expiration.secs nimbus判断上传/下载链接的超时时间，当空闲时间超过该设定时nimbus会认为链接死掉并主动断开 ui.port Storm UI的服务端口 drpc.servers DRPC服务器列表，以便DRPCSpout知道和谁通讯 drpc.port Storm DRPC的服务端口 supervisor.slots.ports supervisor上能够运行workers的端口列表.每个worker占用一个端口,且每个端口只运行一个worker.通过这项配置可以调整每台机器上运行的worker数.(调整slot数/每机) supervisor.childopts 在storm-deploy项目中使用,用来配置supervisor守护进程的jvm选项 supervisor.worker.timeout.secs supervisor中的worker心跳超时时间,一旦超时supervisor会尝试重启worker进程. supervisor.worker.start.timeout.secs supervisor初始启动时，worker的心跳超时时间，当超过该时间supervisor会尝试重启worker。因为JVM初始启动和配置会带来的额外消耗，从而使得第一次心跳会超过supervisor.worker.timeout.secs的设定 supervisor.enable supervisor是否应当运行分配给他的workers.默认为true,该选项用来进行Storm的单元测试,一般不应修改. supervisor.heartbeat.frequency.secs supervisor心跳发送频率(多久发送一次) supervisor.monitor.frequency.secs supervisor检查worker心跳的频率 worker.childopts supervisor启动worker时使用的jvm选项.所有的”%ID%”字串会被替换为对应worker的标识符 worker.heartbeat.frequency.secs worker的心跳发送时间间隔 task.heartbeat.frequency.secs task汇报状态心跳时间间隔 task.refresh.poll.secs task与其他tasks之间链接同步的频率.(如果task被重分配,其他tasks向它发送消息需要刷新连接).一般来讲，重分配发生时其他tasks会理解得到通知。该配置仅仅为了防止未通知的情况。 topology.debug 如果设置成true，Storm将记录发射的每条信息。 topology.optimize master是否在合适时机通过在单个线程内运行多个task以达到优化topologies的目的. topology.workers 执行该topology集群中应当启动的进程数量.每个进程内部将以线程方式执行一定数目的tasks.topology的组件结合该参数和并行度提示来优化性能 topology.ackers topology中启动的acker任务数.Acker保存由spout发送的tuples的记录，并探测tuple何时被完全处理.当Acker探测到tuple被处理完毕时会向spout发送确认信息.通常应当根据topology的吞吐量来确定acker的数目，但一般不需要太多.当设置为0时,相当于禁用了消息可靠性,storm会在spout发送tuples后立即进行确认. topology.message.timeout.secs topology中spout发送消息的最大处理超时时间.如果一条消息在该时间窗口内未被成功ack,Storm会告知spout这条消息失败。而部分spout实现了失败消息重播功能。 topology.kryo.register 注册到Kryo(Storm底层的序列化框架)的序列化方案列表.序列化方案可以是一个类名,或者是com.esotericsoftware.kryo.Serializer的实现. topology.skip.missing.kryo.registrations Storm是否应该跳过它不能识别的kryo序列化方案.如果设置为否task可能会装载失败或者在运行时抛出错误. topology.max.task.parallelism 在一个topology中能够允许的最大组件并行度.该项配置主要用在本地模式中测试线程数限制. topology.max.spout.pending 一个spout task中处于pending状态的最大的tuples数量.该配置应用于单个task,而不是整个spouts或topology. topology.state.synchronization.timeout.secs 组件同步状态源的最大超时时间(保留选项,暂未使用) topology.stats.sample.rate 用来产生task统计信息的tuples抽样百分比 topology.fall.back.on.java.serialization topology中是否使用java的序列化方案 zmq.threads 每个worker进程内zeromq通讯用到的线程数 zmq.linger.millis 当连接关闭时,链接尝试重新发送消息到目标主机的持续时长.这是一个不常用的高级选项,基本上可以忽略. java.library.path JVM启动(如Nimbus,Supervisor和workers)时的java.library.path设置.该选项告诉JVM在哪些路径下定位本地库. 环境准备 从Storm官网下载Storm安装包，本文使用的Storm版本为1.2.2 从Zookeeper官网下载Zookeeper安装包 开始安装配置由于Zookeeper和Storm都是以Java为基础开发的，所以需要Java环境，在Linux服务器上配置Java开发环境，此处不做累述，读者请自行百度。 搭建Zookeeper集群参考 Zookeeper集群搭建博客 搭建Storm集群配置1234wget https://www.apache.org/dyn/closer.lua/storm/apache-storm-1.2.2/apache-storm-1.2.2.tar.gztar -zxvf apache-storm-1.2.2.tar.gzcd apache-storm-1.2.2/confvi storm.yaml 主要的配置项有一下几点： 配置Storm集群的Zookeeper集群主机列表 1234storm.zookeeper.servers: - \"master\" - \"slave1\" - \"slave2\" 如果Zookeeper集群使用的端口与默认端口不同，还需一下配置： 1storm.zookeeper.port: 2182 指定Storm数据存储目录 Nimbus和Supervisor守护进程需要在本地磁盘上存储少量状态信息。需要我们手动在每台Supervisor机器上创建此目录，并授予适当的权限。 1storm.local.dir: \"/home/hadoop/storm/data\" 如果使用相对路径，可以相对于安装Storm的位置（STORM_HOME），或者使用默认值留空。 1$STORM_HOME/data supervisor的worker数量配置 以下配置指定supervisor的工作节点，可以运行的worker数量，每个worker占用一个端口来接收消息，最多分配5个；默认情况下每个节点可以运行4个worker，分别在6700、6701、6702、6703，此处定义几个端口，则就表示可以运行几个worker。 12345supervisor.slots.ports: - 6700 - 6701 - 6702 - 6703 此处为最基本的配置，若需其他对集群的优化配置，请查看官网Storm集群搭建教程，上面有详细的配置方式。（英语较差的童鞋，不要害怕英文文档，试着读，多读几遍，慢慢的大概意思也会了解了，有道是“书读百遍其义自见”） 启动集群 在Nimbus主机上启动nimbus 1bin/storm nimbus 2&gt;&amp;1 &amp; 在每个Storm集群节点上启动supervisor 1bin/storm supervisor 2&gt;&amp;1 &amp; 在Nimbus主机上启动Storm UI 1bin/storm ui 2&gt;&amp;1 &amp;","permalink":"/2018/08/07/storm集群搭建/","tags":[{"name":"大数据","slug":"大数据","permalink":"/tags/大数据/"}]},{"title":"zookeeper集群搭建","date":"2018-08-07T05:43:07.000Z","path":"2018/08/07/zookeeper集群搭建/","text":"zookeeper集群搭建本文的所有配置及集群的搭建，都是基于zookeeper-3.4.10的。 zoo.cfg配置详解 参数名 说明 clientPort 客户端连接Server的端口，即对外服务端口，一般设置为2181 dataDir 存储快照文件snapshot的目录。默认情况下，事务日志也会存储在这里。建议同时配置参数dataLogDir，事务日志的写性能直接影响zk性能 tickTime zk中的一个时间单元，zk中所有时间都是以这个时间单元为基础，进行整数倍配置的。例如，session的最小超时时间是2*tickTime dataLogDir 事务日志输出目录。尽量给事务日志的输出配置单独的磁盘或是挂载点，这将极大的提升zk性能（No Java System Property） globalOutstandingLimit 最大请求堆积数。默认是1000。zk运行的时候，尽管server已经没有空闲来处理更多的客户端请求了，但还是允许客户端将请求提交到服务器上来，以提高吞吐性能。当然，为了防止Server内存溢出，这个请求堆积数还是需要限制下的。(Java System Property:zookeeper.globalOutstandingLimit) preAllocSize 预先开辟磁盘空间，用于后续写入事务日志。默认是64M，每个事务日志大小就是64M。如果zk的快照频率较大的话，建议适当减小这个参数。（Java System Property:zookeeper.preAllocSize） snapCount 每进行snapCount次事务日志输出后，出发一次快照(snapshot)，此时，zk会生成一个snapshot.文件，同时创建一个新的事务日志文件log.\\。默认是100000.(真正的代码实现中，会进行一定的随机数处理，以避免所有服务器在同一时间进行快照而影响性能)。(Java System Property:zookeeper.snapCount) traceFile 用于记录所有请求的log，一般调试过程中可以使用，但是生产环境不建议使用，会严重影响性能。(Java System Property:zookeeper.requestTraceFile) maxClientCnxns 单个客户端与单台服务器之间的连接数的限制，是IP级别的，默认是60，如果设置为0，那么表明不作任何限制。请注意这个限制的使用范围，仅仅是单台客户端机器与单台zk服务器直接的连接数限制，不是针对指定客户端IP，也不是zk集群的连接数限制，也不是单台zk对所有客户端的连接数限制。 clientPortAddress 对于多网卡的机器，可以为每个IP指定不同的监听端口。默认情况是所有IP都监听clientPort指定的端口。 minSessionTimeoutmaxSessionTimeout Session超时时间限制，如果客户端设置的超时时间不在这个范围，那么会被强制设置为最大或最小时间。默认的Session超时时间是在2*tickTime~20*tickTime这个范文 fsync.warningthresholdms 事务日志输出时，如果调用fsync方法超过指定的超时时间，那么会在日志中输出警告信息。默认是1000ms。( Java system property: fsync.warningthresholdms) autopurge.purgeInterval 在上文中已经提到，3.4.0及之后版本，ZK提供了自动清理事务日志和快照文件的功能，这个参数指定了清理频率，单位是小时，需要配置一个1或更大的整数，默认是0，表示不开启自动清理功能。(No Java system property) autopurge.snapRetainCount 这个参数和上面的参数搭配使用，这个参数指定了需要保留的文件数目。默认是保留3个。(No Java system property) electionAlg 在之前的版本中， 这个参数配置是允许我们选择leader选举算法，但是由于在以后的版本中，只会留下一种“TCP-based version of fast leader election”算法，所以这个参数目前看来没有用了，这里也不详细展开说了。(No Java system property) initLimit Follower在启动过程中，会从Leader同步所有最新数据，然后确定自己能够对外服务的起始状态。Leader允许F在 initLimit 时间内完成这个工作。通常情况下，我们不用太在意这个参数的设置。如果ZK集群的数据量确实很大了，F在启动的时候，从Leader上同步数据的时间也会相应变长，因此在这种情况下，有必要适当调大这个参数了。(No Java system property) syncLimit 在运行过程中，Leader负责与ZK集群中所有机器进行通信，例如通过一些心跳检测机制，来检测机器的存活状态。如果L发出心跳包在syncLimit之后，还没有从F那里收到响应，那么就认为这个F已经不在线了。注意：不要把这个参数设置得过大，否则可能会掩盖一些问题。(No Java system property) leaderServes 默认情况下，Leader是会接受客户端连接，并提供正常的读写服务。但是，如果你想让Leader专注于集群中机器的协调，那么可以将这个参数设置为no，这样一来，会大大提高写操作的性能。(Java system property: zookeeper.leaderServes) server.x=[hostname]:nnnnn[:nnnnn] 这里的x是一个数字，与myid文件中的id是一致的。右边可以配置两个端口，第一个端口用于F和L之间的数据同步和其它通信，第二个端口用于Leader选举过程中投票通信。 (No Java system property) group.x=nnnnn[:nnnnn]weight.x=nnnnn 对机器分组和权重设置，可以 参见这里(No Java system property) cnxTimeout Leader选举过程中，打开一次连接的超时时间，默认是5s。(Java system property: zookeeper.cnxTimeout) zookeeper.DigestAuthenticationProvider.superDigest ZK权限设置相关，具体参见 《 使用super 身份对有权限的节点进行操作 》 和 《 ZooKeeper 权限控制 》 skipACL 对所有客户端请求都不作ACL检查。如果之前节点上设置有权限限制，一旦服务器上打开这个开头，那么也将失效。(Java system property: zookeeper.skipACL) forceSync 这个参数确定了是否需要在事务日志提交的时候调用 FileChannel .force来保证数据完全同步到磁盘。(Java system property:zookeeper.forceSync) jute.maxbuffer 每个节点最大数据量，是默认是1M。这个限制必须在server和client端都进行设置才会生效。(Java system property:jute.maxbuffer) zoo.cfg配置要求类型配置项描述最低配置clientPort监听客户端连接的端口，默认值为2181dataDir存储持久数据的本地文件系统位置tickTime基本事件单元，以毫秒为单位，用来控制心跳和超时，默认情况下超时时间为两倍的tickTime高级配置dataLogDir事件日志写入的目录maxClientCnxns限制连接到Zookeeper的客户端数量，并且限制并发连接数量，它通过ip区分不同的客户端minSessionTimeout与maxSessionTimeout最小会话超时时间和最大的会话超时时间，在默认情况下，最小的会话超时时间为两倍的tickTime时间，最大的会话超时时间为20倍的会话超时时间，系统启动时会显示相应的信息。默认为-1集群配置initLimit参数设定了允许所有Follower与Leader进行连接并同步的时间，如果在设定的时间段内，半数以上的Follower未能完成同步，Leader便会宣布放弃领导地位，进行另一次的Leader选举。如果zk集群环境数量确实很大，同步数据的时间会很变长，因此这种情况下可以适当调大该参数。默认为10syncLimit参数设定了允许一个Follower与一个Leader进行同步的时间，如果在设定的时间段内，Follower未完成同步，它将会被集群丢弃。所有连接到这个Follower的客户端将连接到另外一个Followerserver.A=B:C:D其中A是一个数字，表示这个是第几号服务器；B是这个服务器的IP地址或者主机名称；C表示的是Follower与Leader交换信息的端口，默认值为2888；D表示的是Leader选举端口，默认值为3888 集群搭建软件准备由于zookeeper是基于Java开发的，所以需要Java环境，需要的童鞋，请自行百度，安装Java环境 1234wget http://ftp.mirror.tw/pub/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gztar -zxvf zookeeper-3.4.10.tar.gzcd zookeeper-3.4.10/confmv zoo_sample.cfg 注意： zookeeper默认配置文件为zoo_sample.cfg，需要自定义配置时，需要将此配置文件修改为zoo.cfg，注意，zoo.cfg和zoo_sample.cfg文件不能同时存在 集群配置 zoo.cfg对此配置文件的配置项不做解释，每项具体含义，上面都有详细解释，读者可自行查阅1234567891011tickTime=2000initLimit=10syncLimit=5dataDir=/home/zk/zookeeper-3.4.10/data/dataLogDir=/home/zk/zookeeper-3.4.10/logs/clientPort=2181autopurge.snapRetainCount=500autopurge.purgeInterval=24server.1=192.168.11.12:2888:3888server.2=192.168.11.13:2888:3888server.3=192.168.11.14:2888:3888 然后将配置文件同步到其他两台服务器上。推荐使用scp命令，如： 1scp /home/zk/zookeeper-3.4.10/conf/zoo.cfg zk@192.168.11.12:/home/zk/zookeeper-3.4.10/conf 创建ServerID标识（敲黑板了，此处是重点） 在192.168.11.12服务器的/home/zk/zookeeper-3.4.10/data目录下，新建myid文件，输入1；其他服务器上类似，myid与server.x=192.168.11.12:2888:3888的x匹配。 1echo \"1\" &gt; /home/zk/zookeeper-3.4.10/data/myid 启动集群在三台服务器上执行以下命令。 1sh zkServer.sh start 注意： 启动zookeeper常见问题有以下几点： 启动第一台zk节点时，查看日志，可以看见有异常，因为其他节点未启动，zk检查线程未找到zk集群的其他节点，所以报错。将其他节点起起来即可。 节点启动成功，但是不能正常连接，请开发zk集群涉及到的防火墙端口 启动节点报错，极有可能是zoo.cfg配置文件配置有误，请检查配置文件配置项是否正确 其他问题请自行百度（解决问题是一个程序员最基本的能力） 如果一些童鞋的服务器或虚拟机资源不足，可使用zookeeper的伪集群方式部署，思路：通过在同一台机器上，启动不同端口的zookeeper，即可构成集群，此处就不再累述了。","permalink":"/2018/08/07/zookeeper集群搭建/","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"/tags/zookeeper/"}]},{"title":"redis常用配置","date":"2018-02-08T14:51:33.000Z","path":"2018/02/08/redis系统学习/","text":"Redis1、基本配置 Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程1daemonize no 当Redis以守护进程方式运行时，Redis会默认把pid写入/var/run/redis.pid文件，可以通过pidfile指定 1pidfile /var/run/redis.pid 指定Redis监听端口，默认端口为6379 1port 6379 绑定主机地址 1bind 127.0.0.1 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 1timeout 300 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose 1loglevel verbose 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null 1logfile stdout 设置数据库的数量，默认数据库有16个（0-15），默认使用0，可以使用SELECT \\&lt;dbid> 命令在连接上指定数据库id 1databases 16 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 1save &lt;seconds&gt; &lt;changes&gt; Redis默认配置文件中提供了三个条件 123save 900 1save 300 10save 60 10000 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但是会导致数据库文件变大 1rdbcompression yes 指定本地数据库文件名，默认值为dump.rdb 1dbfilename dump.rdb 指定本地数据库存放目录 1dir ./ 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 1slaveof &lt;masterip&gt; &lt;masterport&gt; 当master服务设置了密码保护时，slav服务连接master的密码 1masterauth &lt;master-password&gt; 如果配置了连接密码，客户端在链接Redis时需要通过AUTH \\&lt;password>命令提供密码，默认关闭 1requirepass foobared 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置maxclients 0，表示不做限制。当客户端连接数达到限制时，Redis会关闭新的连接并像客户端返回max number of clients reached错误信息 1maxclients 128 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理后，仍然达到最大内存限制，将无法再进行写操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放到swap区 1maxmemory &lt;bytes&gt; 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面的save条件同步的，所以有的数据会在一段时间内只存在于内存中，默认为no 1appendonly no 指定更新日志文件名，默认为appendonly.aof 1appendfilename &quot;appendonly.aof&quot; 指定更新日志条件，共有3个可选值 no：表示等操作系统进行数据缓存同步到磁盘（快） always：表示每次更新操作后手动调用fsync() 将数据写到磁盘（慢，安全） everysec：表示每次同步一次（折衷，默认值） 1appendfsync everysec 指定是否启用虚拟内存机制，默认值为no，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动缓存到内存中 1vm-enabled no 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 1vm-swap-file /tmp/redis.swap 将所有大于vm-max-memory的数据存入虚拟内存，无论vm-max-memory设置多小，所有索引数据都是内存存储的（Redis的索引数据就是keys），也就是说，当vm-max-memory设置为0的时候，其实是所有value都存在于磁盘。默认值为0 1vm-max-memory 0 Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的数据大小来设定的，如果存储很多小对象，page大小最好设置为32或者64bytes，如果存储很多的大对象，则可以使用更大的page，如果不确定，就使用默认值 1vm-page-size 32 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是存放在内存中的，在磁盘上每8个pages将消耗1byte的内存 1vm-pages 134217728 设置访问swap文件的线程数，最好不要超过机器的核数，如果设置为0，那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟，默认值为4 1vm-max-threads 4 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启 1glueoutputbuf yes 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 12hash-max-zipmap-entries 64hash-max-zipmap-value 512 指定是否激活重置哈希，默认为开启 1activerehashing yes 2、常用操作（高级）Redis官网命令详解 2.1 事务操作Redis的事务也有两种，乐观锁和悲观锁。 悲观锁，直接给这个key加锁，这个key只能当前连接可以操作。 乐观锁，给这个key加锁，只要这个key的值没有更改就可以了。 Redis的事务中，默认启用的是乐观锁，只负责监测key有没有变动。 12345watch key1 key2 监听key有没有变化，如果有变化，则事务取消，在multi之前使用unwatch key1 key2 不加具体key时，取消所有key的监听。multi 开启事务...discard/exec 取消事务/提交事务 注意：如果在exec时，命令语法有问题，这时所有的语句都得不到执行。如果语法本身没问题，但是适用的对象有问题，exec之后，会执行正确的语句，并跳过有问题的语句。 2.2 消息的发布与订阅使用办法： 订阅端：subscribe 频道名称 psubscribe 支持表达式匹配的频道 返回值为订阅到消息的客户端数量 发布端：publish 频道名称 发布内容 2.3 Redis持久化配置 持久化 把数据存储于断电后不会丢失的设备中，通常是硬盘 常见的持久化方式 主从：通过主服务器往内存中写，从服务器做保存和持久化 日志：操作生成相关日志，并通过日志来恢复数据，couchDB对于数据内容，不修改，只追加，则文件本身就是日志，不会丢失数据。 2.3.1 rdb快照持久化 rdb工作原理 每隔N分钟或N次写操作后，从内存dump数据形成rdb文件，压缩放在备份目录 rdb快照相关参数 12345678save 900 1 #刷新快照到磁盘中，必须满足两者要求才会触发，即900秒之内至少1个关键字发生变化save 300 10 #必须是300秒之内至少10个关键字发生变化save 60 10000 #必须是60秒之内至少10000个关键字发生变化stop-writes-on-bgsave-error yes #后台存储错误停止写rdbrdbcompression yes #使用LZF压缩rdb文件rdbchecksum yes #导入rdb恢复时数据时，要不要校验rdb的完整性dbfilename dump.rdb #设置rdb文件名dir ./ #设置工作目录，rdb文件会写入该目录 rdb的缺陷 在上一个保存点刚结束，下个保存点还没到时如果断电，将会丢失1-N分钟的数据 rdb的优势 由于导出的是一个内存的二进制文件，所以rdb文件的恢复速度超级快 2.3.2 aof日志持久化 aof工作原理 redis客户端连接redis服务器后所进行的每一条命令的操作都逐条记录到aof日志中，在恢复数据时，只需要将日志中记录的命令都依次执行一遍即可。 aof配置参数 123456789appendonly yes #是否打开aof日志功能appendfilename &quot;appendonly.aof&quot; #设置aof文件名appendfsync everysec #折衷方案，每秒写一次appendfsync no #写入工作交给操作系统，由操作系统判断缓冲区大小，统一写入到aof，同步频率低，速度快appendfsync always #每一个命令都立即同步到aof，安全，速度慢no-appendfsync-on-rewrite no #正在到处rbd快照的过程中，要不要停止同步aofauto-aof-rewrite-percentage 100 #aof文件大小比起上次重写时的大小，增长率100%时进行重写auto-aof-rewrite-min-size 64mb #aof文件，至少超过64M时进行重写# 上面两个aof重写规则同时满足aof才会进行重写 aof的缺陷 由于项目使用redis，就是图redis的读写速度快，但是如果频繁写磁盘，也会拉低效率的，而且越往后，aof日志文件会越来越大的。 aof的优势 使用日志记录操作，能有效的保证数据的完整性，就算太巧合了，在刚执行了命令还没来得及同步aof时断电了，那也只会丢失当前的一条命令。 aof重写 把内存中的数据，逆化成命令写到aof日志里，以解决aof日志过大的问题。 2.3.3 总结1、在dump过程中，aof如果停止同步，数据不会丢失，因为所有的操作会缓存在队列里，dump完成后，统一操作 2、如果rdb和aof文件都存在，它会采用谁优先就用谁来恢复数据，也就是会用aof 3、对于rdb和aof两种持久化方式，没有绝对的谁好谁坏，所以可以两者同时用，效果更优 4、rdb和aof相比，rdb的数据恢复更快，因为rdb的数据是内存映射，可以直接载入到内存，而aof是一条条的命令，需要逐条执行 2.4 Redis主从复制此处使用 4.0.2 的版本，搭建一主两从的Redis集群。 环境准备 从此处下载redis-4.0.2.tar.gz，解压之后，编译源码进行安装。 1234$ wget http://download.redis.io/releases/redis-4.0.2.tar.gz$ tar -zxvf redis-4.0.2.tar.gz$ cd redis-4.0.2$ make &amp;&amp; make install 在用户家目录下新建redis相关目录 12345$ cd ~$ make redis$ cd redis$ mkdir master# mkdir slave 然后拷贝redis-4.0.2目录中的redis.conf配置文件到master，修改为redis_master.conf，slave中拷贝两份，分别命名为redis_slave1.conf，redis_slave2.conf。 接下来修改配置文件内容（只贴出关键几个点，其他辅助内容请读者自行修改）：redis_master.conf 12port 7000daemonize yes redis_slave1.conf 123port 7001daemonize yesslaveof localhost 7000 redis_slave2.conf 123port 7002daemonize yesslaveof localhost 7000 分别启动三个节点： 123$ ./redis-4.0.2/src/redis-server ./master/redis_master.conf$ ./redis-4.0.2/src/redis-server ./slave/redis_slave1.conf$ ./redis-4.0.2/src/redis-server ./slave/redis_slave2.conf 登录进master节点，查看主从模式是否正常启动(主节点上能显示出两个从节点即可) 12$ ./redis-4.0.2/src/redis-cli&gt; info replication 2.5 三主三从三哨兵集群模式redis编译安装和上面一样 2.5.1 环境准备master 1192.168.10.100:6380,192.168.10.100:6381,192.168.10.100:6382 slave 1192.168.10.100:6383,192.168.10.100:6384,192.168.10.100:6385 sentinel 1192.168.10.100:26380,192.168.10.100:26381,192.168.10.100:26382 2.5.2 修改配置文件手动在服务器上新建6380,6381,6382,6383,6384,6385几个目录，将redis.conf配置文件每个目录拷贝一份（批量拷贝文件时，最好参考linux中xargs命令；当然，也可以cp多执行几次）。 redis.conf配置文件修改 1234567891011121314151617181920# 端口分别为6380,6381,6382,6383,6384,6385port 6380# 默认端口为127.0.0.1，改为本机地址则为任意服务器都可以访问，若只指定服务器访问，则改为指定服务器ip即可，由于当前是一台服务器上的伪集群，所以配置本机ip地址。bind 192.168.10.100# Redis后台运行daemonize yes# pidfile文件对应存放目录(redis节点进程号)pidfile /home/admin/redis/cluster/6380/redis.pid# 操作日志logfile &quot;/home/admin/redis/cluster/6380/redis.log&quot;# 数据文件存放目录dir /home/admin/redis/cluster/6380/# 是否开启集群(重点)cluster-enabled yes# 集群节点配置，集群首次启动自动生成cluster-config-file nodes.conf# 集群节点连接超时时间cluster-node-timeout 15000# aof日志开启，可做为日志记录，也可借此恢复数据appendonly yes 其他节点类似。 然后启动每一个节点 123456$ ./redis-4.0.2/src/redis-server ./cluster/7000/redis.conf$ ./redis-4.0.2/src/redis-server ./cluster/7001/redis.conf$ ./redis-4.0.2/src/redis-server ./cluster/7002/redis.conf$ ./redis-4.0.2/src/redis-server ./cluster/7003/redis.conf$ ./redis-4.0.2/src/redis-server ./cluster/7004/redis.conf$ ./redis-4.0.2/src/redis-server ./cluster/7005/redis.conf 2.5.3 创建集群这里创建集群借助于redis自己提供的一个集群创建工具redis-trib.rb（依赖于ruby环境） 1$ ./redis-4.0.2/src/redis-trib.rb create --replicas 1 192.168.10.100:6380 192.168.10.100:6381 192.168.10.100:6382 192.168.10.100:6383 192.168.10.100:6384 192.168.10.100:6385 根据提示完成集群创建 接下来验证集群是否搭建成功，连接其中一个节点 1234567891011121314$ ./redis-4.0.2/src/redis-cli -h 192.168.10.110 -p 6380&gt; cluster nodesdcebbc47abd482363f221020dd1be714a498b841 192.168.10.110:6382 master - 01524568524063 3 connected 10923-1638333eaf24ca33b4f5bcc37c2a7434bddaf5432f057 192.168.10.110:6380 myself,master - 0 0 1connected 0-546051ed0849bf29de0221eb3b9b4ccbebfd341593ad 192.168.10.110:6384 slave409b146c1fc86acfd6198c491cf77eaf8c8c7c04 0 1524568525066 5 connectede29d4537e924f0e29f5155536a636b35a44a8c24 192.168.10.110:6383 slave33eaf24ca33b4f5bcc37c2a7434bddaf5432f057 0 1524568523562 4 connecteddc4f070c42f9002e1c54bb6019ee4c34331570cc 192.168.10.110:6385 slavedcebbc47abd482363f221020dd1be714a498b841 0 1524568523062 6 connected409b146c1fc86acfd6198c491cf77eaf8c8c7c04 192.168.10.110:6381 master - 01524568524063 2 connected 5461-10922 输入info replication可查看节点信息。 2.5.4 哨兵搭建新建sentinel/26380,26381,26382目录，将redis家目录下的sentinel.conf文件拷贝到每个目录中 sentinel.conf 123456789bind 192.168.10.100port 26380daemonize yesdir &quot;/home/admin/redis/cluster/sentinel/26380&quot;# 故障转移配置# 表示哨兵集群中，至少有两个节点认为Redis节点挂掉，则将节点从集群中剔除sentinel monitor mymaster 192.168.10.100 6380 2sentinel config-epoch mymaster 0sentinel leader-epoch mymaster 0 其他的类似 启动哨兵 123$ ./redis-4.0.2/src/redis-sentinel ./cluster/sentinel/26380/sentinel.conf$ ./redis-4.0.2/src/redis-sentinel ./cluster/sentinel/26381/sentinel.conf$ ./redis-4.0.2/src/redis-sentinel ./cluster/sentinel/26382/sentinel.conf 查看哨兵节点信息 12345678$ ./redis-4.0.2/src/redis-cli -h 192.168.10.110 -p 26380&gt; info Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=cpicmaster,status=ok,address=192.168.10.110:6380,slaves=1,sentinels=3","permalink":"/2018/02/08/redis系统学习/","tags":[{"name":"Redis","slug":"Redis","permalink":"/tags/Redis/"}]},{"title":"对前后台分离的思考","date":"2018-01-04T03:17:33.000Z","path":"2018/01/04/对前后台分离的思考/","text":"对前后台分离的思考前言传统的javaweb项目，在开发的过程中，没有明确的分工，后台人员即要写后台，也要做数据库，更要写页面，而且传统的javaweb项目，大多都是jsp，有时候没有明确的规范，jsp页面加入大量的java代码，导致项目前后台杂乱不堪。 随着时代的发展，各种前后台框架的出现，前段知识大量增加，如果还保持着传统项目架构，后端人员工作量大大增加，需要学习的知识也同步增加，最终造成的结果就是啥都懂一点，啥都不精。 慢慢的，前后端分离架构出现了，前端人员专心研究前端的事，后端人员专心提高后端的事，正所谓术业有专攻。 正文前后端分离，大体上就是前端页面和后端的交互只通过json。页面的跳转等都由前端控制，后端只负责为页面提供数据。 在公司为期将近一年的开发中，各种新项目，老项目都渐渐的采用前后端分离架构，对这种架构模式也有了一点初步的认识，接下来就说说我在项目中对前后端分离的各种体会。 首先，先说说在开发中，因为前后端分离产生的一些问题。 在开发中，因为基本上前端都是那种特别纯粹的前端人员，也就是只懂前端，不了解java，不了解oracle，不了解业务，不了解网络协议等等各种基础知识即特性，在开发中出现了各种问题，比如请求中cookie丢失不知如何处理，功能开发完成之后不知如何测试，不懂业务导致不知道自己做出的页面到底对不对等等各种问题，而且由于后台只提供数据，不做页面跳转，所以在和传统项目做SSO单点登录的时候更麻烦。 当然，前后台分离也并不是没有好处。 开发人员的职能划分更加明确，前后端人员各自考虑自己职能范围内的事，比如前端人员可以专心提高页面的用户体验，而后端人员则专注于接口开发和后台性能 前后端能够同步进行，事先定义好接口，前后端同步进行，到后面只需要进行对接联调即可 前台基本上采用静态页面，响应速度快 前后端分离了，可以分开部署，也可以分开做负载处理 针对前后端分离架构的项目准备工作由于前后端分离，前后端由不同的人员去开发，所以项目的准备工作一定要做到位。 项目必须要有详细的API，并且能够测试数据，以便前端人员能够在最短的时间内拿到正确的API，swagger就挺不错的，后端API有改动时，能够实时反映出来。 对于页面功能，最好有明确的模型图 在项目开始时，前后端人员必须都对业务有所了解，“脱离业务的项目架构都是耍流氓”，忘记出自哪里了。 目前大概只有这些体会了，后面有更深的理解，会继续补充。","permalink":"/2018/01/04/对前后台分离的思考/","tags":[{"name":"项目架构,前后端分离","slug":"项目架构-前后端分离","permalink":"/tags/项目架构-前后端分离/"}]},{"title":"lombok常用注解","date":"2017-09-07T15:43:12.000Z","path":"2017/09/07/lombok使用/","text":"LombokProject Lombok is a java library that automatically plugs into your editor and build tools, spicing up your java.Never write another getter or equals method again. Early access to future java features such as val, and much more. 这是lombok官网的解释，大概意思是说lombok项目是一个java库，会自动处理代码的编译，比如你不用写getter方法，它就会自动帮你实现。 下面简单介绍一些在开发中常用的注解。 Lombok常用注解@Getter可标注到类或属性上，标注到类上表示此类中的所有属性生成getter方法，标注到某个属性上，表示此属性生成getter方法。 @Setter和@Getter类似，可标注到类或属性上，标注到类上表示此类中的所有属性生成setter方法，标注到某个属性上，表示此属性生成setter方法。 @ToString只能标注到类上，相当于是重写此类的toString方法。 @EqualsAndHashCode只能标注到类上，相当于是重写此类的hashCode和equals方法。 @NoArgsConstructor只能标注到类上，生成无参的构造方法。 @Data只能标注到类上，综合@Getter，@Setter，@ToString，@EqualsAndHashCode，@NoArgsConstructor五个注解的功能。 @Value只能标注到类上，综合@Getter，@Setter，@ToString，@EqualsAndHashCode，@NoArgsConstructor五个注解的功能，和@Data不同的是，默认将所有属性定义成final的，也就是只会生成getter方法，不会生成setter方法，如果不需要final，则给属性加上@NonFinal注解即可。 @AllArgsConstructor只能标注到类上，生成包含所有属性的构造方法，使用此注解时建议和@NoArgsConstructor结合使用，否则此类将没有无参的构造方法。 @RequiredArgsConstructor只能标注到类上，会生成一个包含常量，和标识了@NotNull的变量 的构造方法。生成的构造方法是private，如何想要对外提供使用可以使用staticName选项生成一个static方法。如： 1234@RequiredArgsConstructor(staticName = \"passwd\")public class User &#123; @NonNull private String password;&#125; 上面代码编译后对应下面的代码 12345678public class User &#123; private User(String password) &#123; this.password = password; &#125; public static User passwd(String password) &#123; return new User(password); &#125;&#125; @Builder只能标注到类上，将生成类的一个当前流程的一种链式构造工厂，如下： 1User buildUser = User.builder().password(\"haha\").username(\"gaga\").build(); 可配合@Singular注解使用，@Singular注解使用在jdk内部集合类型的属性，Map类型的属性以及Guava的com.google.common.collect 的属性上。例如 未标注@Singular的属性，一般setter时，会直接覆盖原来的引用，标注了@Singular的属性，集合属性支持添加操作，会在属性原来的基础上增加。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public static class UserBuilder &#123; private String username; private String password; private ArrayList&lt;String&gt; projects; UserBuilder() &#123; &#125; public User.UserBuilder username(String username) &#123; this.username = username; return this; &#125; public User.UserBuilder password(String password) &#123; this.password = password; return this; &#125; public User.UserBuilder project(String project) &#123; if (this.projects == null) this.projects = new ArrayList&lt;String&gt;(); this.projects.add(project); return this; &#125; public User.UserBuilder projects(Collection&lt;? extends String&gt; projects) &#123; if (this.projects == null) this.projects = new ArrayList&lt;String&gt;(); this.projects.addAll(projects); return this; &#125; public User.UserBuilder clearProjects() &#123; if (this.projects != null) this.projects.clear(); return this; &#125; public User build() &#123; Set&lt;String&gt; projects; switch (this.projects == null ? 0 : this.projects.size()) &#123; case 0: projects = java.util.Collections.emptySet(); break; case 1: projects = java.util.Collections.singleton(this.projects.get(0)); break; default: projects = new java.util.LinkedHashSet&lt;String&gt;(this.projects.size() &lt; 1073741824 ? 1 + this.projects.size() + (this.projects.size() - 3) / 3 : Integer.MAX_VALUE); projects.addAll(this.projects); projects = java.util.Collections.unmodifiableSet(projects); &#125; return new User(username, password, projects); &#125; public String toString() &#123; return \"User.UserBuilder(username=\" + this.username + \", password=\" + this.password + \", projects=\" + this.projects + \")\"; &#125; &#125; @Accessors可标注在类或属性上，当然最实用的功能还是标注到类上。 标注到类上，chain属性设置为true时，类的所有属性的setter方法返回值将为this，用来支持setter方法的链式写法。如： 1new User().setPassword(\"gaga\").setUsername(\"haha\"); fluent属性设置为true时，类的所有getter，setter方法将省略get和set前缀，获取属性值直接使用属性名相同的无参方法，设置属性值使用属性名相同的有参方法，并且返回值为this。如： 123User user = new User().password(\"gaga\").username(\"haha\");String password = user.password();String username = user.username(); 标注到属性上，使用prefix设置需要省略的属性生成getter，setter方法时的前缀，且属性必须为驼峰式命名。 如： 1234@Accessors(prefix = \"a\")@Getter@Setterprivate String aUsername = \"gaga\"; 编译之后为 123456public String getUsername() &#123; return aUsername;&#125;public void setUsername(String aUsername) &#123; this.aUsername = aUsername;&#125; 以上一些常用的lombok的用法介绍完了，在日常的开发或者自己的练习中，使用lombok并结合各版本的jdk特性，将更大的提高开发效率，提高开发质量。","permalink":"/2017/09/07/lombok使用/","tags":[{"name":"开发工具框架","slug":"开发工具框架","permalink":"/tags/开发工具框架/"}]},{"title":"lombok常用注解","date":"2017-09-07T15:43:12.000Z","path":"2017/09/07/常用排序算法(Java版)/","text":"LombokProject Lombok is a java library that automatically plugs into your editor and build tools, spicing up your java.Never write another getter or equals method again. Early access to future java features such as val, and much more. 这是lombok官网的解释，大概意思是说lombok项目是一个java库，会自动处理代码的编译，比如你不用写getter方法，它就会自动帮你实现。 下面简单介绍一些在开发中常用的注解。 Lombok常用注解@Getter可标注到类或属性上，标注到类上表示此类中的所有属性生成getter方法，标注到某个属性上，表示此属性生成getter方法。 @Setter和@Getter类似，可标注到类或属性上，标注到类上表示此类中的所有属性生成setter方法，标注到某个属性上，表示此属性生成setter方法。 @ToString只能标注到类上，相当于是重写此类的toString方法。 @EqualsAndHashCode只能标注到类上，相当于是重写此类的hashCode和equals方法。 @NoArgsConstructor只能标注到类上，生成无参的构造方法。 @Data只能标注到类上，综合@Getter，@Setter，@ToString，@EqualsAndHashCode，@NoArgsConstructor五个注解的功能。 @Value只能标注到类上，综合@Getter，@Setter，@ToString，@EqualsAndHashCode，@NoArgsConstructor五个注解的功能，和@Data不同的是，默认将所有属性定义成final的，也就是只会生成getter方法，不会生成setter方法，如果不需要final，则给属性加上@NonFinal注解即可。 @AllArgsConstructor只能标注到类上，生成包含所有属性的构造方法，使用此注解时建议和@NoArgsConstructor结合使用，否则此类将没有无参的构造方法。 @RequiredArgsConstructor只能标注到类上，会生成一个包含常量，和标识了@NotNull的变量 的构造方法。生成的构造方法是private，如何想要对外提供使用可以使用staticName选项生成一个static方法。如： 1234@RequiredArgsConstructor(staticName = \"passwd\")public class User &#123; @NonNull private String password;&#125; 上面代码编译后对应下面的代码 12345678public class User &#123; private User(String password) &#123; this.password = password; &#125; public static User passwd(String password) &#123; return new User(password); &#125;&#125; @Builder只能标注到类上，将生成类的一个当前流程的一种链式构造工厂，如下： 1User buildUser = User.builder().password(\"haha\").username(\"gaga\").build(); 可配合@Singular注解使用，@Singular注解使用在jdk内部集合类型的属性，Map类型的属性以及Guava的com.google.common.collect 的属性上。例如 未标注@Singular的属性，一般setter时，会直接覆盖原来的引用，标注了@Singular的属性，集合属性支持添加操作，会在属性原来的基础上增加。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public static class UserBuilder &#123; private String username; private String password; private ArrayList&lt;String&gt; projects; UserBuilder() &#123; &#125; public User.UserBuilder username(String username) &#123; this.username = username; return this; &#125; public User.UserBuilder password(String password) &#123; this.password = password; return this; &#125; public User.UserBuilder project(String project) &#123; if (this.projects == null) this.projects = new ArrayList&lt;String&gt;(); this.projects.add(project); return this; &#125; public User.UserBuilder projects(Collection&lt;? extends String&gt; projects) &#123; if (this.projects == null) this.projects = new ArrayList&lt;String&gt;(); this.projects.addAll(projects); return this; &#125; public User.UserBuilder clearProjects() &#123; if (this.projects != null) this.projects.clear(); return this; &#125; public User build() &#123; Set&lt;String&gt; projects; switch (this.projects == null ? 0 : this.projects.size()) &#123; case 0: projects = java.util.Collections.emptySet(); break; case 1: projects = java.util.Collections.singleton(this.projects.get(0)); break; default: projects = new java.util.LinkedHashSet&lt;String&gt;(this.projects.size() &lt; 1073741824 ? 1 + this.projects.size() + (this.projects.size() - 3) / 3 : Integer.MAX_VALUE); projects.addAll(this.projects); projects = java.util.Collections.unmodifiableSet(projects); &#125; return new User(username, password, projects); &#125; public String toString() &#123; return \"User.UserBuilder(username=\" + this.username + \", password=\" + this.password + \", projects=\" + this.projects + \")\"; &#125; &#125; @Accessors可标注在类或属性上，当然最实用的功能还是标注到类上。 标注到类上，chain属性设置为true时，类的所有属性的setter方法返回值将为this，用来支持setter方法的链式写法。如： 1new User().setPassword(\"gaga\").setUsername(\"haha\"); fluent属性设置为true时，类的所有getter，setter方法将省略get和set前缀，获取属性值直接使用属性名相同的无参方法，设置属性值使用属性名相同的有参方法，并且返回值为this。如： 123User user = new User().password(\"gaga\").username(\"haha\");String password = user.password();String username = user.username(); 标注到属性上，使用prefix设置需要省略的属性生成getter，setter方法时的前缀，且属性必须为驼峰式命名。 如： 1234@Accessors(prefix = \"a\")@Getter@Setterprivate String aUsername = \"gaga\"; 编译之后为 123456public String getUsername() &#123; return aUsername;&#125;public void setUsername(String aUsername) &#123; this.aUsername = aUsername;&#125; 以上一些常用的lombok的用法介绍完了，在日常的开发或者自己的练习中，使用lombok并结合各版本的jdk特性，将更大的提高开发效率，提高开发质量。","permalink":"/2017/09/07/常用排序算法(Java版)/","tags":[{"name":"开发工具框架","slug":"开发工具框架","permalink":"/tags/开发工具框架/"}]},{"title":"Docker学习笔记","date":"2017-06-16T11:24:41.000Z","path":"2017/06/16/Docker学习笔记/","text":"[TOC] Docker基本操作Docker简介Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。 Docker的主要目标是“Build,Ship and Run Any App, Anywhere”，即通过对应用组件的封装（Packaging）、分发（Distribution）、部署（Deployment）、运行（Runtime）等生命周期的管理，达到应用组件级别的“一次封装，到处运行”（有点类似于java）。这里的应用组件，即可以是一个Web应用，也可以是一套数据库服务，甚至是一个操作系统或者编译器。 Docker的应用场景 Web 应用的自动化打包和发布。 自动化测试和持续集成、发布 在服务型环境中部署和调整数据库或其他的后台应用 从头编译或者扩展现有的OpenShift或Cloud Foundry平台来搭建自己的PaaS环境 Docker的优点 简化程序 Docker让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的Linux机器上，便可以实现虚拟化。Docker改变了虚拟化的方式，使开发者可以直接将自己的成果放入Docker中进行管理。过去需要数天乃至数周的任务，在Docker容器的处理下，只需要数秒就能完成。 避免选择恐惧症 Docker镜像中包含了运行环境和配置，所以Docker可以简化部署多种应用实例工作。比如Web应用、后台应用、数据库应用、大数据应用比如Hadoop集群、消息队列等等都可以打包成一个镜像部署。 节省开支 云计算时代的到来，使开发者不必为了追求效果而配置高额的硬件，Docker改变了高性能必然高价格的思维定势。Docker与云的结合，让云空间得到更充分的利用，不仅解决了硬件管理的问题，也改变了虚拟化的方式。 Centos的Docker安装与启动 检查Linux版本 1[docker@localhost ~]$ uname -r Docker要求Centos系统的内核版本高于3.10 安装Docker 切换到root用户，更新系统 1[root@localhost ~]# yum update 安装Docker 1[root@localhost ~]# yum -y install docker Docker软件包和依赖包已经包含在默认的Centos-Extras软件源里了。 如果这种方式不能安装，也可使用下面的命令进行安装 1[root@localhost ~]# curl -fsSL https://get.docker.com/ | sh 执行这个脚本后会添加docker.repo源并安装Docker 注：若安装失败，重新使用上面命令安装时有时会报错，只需要去家目录下的.docker目录中将docker的相关文件删除，然后重新执行命令下载即可。 启动Docker服务 1[root@localhost ~]# service docker start 测试 1[docker@localhost ~]$ docker run hello-world 由于本地没有hello-world这个镜像，所以会下载一个hello-world的镜像，并在容器中运行 Docker的基本使用 查看Docker常用命令 1[docker@localhost ~]$ docker 或者 1[docker@localhost ~]$ docker --help 如我们需要查看其中某个命令的使用方法，可使用以下命令 1[docker@localhost ~]$ docker run --help 运行一个web应用 我们在Docker容器中运行一个Python Flask应用来运行一个web应用 1[docker@localhost ~]$ docker run -d -P training/webapp python app.py 我们先来看看之前执行docker run –help命令后的结果吧 1docker run [OPTIONS] IMAGE [COMMAND] [ARG...] OPTIONS: 代表run命令的一些参数 IMAGE: 镜像名 COMMAND: 运行镜像之后要执行的命令 ARG…: 命令需要的一些参数 好了，我们现在来看看刚刚我们运行一个web应用的命令 -d, –detach=false Run container in background and print container ID 让容器在后台运行，默认是关闭的 -P, –publish-all=false Publish all exposed ports to random ports 让容器内部使用的网络端口映射到我们使用的主机上，默认是关闭的 注意: 我们这里用的是大写的-P 小写的-p手动将容器端口映射到宿主机上的端口，如 1[docker@localhost ~]$ docker run -d -p 5000:5000 training/webapp python app.py 查看WEB应用容器查看正在运行的容器123[docker@localhost ~]$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf5d5071807a8 training/webapp \"python app.py\" 13 seconds ago Up 12 seconds 0.0.0.0:32768-&gt;5000/tcp prickly_davinci 查看所有已构建的容器1docker ps -a 包括正在运行，已停止的等多个容器。 结果中有容器ID，镜像名，端口，容器名等信息，其中端口显示了prickly_davinci容器端口的映射情况，此时映射的端口是容器自动做的映射，如果我们运行时没使用-P，而是使用-p手动映射，此处则显示手动指定的端口。其次容器名称此处为容器自动指定的，我们可以通过–name来手动指定，如 1[docker@localhost ~]$ docker run -d -p 5000:5000 --name webapp training/webapp python app.py 上面默认都是绑定tcp端口，如果要绑定UDP端口，可以在端口后面加上/udp 1[docker@localhost ~]$ docker run -d -p 5000:5000/udp --name webapp training/webapp python app.py 查看容器端口映射 使用容器ID查看容器端口映射情况 12[docker@localhost ~]$ docker port f5d5071807a85000/tcp -&gt; 0.0.0.0:32768 使用容器名称查看端口映射情况 12[docker@localhost ~]$ docker port prickly_davinci5000/tcp -&gt; 0.0.0.0:32768 查看具体某个端口的映射情况 12[docker@localhost docker]$ docker port tomcat 80800.0.0.0:8080 接下来凡是使用容器标识操作的都使用容器名称，并且容器ID也支持相同的命令操 查看WEB应用程序日志1[docker@localhost ~]$ docker logs -f modest_banach -f: 让docker logs像使用tail -f一样来输出容器内部的标准输出 查看WEB应用程序容器的进程1[docker@localhost ~]$ docker top modest_banach 检查WEB应用程序1[docker@localhost ~]$ docker inspect modest_banach 停止WEB应用程序1[docker@localhost ~]$ docker stop modest_banach 启动WEB应用容器1[docker@localhost ~]$ docker start modest_banach 重启WEB应用容器1[docker@localhost ~]$ docker restart modest_banach 注：正在运行的容器我们可以使用restart来重启 移除WEB应用容器1[docker@localhost ~]$ docker rm modest_banach 注：移除容器时，容器必须是停止状态。 Docker镜像的使用查看本地镜像列表12[docker@localhost ~]$ docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE 各个选项说明： REPOSITORY: 表示镜像的仓库源 TAG: 镜像的标签 IMAGE ID: 镜像ID CREATED: 镜像创建时间 SIZE: 镜像大小 同一个仓库源可以有多个TAG，代表这个仓库源的不同个版本，如ubuntu仓库源里，有15.10,14.04等多个不同的版本，我们可以使用REPOSITORY:TAG来定义不同的镜像，如 1[docker@localhost ~]$ docker run -t -i ubuntu:15.10 /bin/bash 如果不指定镜像的版本标签，docker将默认使用latest镜像 获取一个新的镜像1[docker@localhost ~]$ docker pull ubuntu:15.10 查找镜像12[docker@localhost ~]$ docker search httpdNAME DESCRIPTION STARS OFFICIAL AUTOMATED NAME: 镜像仓库源的名称 DESCRIPTION: 镜像的描述 OFFICIAL: 是否是docker官方发布 拖取镜像1[docker@localhost ~]$ docker pull httpd 运行镜像1[docker@localhost ~]$ docker run httpd 自定义镜像创建镜像当我们从docker镜像仓库中下载的镜像不能满足我们的需求时，我们可以通过以下两种方式对镜像进行更改： 1、从已经创建的容器中更新镜像，并且提交这个镜像 2、使用Dockerfile指令来创建一个新的镜像 更新镜像在更新镜像之前，我们先用以下命令启动容器，在容器中使用apt-get update命令更新，完成操作后使用exit退出容器。 12[docker@localhost ~]$ docker run -t -i ubuntu:15.10 /bin/bashroot@2d60a31b8bdf:/# apt-get update 提交容器副本12[docker@localhost ~]$ docker commit -m=\"has update\" -a=\"ubuntu/update\" 2d60a31b8bdf ubuntu:v2ea547a1aa6de52e24092ff3ca13ae7ae58cd35123e2e58e6f3d784208af7ef5e -m: 提交的描述信息 -a: 指定镜像作者 2d60a31b8bdf: 容器ID runoob/ubuntu:v2: 指定要创建的目标镜像名 构建镜像创建Dockerfile，使用docker build命令来创建一个新的镜像 1234567891011[docker@localhost docker]$ cat DockerfileFROM centos:6.7MAINTAINER Fisher \"artislong@haha.com\"RUN /bin/echo 'root:123456' |chpasswdRUN useradd dockerRUN /bin/echo 'docker:123456' |chpasswdRUN /bin/echo -e \"LANG=\\\"en_US.UTF-8\\\"\" &gt;/etc/default/localEXPOSE 22EXPOSE 80CMD /usr/sbin/sshd -D Dockerfile是一个文本格式的配置文件，它由一行行命令语句（指令）组成，并且支持以#开头的注释行 每个指令都会在镜像上创建一个新的层，每个指令的前缀都必须大写。 第一条FROM，指定使用哪个镜像源 RUN指令告诉docker在镜像内执行命令，安装了什么。。。 然后我们通过Dockerfile文件来构建一个镜像 1[docker@localhost docker]$ docker build -t runoob/centos:6.7 . 千万不要忽略最后面的 “.”，它表示使用当前目录下的Dockerfile文件 -t: 指定要创建的目标镜像名 ​ 我们可以使用新的镜像来创建容器 123[docker@localhost docker]$ docker run -t -i runoob/centos:6.7 /bin/bash[root@ebd742bf9af0 /]# id dockeruid=500(docker) gid=500(docker) groups=500(docker) 从上面看到新镜像已经包含了我们创建的用户docker 设置镜像标签1[docker@localhost docker]$ docker tag f38a8f197ee4 runoob/centos:dev docker tag 镜像ID，镜像源名和新的标签名 Docker安装Nginx创建Nginx目录，用于存放后面相关文件1[docker@localhost ~]$ mkdir -p ~/nginx/www ~/nginx/logs ~/nginx/conf www目录将映射为nginx容器配置的虚拟目录 logs目录将映射为nginx容器的日志目录 conf目录里的配置文件将映射为nginx容器的配置文件 查找Docker Hub上的nginx镜像1[docker@localhost nginx]$ docker search nginx 拉取官方nginx镜像1[docker@localhost nginx]$ docker pull nginx 查看nginx本地镜像1[docker@localhost nginx]$ docker images nginx 使用nginx镜像运行容器1[docker@localhost nginx]$ docker run -i -t -d -p 80:8081 --name nginx -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -d nginx -p 80:8081: 将容器的80端口映射到宿主机的8081端口 -name nginx: 将容器命名为nginx -v $PWD/www:/www: 将主机中当前目录下的www目录挂载到容器的/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf: 将主机中当前目录下的nginx.conf挂载到容器的/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs: 将主机中当前目录下的logs挂载到容器的/wwwlogs 查看容器启动情况1[docker@localhost nginx]$ docker ps 通过浏览器访问访问路径为: http://主机ip:8081/ ，就可访问nginx Docker安装Tomcat创建tomcat的相关目录1[docker@localhost ~]$ mkdir -p ~/tomcat/webapps ~/tomcat/logs ~/tomcat/conf 查找Docker Hub上的tomcat镜像1[docker@localhost ~]$ docker search tomcat 拉取官方tomcat镜像1[docker@localhost ~]$ docker pull tomcat 创建测试文件 在~/tomcat/webapps目录下创建test目录 1[docker@localhost webapps]$ mkdir test 进入test目录，编写测试页面 1[docker@localhost test]$ vi index.html index.html文件内容： 12345678910&lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;docker中的tomcat测试&lt;/title&gt; &lt;/head&gt; &lt;body&gt; Hello, World! &lt;br&gt; 哈哈哈哈，运行成功啦啦啦啦啦 &lt;/body&gt;&lt;/html&gt; 运行tomcat容器 1[docker@localhost tomcat]$ docker run --name tomcat -p 8080:8080 -v $PWD/webapps/test:/usr/local/tomcat/webapps/test -d tomcat 命令说明： -v $PWD/webapps/test:/usr/local/tomcat/webapps/test: 将主机中当前目录下的test挂载到容器的/test 启动成功后，在浏览器访问：http://主机ip:8080/test/index.html即可访问刚才编写的测试页面 —————————————————————————分割线———————————————————————– Dockerfile镜像制作Dockerfile是一个文本格式的配置文件，用户可以使用Dockerfile快速创建自定义的镜像。 基本结构Dockerfile由一行行命令语句组成，并且支持以#开头的注释行。 一般Dockerfile文件分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令。 1234567891011121314# This dockerfile uses the ubuntu image# VERSION 2 - EDITION 1# Author:docker_user# Command format: Instruction [arguments / command] ..# 第一行必须制定基于的基础镜像FROM ubuntu# 维护者信息MAINTAINER docker_user docker_user@email.com# 镜像的操作指令RUN echo \"deb http://archive.ubuntu.com/ubuntu/ raring main universe\" &gt;&gt; /etc/apt/sources.listRUN apt-get update &amp;&amp; apt-get install -y nginxRUN echo \"\\ndaemon off;\" &gt;&gt; /etc/nginx/nginx.conf# 容器启动时执行指令CMD /usr/sbin/nginx Dockerfile文件编写时，一开始必须指明所基于的镜像名称，接下来一般会说明维护者信息 后面则是镜像操作指令，例如RUN指令，镜像增加新的一层，并提交。最后是CMD指令，来指定运行容器时的操作命令。 以下有两个摘自书上的Dockerfile例子： 123456# Ngnix# # VERSION 0.0.1FROM ubuntuMAINTAINER Victor Vieux &lt;victor@docker.com&gt;RUN apt-get update &amp;&amp; apt-get install -y inotify-tools nginx apache2 openssh-server 此Dockerfile文件是在ubuntu父镜像基础上安装inotify-tools、nginx、apache2、openssh-server软件，从而创建一个新的Nginx镜像 注 ：inotify-tools是为linux下inotify文件监控工具提供的一套c的开发接口库函数，同时还提供了一系列的命令行工具，这些工具可以用来监控文件系统的事件。 12345678910111213# Firefox over VNC# # VERSION 0.3FROM ubuntu# Install vnc, xvfb in order to reate a 'fake' display and firefoxRUN apt-get update &amp;&amp; apt-get install -y xllvnc xvfb firefoxRUN mkdir /.vnc# Setup a passwordRUN xllvnc -storepasswd 1234 ~/.vnc/passwd# Autostart firefox (might not be the best way, but it does the trick)RUN bash -c 'echo \"firefox\" &gt;&gt; /.bashrc'EXPOSE 5900CMD [\"xllvnc\", \"-forever\", \"-usepw\", \"-create\"] 此Dockerfile基于ubuntu父镜像，安装filefox和vnc软件，启动后，用户可以通过5900端口通过vnc方式使用firefox。 指令指令的一般格式为INSTRUCTION arguments，指令包括FROM、MAINTAINER、RUN等。 Dockerfile指令说明 指令 说明 FROM 指定所创建镜像的基础镜像 MAINTAINER 指定维护者信息 RUN 运行命令 CMD 指定启动容器时默认执行的命令 LABEL 指定生成镜像的元数据标签信息 EXPOSE 声明镜像内服务所监听的端口 ENV 指定容器环境变量 ADD 复制指定的 \\&lt;src> 路径下的内容到容器中的 \\&lt;dest> 路径下，\\&lt;src> 可以为URL；如果为tar文件，会自动解压到 \\&lt;dest> 路径下 COPY 复制本地主机的 \\&lt;src> 路径下的内容到镜像中的 \\&lt;dest> 路径下；一般情况下推荐使用COPY而不是ADD ENTRYPOINT 指定镜像的默认入口 VOLUME 创建数据卷挂载点 USER 指定运行容器时的用户名或UID WORKDIR 配置工作目录 ARG 指定镜像内使用的参数 （例如版本号信息等） ONBUILD 配置当所创建的镜像作为其他镜像的基础镜像时，所执行的创建操作指令 STOPSIGNAL 容器退出的信号值 HEALTHCHECK 如何进行健康检查 SHELL 指定使用shell时的默认shell类型 FROM1格式为 FROM &lt;image&gt; 或FROM&lt;image&gt;:&lt;tag&gt; 第一条指令必须为FROM指令。并且，如果在同一个Dockerfile中创建多个镜像时，可以使用多个FROM指令（每个镜像一次）。 MAINTAINER1格式为 MAINTAINER &lt;name&gt;, 指定维护者信息 RUN1格式为 RUN &lt;command&gt; 或 RUN [\"executable\", \"param1\", \"param2\"] RUN 将在shell终端中运行命令，即 /bin/sh -c RUN [“executable”, “param1”, “param2”]则使用exec执行。 指定使用其他终端可以通过第二种方式实现，例如 RUN [“/bin/bash”, “-c”, “echo hello”]。 每条RUN指令将在当前镜像基础上执行指令命令，并提交为新的镜像。当命令较长时可以用 \\ 来换行。 CMD支持三种格式 使用exec执行，推荐方式 1CMD [\"executable\", \"param1\", \"param2\"] 在/bin/sh中执行，提供给需要交互的应用 1CMD command param1 param2 提供给ENTRYPOINT的默认参数 1CMD [\"param1\", \"param2\"] 指定启动容器时执行的命令，每个Dockerfile只能有一条CMD命令。如果指定了多条命令，只有最后一条会被执行。 如果用户启动容器时指定了运行的命令，则会覆盖掉CMD指定的命令。 EXPOSE1格式为 EXPOSE &lt;port&gt; [&lt;port&gt;...] 例如：EXPOSE 22 80 8443 就是告诉Docker服务器容器暴露的端口号，供互联系统使用。在启动容器时需要通过-P或者-p来指定端口映射。 ENV1格式为 ENV &lt;key&gt; &lt;value&gt; 指定一个环境变量，会被后续RUN指令使用，并在容器运行时保持。例如： 1234ENV PG_MAJOR 9.3ENV PG_VERSION 9.3.4RUN curl -SL http://example.com/postgres-$PG_VERSION.tar.xz | tar -xJC /usr/src/postgress &amp;&amp; ...ENV PATH /usr/local/postgres-$PG_MAJOR/bin:$PATH ADD1格式为 ADD &lt;src&gt; &lt;dest&gt; 该命令将复制指定的到容器中的。其中可以是Dockerfile所在目录的一个相对路径（文件或目录）；也可以是一个URL；还可以是一个tar文件（自动解压为目录）。 COPY1格式为 COPY &lt;src&gt; &lt;dest&gt; 复制本地主机的（为Dockerfile所在目录的相对路径，文件或目录）为容器中的。目标路径不存在时，会自动创建。 当使用本地目录为源目录时，推荐使用COPY ENTRYPOINT 使用exec执行，推荐方式 1ENTRYPOINT [\"executable\", \"param1\", \"param2\"] 在shell中执行 1ENTRYPOINT command param1 param2 配置容器启动后执行的命令，并且不可被docker run提供的参数覆盖 每个Dockerfile中只能有一个ENTRYPOINT，当制定多个ENTRYPOINT时，只有最后一个生效。 VOLUME1格式为 VOLUME [\"/data\"] 创建一个可以从本地主机或其他容器挂载的挂载点，一般用来存放数据库和需要保持的数据等。 USER1格式为 USER daemon 指定运行容器时的用户名或UID，后续的RUN也会使用指定的用户。 当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户，例如： 1RUN groupadd -r postgres &amp;&amp; useradd -r -g postgres postgres 要临时获取管理员权限可以使用gosu，不推荐sudo WORKDIR1格式为 WORKDIR /path/to/workdir 为后续RUN、CMD、ENTRYPOINT指令配置工作目录。 可以使用多个WORKDIR指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。例如: 1234WORKDIR /aWORKDIR bWORKDIR cRUN pwd 上面指令最终结果为：/a/b/c ONBUILD1格式为 ONBUILD [INSTRUCTION] 配置当所创建的镜像作为其他新创建镜像的基础镜像时，所执行的操作指令。例如： 1234[...]ONBUILD ADD . /app/srcONBUILD RUN /usr/local/bin/python-build --dir /app/src[...] Dockerfile使用上面的内容创建了镜像image-A，如果基于image-A创建新的镜像时，新的Dockerfile中使用FROM image-A指定基础镜像时，会自动执行ONBUILD指令内容，等价于在Dockerfile后面添加了两条指令，如： 1234FROM image-A# Automatically run the followingADD . /app/srcRUN /usr/local/bin/python-build --dir /app/src 使用ONBUILD指令的镜像，推荐在标签中注明，例如ruby:1.9-onbuild。 高级知识资源隔离Linux内核从2.4.19开始引入namespace的概念，其目的是将某个特定的全局系统资源（global system resource）通过抽象方法使得namespace中的进程看起来拥有它们自己的隔离的全局系统资源实例。 namespace 系统调用参数 隔离内容 在容器语境下的隔离效果 UTS CLONE_NEWUTS 主机名和域名 每个容器可以有自己的hostname和domainname IPC CLONE_NEWIPC 信号量、消息队列和共享内存 每个容器有其自己的System V IPC和POSIX消息队列文件系统，因此，只有在同一个IPC的进程之间才能互相通信 PID CLONE_NEWPID 进程编号 每个PID中的namespace中的进程可以有其独立的PID；每个容器可以有其PID为1的root进程；也使得容器可以在不同的host之间迁移，因为namespace中的进程ID和host无关了。这也使得容器中的每个进程有两个PID：容器中的PID和host上的PID Network CLONE_NEWNET 网络设备、网络栈、端口等 每个容器都有其独立的网络设备，IP地址，IP路由表，/proc/net目录，端口号等。这也使得多个容器内的同一个应用都绑定在各自容器的80端口上 Mount CLONE_NEWNS 挂载点（文件系统） 每个容器能看到不同的文件系统层次结构 User CLONE_NEWUSER 用户和组ID空间 在User中的进程的用户和组ID可以和在host上不通。每个container可以有不同的user和group id；一个host上的非特权用户可以成为User中的特权用户 Docker的资源隔离也是通过这六种方式实现的，在容器启动时，Docker会创建这六种namespace实例，然后把容器中的所有进程放到这些namespace中，使得Docker容器中只能看到隔离的系统资源。 网络模式docker目前支持四种网络工作的方式，分别为host，container，none，bridge。下面简单介绍下这几种网络模式。 host模式 Docker使用了Linux的Namespaces技术来进行资源隔离，如网卡、路由、进程等。如果启动容器的时候使用host模式，那么容器不会自己去创建一个独立的Network Namespace，而是与主机共用一个Network Namespace。容器也不会虚拟出自己的网卡、IP等，而是使用宿主机的IP和端口。 container模式 container模式指定创建的新的容器和已经存在的一个容器共享一个Network Namespace。container模式通过-net=container:NAME_OR_ID指定共享的容器。 none模式 在这种模式下，容器拥有自己的Network Namespace，但是不做任何网络配置，需要我们自己给容器添加网卡、IP等。 bridge模式 bridge模式是Docker默认的网络设置，此模式会为每一个容器分配Network Namespace、设置IP等，并将一个主机上的Docker容器连接到虚拟网桥上，实现容器和容器的主机的互连。​","permalink":"/2017/06/16/Docker学习笔记/","tags":[{"name":"Docker,Dockerfile","slug":"Docker-Dockerfile","permalink":"/tags/Docker-Dockerfile/"}]},{"title":"Nginx+Tomcat+Redis实现Session共享","date":"2017-06-07T06:43:12.000Z","path":"2017/06/07/session共享/","text":"Nginx+Tomcat+Redis实现Session共享之前的博文中简单的介绍了一下Nginx的负载均衡配置，比较简单，但是如果实现多台服务器之间的session共享就是一个难题了。 经过百度，查资料，找到了几种解决session共享的方案。 不适用session，换作cookie 1能把session改成cookie，就能避开session的一些弊端，也有资料表明在集群系统中不能使用session。但是博主思考再三，公司项目的session中存储一些比较重要的信息，在以后的业务中也会使用session中的数据，所以直接使用cookie这种方案果断舍弃。 应用服务器自行实现共享 1让服务器自行实现session共享，就需要提供一个后端服务器都能访问的公共容器来存储session，比如redis或者memcache，当系统需要获取session时，直接从redis或memcache中获取即可。 以上两种方式都与Nginx没多大关系了。下面说说使用nginx如何处理 ip_hash 1234之前的博客中对upstream的几种方式做了介绍，相信大家还记得ip_hash的介绍吧，每个请求按访问ip的hash结果分配，这样每个访问固定访问一个后端服务器。这样一来这个ip下的某个客户端和某个后端服务器就能建立稳固的session。这样每个客户端都只对应一个服务器，那就不存在需要共享session的需要了，不过只用ip这个因子来分配后端，所以还是存在一些缺陷，不能在以下情况下使用：1、nginx不是最前端的服务器。ip_hash要求nginx一定是最前端的服务器，否则nginx就得不到正确的ip，也就不能根据ip来分配后端了。比如squid(一个高性能的代理缓存服务器)作为最前端，那么nginx只能获取到squid所在服务器的ip地址，这种分流方式肯定会混乱的。2、nginx的后端还有其他方式的负载均衡。如果nginx后端又有其他的负载均衡，将请求又通过另外的方式分流了，那么某个客户端的请求肯定不能定位到同一台服务器上。 upstream_hash 12为了解决ip_hash的一些问题，可以使用upstream_hash这个第三方模块，这个模块大多数情况下是用作url_hash的，但是并不妨碍将它用来做session共享；这种方式不是很理解，就不做累述了，以后再慢慢研究。读者可自行查找资料学习。 来自于网络上的方案介绍完了，接下来说说博主项目中的实际操作。 博主最初的打算是使用redis来缓存系统数据，刚好也可以实现session共享。可惜，客户公司方面服务器资源不够，不让使用redis，上面第二种方案瞬间被阉割掉了，有点不爽。这里必须吐槽吐槽客户公司。 由于不让使用redis，所以只能使用第三种方式了，这里就不做太多的累述了，比较简单，配置nginx负载均衡的时候将upstream的方式配置为ip_hash即可，具体配置方式在上篇“Nginx负载均衡配置”中已有例子，可做参考。 简单的解释一下公司项目架构，公司项目采用前后台分离的架构，前端页面使用angularJS实现一种单页面应用，后台服务则使用SpringBoot为前端提供数据服务，后台开发者只需要关注后端逻辑，然后将前端需要的数据转为json传给前端，而不需要去考虑页面的跳转等，而前端人员也不需要关注后台逻辑，可以全身心的提供前端的用户体验度，最主要的是前后台分离后，系统开发职责划分的更加清晰。 关于前后台分离方案，这个博客讲的比较好，读者可做参考。 这样就完了？没有，这就完了这篇博客也太水了，虽然客户公司不让使用redis，但是博主还是自己抽时间使用nginx+tomcat+redis来自己实现session共享。 ——————————————————————这是一个分隔线——————————————————————- 1、软件准备因为是自己玩，所以直接在windows上开工了。 nginx-1.11.5，apache-tomcat-7.0.55，redis-2.6.12(windows版) 读者可从这里下载。其中有三个jar包最为重要： commons-pool-1.6.jar，jedis-2.1.0.jar，tomcat-redis-session-manager-tomcat7.jar，在软件包中的tomcat的lib目录下可找到。 2、配置tomcat在tomcat中的context.xml文件中加入以下内容 123456&lt;Valve className=\"com.radiadesign.catalina.session.RedisSessionHandlerValve\" /&gt;&lt;Manager className=\"com.radiadesign.catalina.session.RedisSessionManager\" host=\"localhost\" port=\"6379\" database=\"0\" maxInactiveInterval=\"60\" /&gt; 将配置好的tomcat三份，分别命名为apache-tomcat-7.0.55-1，apache-tomcat-7.0.55-2，apache-tomcat-7.0.55-3，然后去将每个tomcat的端口改掉，分别改为8081，8082，8083 3、配置Nginx将三个tomcat服务器用nginx代理， 12345upstream localhost &#123; server localhost:8081 weight=1; server localhost:8082 weight=1; server localhost:8083 weight=1; &#125; 4、测试页面在tomcat的webapp目录下新建test目录，在test中新建index.jsp，然后给三个tomcat都拷贝一份 123456789101112&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;!DOCTYPE html&gt;&lt;html lang=\"zh-CN\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt;&lt;/head&gt;&lt;body&gt;&lt;% out.println(request.getSession().getId());%&gt;&lt;/body&gt;&lt;/html&gt; 这可能是可与Hello，World媲美的页面了。 5、启动测试先启动redis，在启动三个tomcat，最后再启动nginx，然后访问页面。 有两种访问方式： 直接访问三个tomcat，【http://localhost:808x/test/index.jsp】，查看页面打印出的sessionId是否一致。 多次访问nginx，【http://localhost:80/test/index.jsp】，同时配置Nginx时将upstream配置为轮询，使用上面路径访问时会将请求轮流转发到三台服务器上，确实此时页面上的sessionId是否一致 好了，这种session共享完成。不过还没完，刚开始介绍时说的那三个jar包还没说说呢，接下来通过tomcat-redis-session-manager-tomcat7.jar的源码来解释一下这种方式实现session共享的原理。 6、Session共享原理分析在解释Session共享原理之前，我们先简单的看看Tomcat架构方面的一些知识作为铺垫。 ##### 6.1 Tomcat架构原理分析 正在深入剖析tomcat源码中，解读清楚了此部分补上","permalink":"/2017/06/07/session共享/","tags":[{"name":"Session","slug":"Session","permalink":"/tags/Session/"}]},{"title":"Nginx负载均衡配置","date":"2017-06-06T14:50:56.000Z","path":"2017/06/06/Nginx负载均衡配置/","text":"Nginx (“engine x”) 是一个高性能的HTTP和反向代理服务器，也是一个IMAP/POP3/SMTP服务器。Nginx是由Igor Sysoev为俄罗斯访问量第二的Rambler.ru站点开发的，第一个公开版本0.1.0发布于2004年10月4日。其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。2011年6月1日，nginx 1.0.4发布。Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。由俄罗斯的程序设计师Igor Sysoev所开发，供俄国大型的入口网站及搜索引擎Rambler（俄文：Рамблер）使用。其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好，中国大陆使用nginx网站用户有：百度、京东、新浪、网易、腾讯、淘宝等。 Nginx负载均衡配置这段来自百度百科，简单介绍一下，读者若需详细了解可自行查找资料，本文侧重于Nginx负载相关的具体操作配置介绍。 Nginx常用的功能有Http代理、反向代理，负载均衡器，web缓存等功能，最近项目需要做负载，简单的研究了一下nginx，对反向代理和负载均衡着重看了一下，所以接下来的文章主要对这两部分进行介绍。 1、Nginx服务器的安装windowns版Nginx下载地址：http://nginx.org/en/docs/windows.html windows上安装Nginx比较简单，Nginx官方已经提供了打包好的.exe的运行文件，不需要用户自己去编译运行。直接打开上面的地址，下载好windows版的nginx，解压后双击nginx.exe或者在命令窗口运行nginx.exe即可。 因为Nginx默认端口是80端口，所以启动成功之后在浏览器地址栏输入localhost就可以看到Nginx的欢迎页面。 linux版的Nginx下载地址：http://nginx.org/ 下载nginx之前，请确保自己的linux系统已经安装了g++，gcc。因为nginx是纯C语言编写，在linux下安装时需要去编译源码安装。 解压Nginx源码包 1&gt; tar -zxvf nginx-1.11.5.tar.gz 设置一下nginx配置信息 123&gt; chmod -R 777 nginx-1.11.5&gt; cd nginx-1.11.5&gt; ./configure --prefix=/usr/local/nginx #此处设置prefix，是设置nginx的安装路径 编译安装 1&gt; make | make install #将源码文件编译成可执行文件和各种库文件，并将其复制到上面设置的安装目录中 启动nginx 1&gt; /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf #这一步可以不指定nginx配置文件 还有最重要的一步，打开Nginx的防火墙端口 123&gt; vi /etc/sysconfig/iptables&gt; 添加端口，如： -A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT&gt; /etc/init.d/iptables restart #重启防火墙，让修改生效 在自己本机的浏览器中输入localhost就可以看到Nginx的欢迎页面。 2、配置Nginx​ 在真正开始配置之前，先说一下Nginx的配置文件配置的基础知识。（Linux和Windows的配置一样，不分开说了） &gt; Nginx的配置文件在安装目录下的conf目录中，一些默认配置都在这个目录下。 nginx.conf 的注释符号为 # 打开nginx.conf文件，可以大概浏览一下，配置文件基本可以分为几个模块 12345678910111213141516171819202122232425... #全局块events &#123; #events块 ...&#125;http #http块&#123; ... #http全局块 server #server块 &#123; ... #server全局块 location [PATTERN] #location块 &#123; ... &#125; location [PATTERN] &#123; ... &#125; &#125; server &#123; ... &#125; ... #http全局块&#125; 全局块：配置影像nginx的全局指令。一般有nginx的进程数，错误日志文件路径，nginx的主进程号等 events块：配置Nginx的工作模式，每个进程的最大连接数等 http块：可以嵌套多个server，配置代理，缓存，日志等功能以及第三方模块的配置。如文件引入，mime-type定义，连接超时时间，单连接请求数等等 server块：配置虚拟主机的相关参数，一个http中可以有多个server location块：配置请求的路由，以及各种页面的处理情况 给大家附上一个nginx的配置文件，博主在公司的测试环境上搭的一个负载均衡器。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#user nobody;#nginx进程数，建议设置为CPU总核心数worker_processes 1;#错误日志文件路径error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#nginx主进程号pid logs/nginx.pid;#工作模式与连接数上限events &#123; # 单个进程的最大连接数（最大连接数=连接数*进程数） worker_connections 1024;&#125;http &#123; #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #日志文件 access_log logs/access.log main; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 sendfile on; #防止网络阻塞 #tcp_nopush on; #长连接超时时间，单位是秒 keepalive_timeout 65; #服务器列表名称随便写 upstream global &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重，权值越高被分配到的几率越大。 server 192.168.100.100:8081; #weight=1 server 192.168.100.100:8084; ip_hash; #upstream的分配方式 &#125; #开启gzip压缩输出 #gzip on; server &#123; #监听端口 listen 8087; #域名可以有多个，用空格隔开 server_name 192.168.100.100; #默认编码 #charset koi8-r; #对“/”启用反向代理 location / &#123; #前端页面项目部署路径 root /home/fisCM/nginx/html; #默认主页面 index index.html index.htm; &#125; #5xx错误对应的页面 #error_page 500 502 503 504 /50x.html; #请求的url过滤，正则匹配，~为区分大小写，~*为不区分大小写。 #我们项目的请求路径为http://192.168.100.100:8087/springboot/... location ^~ /springboot/ &#123; #请求转向global 定义的服务器列表 proxy_pass http://global; &#125; &#125;&#125; 注：192.168.100.100地址是博主瞎写的，读者可改为自己实际的IP地址 由于项目比较简单，所以也没有太多复杂的配置，接下来对Nginx负载均衡的一些基础知识做一下简单介绍。 3、nginx的upstream的几种方式&gt; 轮询（默认） 每个请求按照时间顺序逐一分配到不同的后端服务器，如果后端服务器冗机，能自动剔除。 ip_hash 每个请求按访问ip的hash结果分配，这样每个访问固定访问一个后端服务器。 weight 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 fair(第三方) 按后端服务器的响应时间来分配请求，响应时间短的优先分配。 url_hash(第三方) 按访问URL的hash结果来分配请求，使每个URL定向到同一个后端服务器，后端服务器为缓存时比较适用。另外，在upstream中加入hash语句后，server语句不能写入weight等其他参数。 总结一下，负载均衡简单的理解其实可以看做是用户请求Nginx，Nginx将用户的请求URL按照配置的方式截取，然后按照配置的upstream的方式请求后端服务器。","permalink":"/2017/06/06/Nginx负载均衡配置/","tags":[{"name":"Nginx,负载均衡","slug":"Nginx-负载均衡","permalink":"/tags/Nginx-负载均衡/"}]},{"title":"SpringBoot动态数据源切换","date":"2017-06-01T13:30:56.000Z","path":"2017/06/01/SpringBoot动态数据源切换/","text":"最近项目中需要配置两个数据源，并且在不同的包下动态切换，为此，博主费劲九牛二虎之力百度了一天多，参考网上动态切换数据源的博客，实现了满足项目的数据源动态切换功能。 1、Spring的开发者还是挺有先见之明的，为我们提供了扩展Spring的AbstractRoutingDataSource抽象类，我们来看它的源码 1234567891011121314151617181920212223242526272829 /** * Retrieve the current target DataSource. Determines the * &#123;@link #determineCurrentLookupKey() current lookup key&#125;, performs * a lookup in the &#123;@link #setTargetDataSources targetDataSources&#125; map, * falls back to the specified * &#123;@link #setDefaultTargetDataSource default target DataSource&#125; if necessary. * @see #determineCurrentLookupKey() */protected DataSource determineTargetDataSource() &#123; Assert.notNull(this.resolvedDataSources, \"DataSource router not initialized\"); Object lookupKey = determineCurrentLookupKey(); DataSource dataSource = this.resolvedDataSources.get(lookupKey); if (dataSource == null &amp;&amp; (this.lenientFallback || lookupKey == null)) &#123; dataSource = this.resolvedDefaultDataSource; &#125; if (dataSource == null) &#123; throw new IllegalStateException(\"Cannot determine target DataSource for lookup key [\" + lookupKey + \"]\"); &#125; return dataSource;&#125;/** * Determine the current lookup key. This will typically be * implemented to check a thread-bound transaction context. * &lt;p&gt;Allows for arbitrary keys. The returned key needs * to match the stored lookup key type, as resolved by the * &#123;@link #resolveSpecifiedLookupKey&#125; method. */protected abstract Object determineCurrentLookupKey(); 源码注释解释的很清楚，determineTargetDataSource 方法通过数据源的标识获取当前数据源；determineCurrentLookupKey方法则是获取数据源标识。（作为英语彩笔，有道词典这种翻译软件还是特别好使的） 所以，我们实现动态切换数据源，需要实现determineCurrentLookupKey方法，动态提供数据源标识即可。 2、自定义DynamicDataSource类，继承AbstractRoutingDataSource，并实现determineCurrentLookupKey方法。 123456789101112public class DynamicDataSource extends AbstractRoutingDataSource &#123; @Override protected Object determineCurrentLookupKey() &#123; /** * DynamicDataSourceContextHolder代码中使用setDataSource * 设置当前的数据源，在路由类中使用getDataSource进行获取， * 交给AbstractRoutingDataSource进行注入使用。 */ return DynamicDataSourceContextHolder.getDataSource(); &#125;&#125; 3、创建统一数据源管理类DynamicDataSourceContextHolder 12345678910111213141516171819202122public class DynamicDataSourceContextHolder &#123; // 线程本地环境 private static final ThreadLocal&lt;String&gt; dataSources = new ThreadLocal&lt;String&gt;(); // 管理所有的数据源Id public static List&lt;String&gt; dataSourceIds = new ArrayList&lt;String&gt;(); public static void setDataSource(String dataSource) &#123; dataSources.set(dataSource); &#125; public static String getDataSource() &#123; return dataSources.get(); &#125; public static void clearDataSource() &#123; dataSources.remove(); &#125; // 判断指定的DataSource当前是否存在 public static boolean containsDataSource(String dataSourceId) &#123; return dataSourceIds.contains(dataSourceId); &#125;&#125; 4、重点来了，创建动态数据源注册器DynamicDataSourceRegister 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071 public class DynamicDataSourceRegister implements ImportBeanDefinitionRegistrar, EnvironmentAware &#123; // 默认数据连接池 public static final Object DATASOURCE_TYPE_DEFAULT = \"org.apache.tomcat.jdbc.pool.DataSource\"; private Class&lt;? extends DataSource&gt; dataSourceType; // 默认数据源 private DataSource defaultDataSource; private Map&lt;String, DataSource&gt; dataSourceMaps = new HashMap&lt;String, DataSource&gt;(); /** * 加载多数据源配置 * @param environment */ @Override public void setEnvironment(Environment environment) &#123; initDefaultDataSource(environment); &#125; /** * 初始化默认数据源 * @param environment */ private void initDefaultDataSource(Environment environment) &#123; RelaxedPropertyResolver propertyResolver = new RelaxedPropertyResolver(environment, \"spring.datasource.\"); try &#123; if(propertyResolver.getProperty(\"type\") == null) &#123; dataSourceType = (Class&lt;? extends DataSource&gt;)Class.forName(DATASOURCE_TYPE_DEFAULT.toString()); &#125; else &#123; dataSourceType = (Class&lt;? extends DataSource&gt;)Class.forName(propertyResolver.getProperty(\"type\")); &#125; &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; // 创建数据源 String jndiName = propertyResolver.getProperty(\"jndi-name\"); String[] jndiNames = jndiName.split(\",\"); defaultDataSource = new JndiDataSourceLookup().getDataSource(jndiNames[0]); dataSourceMaps.put(\"AAA\", defaultDataSource); DataSource dataSource1 = new JndiDataSourceLookup().getDataSource(jndiNames[1]); dataSourceMaps.put(\"BBB\", dataSource1); &#125; @Override public void registerBeanDefinitions(AnnotationMetadata annotationMetadata, BeanDefinitionRegistry beanDefinitionRegistry) &#123; Map&lt;String, Object&gt; targetDataSources = new HashMap&lt;String, Object&gt;(); // 将主数据源添加到更多数据源中 targetDataSources.put(\"dataSource\", defaultDataSource); DynamicDataSourceContextHolder.dataSourceIds.add(\"dataSource\"); // 添加更多数据源 targetDataSources.putAll(dataSourceMaps); for(String key : dataSourceMaps.keySet()) &#123; DynamicDataSourceContextHolder.dataSourceIds.add(key); &#125; // 创建DynamicDataSource GenericBeanDefinition beanDefinition = new GenericBeanDefinition(); beanDefinition.setBeanClass(DynamicDataSource.class); beanDefinition.setSynthetic(true); MutablePropertyValues mutablePropertyValues = beanDefinition.getPropertyValues(); mutablePropertyValues.addPropertyValue(\"defaultTargetDataSource\", defaultDataSource); mutablePropertyValues.addPropertyValue(\"targetDataSources\", targetDataSources); beanDefinitionRegistry.registerBeanDefinition(\"dataSource\", beanDefinition); &#125;&#125; 好了，这么一坨代码丢在这儿，相信读者也看着费劲，接下来对动态数据源注册器略作解释 &gt; EnvironmentAware接口提供了一个setEnvironment(Environment environment)方法，通过这个方法我们可以从application.properties配置文件中获取到所有数据源的配置信息，然后创建数据源并加载到内存中 &gt; ImportBeanDefinitionRegistrar接口，光看接口名字大概都能猜到是做什么的，对，就是注册Bean的。该接口用于在系统处理@Configuration class时注册更多的bean。是bean定义级别的操作，而非@Bean method/instance级别的。该接口提供了registerBeanDefinitions方法，该方法是在Spring加载bean时被Spring调用。通过setEnvironment方法，已经将配置文件中所有的数据源获取到了，然后在registerBeanDefinitions方法中将所有数据源注册到Spring容器中。 5、将动态数据源注册器导入到Spring容器中 1234567@SpringBootApplication@Import(&#123;DynamicDataSourceRegister.class&#125;)public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 需要注意的是，使用@Import导入的类必须满足符合以下的某一个条件： 导入的类使用@Configuration进行标注 导入的类中至少有一个使用@Bean标准的方法 导入的类实现了ImportSelector接口 导入的类实现了ImportBeanDefinitionRegistrar接口 到这一步了，是不是就完了呢，当然不是，以上这些步骤只是为切换数据源提供了基础 6、新建一个TargetDataSource注解 123456@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface TargetDataSource &#123; String value();&#125; 此注解用来标记当前的方法的数据源的，在需要指定数据源的方法上标记@TargetDataSource(“AAA”)注解即可，还没完，继续往下看。 7、新建数据源切换AOP切面 123456789101112131415161718192021222324@Aspect@Order(-1) //保证此AOP在@Transactional之前执行@Componentpublic class DynamicDataSourceAspect &#123; private transient static final Logger logger = LoggerFactory.getLogger(DynamicDataSourceAspect.class); // 通过注解切换数据源（细粒度） @Around(\"@annotation(targetDataSource)\") public Object changeDataSource(ProceedingJoinPoint joinPoint, TargetDataSource targetDataSource) throws Throwable &#123; Object object = null; String dataSourceId = targetDataSource.value(); if(DynamicDataSourceContextHolder.containsDataSource(dataSourceId)) &#123; logger.info(\"系统将使用&#123;&#125;数据源\", dataSourceId); DynamicDataSourceContextHolder.setDataSource(dataSourceId); &#125; else &#123; logger.debug(\"数据源&#123;&#125;不存在，将使用默认数据源&#123;&#125;\", dataSourceId, joinPoint.getSignature()); &#125; object=joinPoint.proceed(); DynamicDataSourceContextHolder.clearDataSource(); return object; &#125;&#125; 解释解释，这个切面呢，就是切标记了targetDataSource注解的方法，根据targetDataSource注解的value值设置系统当前的数据源。使用注解方式算是一种细粒度的控制，可切换多个数据源；粗粒度的就是直接切某一个包路径，而且只能是两个数据源互切。两种方式各有各的好处，看业务需要。不过总的来说，能解决问题的方法就是好方法。 最后附一下JNDI数据源在application.properties文件中的配置 1spring.datasource.jndi-name=java:comp/env/jdbc/AAA,java:comp/env/jdbc/BBB 其实，JNDI数据源也可以直接配置到application.properties文件中，或者两种模式都支持，此处不做累述。 ————————————————华丽的分割线—————————————————- 在项目的进展中，此数据源切换已被改造，增加了Druid数据源加密功能，因为是多数据源加密，和官网的有些不一样，代码就不一一累述，读者若有需要，可自行研究或联系博主获取","permalink":"/2017/06/01/SpringBoot动态数据源切换/","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"/tags/SpringBoot/"}]},{"title":"java基本数据类型缓存解析","date":"2016-12-21T16:46:28.000Z","path":"2016/12/22/java基本数据类型缓存解析/","text":"基本类型缓存解析一、Integer缓存解析：123456789101112131415161718192021222324252627282930private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low)); &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); &#125; private IntegerCache() &#123;&#125; &#125;public static Integer valueOf(int i) &#123; assert IntegerCache.high &gt;= 127; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 1、使用自动装箱（Integer i = 1）方式创建Integer对象时，会使用valueOf进行Integer对象的初始化，此时，会调用IntegerCache.high，这是需要对IntegerCache这个静态内部类进行初始化。2、IntegerCache类中有一个cache数组，在加载IntegerCache的时候，会将-128到127的Integer对象都创建了，并存到cache数组中，然后在判断当前初始化的Integer对象的值是否在-128到127之间，如果是，就直接从cache缓存中取，如果不存在，则new一个新的Integer对象。3、之后再使用自动装箱的方式创建Integer对象时，值在-128到127之间时会直接从cache缓存中取。 所以，使用自动装箱的方式创建的Integer对象，两者进行比较时，只要其值相等就是ture。而不在-128到127之间的，比较时会新new一个对象，而导致比较结果为false注意：Integer的最低值是固定的，只能是-128，而最高值是可以通过jvm参数设置的。在执行java程序的时候加上-XX:AutoBoxCacheMax=参数即可。 二、Long及Byte、Character缓存解析12345678910111213141516private static class LongCache &#123; private LongCache()&#123;&#125; static final Long cache[] = new Long[-(-128) + 127 + 1]; static &#123; for(int i = 0; i &lt; cache.length; i++) cache[i] = new Long(i - 128); &#125;&#125;public static Long valueOf(long l) &#123; final int offset = 128; if (l &gt;= -128 &amp;&amp; l &lt;= 127) &#123; // will cache return LongCache.cache[(int)l + offset]; &#125; return new Long(l);&#125; Long的缓存机制（LongCache）与Integer的类似，还有Character（CharacterCache），Byte（ByteCache）的缓存机制也是类似。不过只有Integer的最大值可以通过jvm参数设置，其他的都固定的。其中，Byte，Short，Long 的范围： -128 到 127；Character, 范围是 0 到 127。","permalink":"/2016/12/22/java基本数据类型缓存解析/","tags":[{"name":"java缓存","slug":"java缓存","permalink":"/tags/java缓存/"}]},{"title":"Spring Boot核心","date":"2016-12-18T12:26:36.000Z","path":"2016/12/18/Spring-Boot核心/","text":"一、Spring Boot基本配置 1、入口类和@SpringBootApplicationSpring Boot通常有一个名为*Application的入口类，入口类中有一个main方法，这个main方法其实就是一个标准的Java应用程序的入口方法。在main方法中使用SpringApplication.run(Chapter01Application.class, args),启动Spring Boot应用项目。 2、关闭特定的自动配置通过@SpringBootApplication源码可以看出，关闭特定的自动配置应该使用@SpringBootApplication注解的exclude参数，例如:@SpringBootApplication(exclude={DataSourceAutoConfiguration.class}) 3、定制Banner在Spring Boot启动的时候会有一个默认启动图案，这个图案是可以自定义的。1）我们在src/main/resources下新建一个banner.txt2）通过http://patorjk.com/software/taag网站生成字符，将生成的字符复制到banner.txt文件中3）自动程序，这时控制台图案将变成刚才生成的图案 4、关闭banner在main方法中修改为(Spring Boot:1.4.0)： 123SpringApplication application = new SpringApplication(Chapter1Application.class); application.setBannerMode(Mode.OFF); application.run(args); 或者 123new SpringApplicationBuilder(Chapter1Application.class) // .bannerMode(Mode.OFF) // .run(args); 5、Spring Boot配置文件Spring Boot使用一个全局的配置文件application.properties或application.yml，放置在src/main/resources目录或者类路径的/config下。Spring Boot不仅支持常规的properties配置文件，还支持yaml语言的配置文件。yaml是以数据为中心的语言，在配置数据的时候具有面向对象的特征。Spring Boot的全局配置文件的作用是对一些默认配置值进行修改。例如：修改tomcat端口为8080-&gt;8888，默认的访问路径为”/“-&gt;”/helloboot”。可以在application.properties中添加： 12server.port=9090 server.context-path=/helloBoot 6、官方starter pomspring-boot-starter &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spring Boot核心starter，包含自动配置、日志、yaml配置文件的支持spring-boot-starter-actuator &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 准生产特性，用来监控和管理应用spring-boot-starter-remote-shell &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 提供基于ssh协议的监控和管理spring-boot-starter-amqp &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 使用spring-rabbit来支持AMQPspring-boot-starter-aop &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 使用spring-aop和AspectJ支持面向切面变成spring-boot-starter-batch &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Spring Batch的支持spring-boot-starter-cache &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Spring Cache抽象的支持spring-boot-starter-cloud-connectors &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对云平台（Cloud Foundry，Heroku）提供的服务提供简化的连接方法spring-boot-starter-data-elasticsearch &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-data-elasticsearch对Elasticsearch的支持spring-boot-starter-data-gemfire &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-data-gemfire对分布式存储GenFile的支持spring-boot-starter-data-jpa &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对JPA的支持，包含spring-data-jpa，spring-orm和Hibernatespring-boot-starter-data-mongodb &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-data-mongodb，对MongoDB进行支持spring-boot-starter-data-rest &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-data-rest-webmvc将Spring Data Repository暴露REST形式的服务spring-boot-starter-data-solr &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-data-solr对Apache Solr数据检索平台的支持spring-boot-starter-freemarker &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对FreeMarker模板引擎的支持spring-boot-starter-groovy-templates &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Groovy模板引擎的支持spring-boot-starter-hateoas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-hateoas 通过spring-hateoas对基于HATEOAS的REST形式的网络服务的支持spring-boot-starter-hornetq &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过HornetQ对JMS的支持spring-boot-starter-integration &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对系统集成框架spring-integration的支持spring-boot-starter-jdbc &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对JDBC数据库的支持spring-boot-starter-jersey &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Jersery REST形式的网络服务的支持spring-boot-starter-jta-atomikos &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过Atomikos对分布式事务的支持spring-boot-starter-jta-bitronix &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过Bitronix对分布式事务的支持spring-boot-starter-mail &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对javax.mail的支持spring-boot-starter-mobile &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对spring-mobile的支持spring-boot-starter-mustache &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Mustache模板引擎的支持spring-boot-starter-redis &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对键值对内存数据库Redis的支持，包含spring-reidsspring-boot-starter-security &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对spring-security的支持spring-boot-starter-social-faceboot &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-social-faceboot对Facebook的支持spring-boot-starter-social-twitter &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 通过spring-social-twitter对Twitter的支持spring-boot-starter-test &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对常用的测试框架Junit，Hamcrest和Mockito的支持，包含spring-test模板spring-boot-starter-thymeleaf &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Thymeleaf模板引擎的支持，包含于Spring整合的配置spring-boot-starter-velocity &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Velocity模板引擎的支持spring-boot-starter-web &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对Web项目开发的支持，包含Tomcat和spring-webmvcspring-boot-starter-Tomcat &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Spring Boot默认的Servlet容器Tomcatspring-boot-starter-Jetty &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 使用Jetty作为Servlet容器替换Tomcatspring-boot-starter-undertow &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 使用Undertow作为Servlet容器替换Tomcatspring-boot-starter-logging &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Spring Boot默认的日志框架Logbackspring-boot-starter-log4j &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 支持使用Log4j日志框架spring-boot-starter-websocket &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对WebSocket开发的支持spring-boot-starter-ws &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对Spring Web Services的支持 还有第三方为Spring Boot所写的starter pom,这里不做介绍 7、使用xml配置Spring Boot提倡零配置，即无xml配置，但是在实际项目中，可能有些特殊要求，使得开发者必须使用xml配置，这时我们可以通过Spring提供的@ImportResource来加载xml配置，例如： 1@ImportResource(&#123;\"classpath:context.xml”&#125;) 8、命令行参数配置Spring Boot可以是基于jar包运行的，打成jar包的程序可以直接通过java -jar xx.jar来运行可以通过java -jar xx.jar —server.port=8888来修改Tomcat端口号 9、常规属性配置在常规Spring环境下，注入properties文件里的值得方式，通过@PropertySource指明properties文件的位置，然后通过@Value注入值。在Spring Boot里，只需要在application.properties定义属性，直接使用@Value注入即可。例如：在application.properties文件中添加属性： 12book.author=cmbook.name=spring boot 在com.gnd.springboot.config.init路径下新建PropertiesTests属性配置类，使用@Value注入book属性 12345678910111213141516171819@Componentpublic class PropertiesTests &#123; @Value(\"book.author\") private String author; @Value(\"book.name\") private String name; public String getAuthor() &#123; return author; &#125; public void setAuthor(String author) &#123; this.author = author; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 10、类型安全的配置（基于properties）Spring Boot提供了基于类型安全的配置方式，通过@ConfigurationProperties将properties属性和一个Bean及其属性关联，从而实现类型安全的配置。所以，常规属性配置可以修改为： 123456789101112131415161718@Component@ConfigurationProperties(prefix = \"book\")public class PropertiesTests &#123; private String author; private String name; public String getAuthor() &#123; return author; &#125; public void setAuthor(String author) &#123; this.author = author; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 11、日志配置Spring Boot支持Java Util Logging、Log4J、Log4J2和Logback作为日志框架，无论使用哪种日志框架，Spring Boot已为当前使用日志框架的控制台输出及文件输出做好了配置。默认情况下，Spring Boot使用Logback作为日志框架。日志级别:logging.file=/home/cm/mylog.log配置日志文件，格式为logging.level.包名=级别：logging.level.org.springframework.web=DEBUG 12、Profile配置Profile是Spring用来针对不同的环境对不同的配置提供支持的，全局Profile配置使用application-{profile}.properties(如application-prod.properties),通过在application.properties中设置spring.profiles.active=prod来指定活动的Profile例如：我们分为生产(prod)和开发(dev)环境，在生产环境下端口号为80，开发环境为8888。两种配置文件分别为： 12application-prod.properties: server.port=80application-dev.properties: server.port=8888 然后在application.properties增加： 1spring.profiles.active=dev(prod) 通过Profile可以灵活切换Spring Boot项目的配置了。 二、Spring Boot运行原理Spring Boot关于自动配置的源码在spring-boot-autoconfigure-1.4.0.RELEASE.jar内，主要包含了以下配置：若想知道Spring Boot为我们做了哪些自动配置，可以通过通过三种方式查看以启用和未启用的自动配置的报告：1）运行jar时增加—debug参数：java -jar xx.jar —debug2)在application.properties中设置属性：debug=true（这个方便点）3）在开发工具启动参数中配置 1、Spring Boot运行原理解析： 对@SpringBootApplication注解说明： @SpringBootApplication是一个组合注解，它的核心功能是由@EnableAutoConfiguration注解提供的。查看@EnableAutoConfiguration源码这里@Import注解导入配置功能，EnableAutoConfigurationImportSelector使用SpringFactoriesLoader.loadFactoryNames方法来扫描具有META-INF/spring.factories文件的jar包，而spring-boot-autoconfigure-1.4.0.RELEASE.jar里就有一个spring.factories文件，次问价中声明了有哪些自动配置。 任意打开一个AutoConfiguration文件，一般都有以下条件注解，在spring-boot-autoconfigure-1.4.0.RELEASE.jar的org.springframework.boot.autoconfigure.condition包下，条件注解如下： @ConditionalOnBean： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当容器里有指定的Bean的条件下 @ConditionalOnClass: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当类路径下有指定的类的条件下 @ConditionalOnExpression： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 基于SpEL表达式作为判断条件 @ConditionalOnJava： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 基于JVM版本作为判断条件 @ConditionalOnJndi： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在JNDI存在的条件下查找指定的位置 @ConditionalOnMissingBean： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当容器里没有指定Bean的情况下 @ConditionalOnMissingClass： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当类路径下没有指定的类的条件下 @ConditionalOnNotWebApplication： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当前项目不是Web项目的条件下 @ConditionalOnProperty： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 指定的属性是否有指定的值 @ConditionalOnResource： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 类路径是否有指定的值 @ConditionalOnSingleCandidate： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当指定Bean在容器中只有一个，或者虽然有多个但是指定首选的Bean @ConditionalOnWebApplication： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当前项目是Web项目的条件下这些注解都是使用了@Conditional元注解，不过是使用了不同的条件而已。 2、分析http的编码配置配置参数 HttpEncodingProperties的源码如下：这里的配置类可以直接在application.properties中以spring.http.encoding 为前缀配置，比如：如果需要修改默认编码方式，可通过spring.http.encoding.charset=gbk 配置。根据条件配置CharacterEncodingFilter的Bean，源码如下: 3、自定义自动配置（包装成starter pom）1）新建maven工程spring-boot-starter-hello，在pom.xml中添加如下配置: 12345678910111213141516&lt;properties&gt; &lt;spring-framework.version&gt;1.4.0.RELEASE&lt;/spring-framework.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2) 新建属性配置类HellpServiceProperties 1234567891011@ConfigurationProperties(prefix = \"hello\")public class HelloServiceProperties &#123; private static final String MSG = \"world\"; private String msg = MSG; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125;&#125; 此种配置方式为类型安全的属性获取。在application.properties中通过hello.msg= 来设置，若不设置，默认为hello.msg=world 3）新建依据类HelloService（此类可以是第三方类库的类） 123456789101112public class HelloService &#123; private String msg; public String sayHello() &#123; return \"Hello \" + msg; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125;&#125; 4）新建自动配置类 123456789101112131415@Configuration@EnableConfigurationProperties(HelloServiceProperties.class)@ConditionalOnClass(HelloService.class)@ConditionalOnProperty(prefix = \"hello\", value = \"enabled\", matchIfMissing = true)public class HelloServiceAutoConfiguration &#123; @Autowired private HelloServiceProperties helloServiceProperties; @Bean @ConditionalOnMissingBean(HelloService.class) public HelloService helloService() &#123; HelloService helloService = new HelloService(); helloService.setMsg(helloServiceProperties.getMsg()); return helloService; &#125;&#125; 根据HelloServiceProperties提供的参数，并通过@ConditionalOnClass来判断HelloService这个类在类路径中是否存在，且当这个容器中没有这个Bean的情况下自动配置这个Bean。5）注册自动配置在src/main/resources中新建META-INF/spring.factories文件，内容为 1org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.gnd.springboot.config.HelloServiceAutoConfiguration&lt;br&gt; 其中“\\”是为了在换行之后仍能读到属性，若有多个自动配置，以“,”分隔6）测试自定义自动配置新建一个maven web工程，添加如下依赖: 12345678910111213141516&lt;properties&gt; &lt;spring-framework.version&gt;1.4.0.RELEASE&lt;/spring-framework.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;spring-boot-starter-hello&lt;/groupId&gt; &lt;artifactId&gt;com.gnd.springboot&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; spring-boot-starter-hello为之前新建的自定义自动配置starter pom新建测试启动类 12345678910111213@RestController@SpringBootApplicationpublic class Chapter11Application &#123; @Autowired private HelloService helloService; @RequestMapping(\"/test\") public String index() &#123; return helloService.sayHello(); &#125; public static void main(String[] args)&#123; SpringApplication.run(Chapter11Application.class, args); &#125;&#125; 运行测试工程之后，浏览器输入”http://localhost:8080/test“测试，测试结果如下:新建application.properties配置文件，内容为 1hello.msg=haha 重启工程，浏览器输入”http://localhost:8080/test“测试，测试结果如下:","permalink":"/2016/12/18/Spring-Boot核心/","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"/tags/SpringBoot/"}]},{"title":"jdk各版本区别","date":"2016-12-17T16:06:43.000Z","path":"2016/12/18/jdk各版本区别/","text":"jdk5新特性1、自动装箱和拆箱2、枚举3、静态导入4、可变参数5、內省 内省是Java语言对Bean类属性、事件的一种缺省处理方法。例如类A中有属性那么，那我们可以通过getName，setName来得到其值或者设置新的值。通过getName/setName来访问name属性，这就是默认的规则。Java中提供了一套API用来访问某个属性的getter，setter方法，通过这些API可以使你不需要了解这个规则，这些API存放于包java.beans中。 一般的做法是通过类Introspector来获取某个对象的BeanInfo信息，然后通过BeanInfo来获取属性的描述器（PropertyDescriptor），通过这个属性描述器就可以获取某个属性对应的getter/setter方法，然后我们就可以通过反射机制来调用这些方法。 6、泛型7、For-Each循环jdk6新特性1、Desktop类和SystemTray类 AWT新增加了两个雷：Desktop，SystemTray。 Desktop可以用来打开系统默认浏览器指定的URL，打开系统默认邮件客户端给指定的邮件账号发邮件，用默认应用程序打开或编辑文件（比如，用记事本打开txt文件），用系统默认的打印机打印文档 SystemTray可以用来在系统托盘区创建一个托盘程序 2、使用JAXB2来实现对象与XML之间的映射 也就是对象与XML之间的映射（OXM），也可以通过XMLBeans和Castor等来实现同样的功能。 3、StAX StAX是The Streaming API for XML的缩写，一种利用拉模式解析(pull-parsing)XML文档的API.StAX通过提供一种基于事件迭代器(Iterator)的API让 程序员去控制xml文档解析过程,程序遍历这个事件迭代器去处理每一个解析事件，解析事件可以看做是程序拉出来的，也就是程序促使解析器产生一个解析事件 然后处理该事件，之后又促使解析器产生下一个解析事件，如此循环直到碰到文档结束符； SAX也是基于事件处理xml文档，但却 是用推模式解析，解析器解析完整个xml文档后，才产生解析事件，然后推给程序去处理这些事件；DOM 采用的方式是将整个xml文档映射到一颗内存树，这样就可以很容易地得到父节点和子结点以及兄弟节点的数据，但如果文档很大，将会严重影响性能。 4、使用Compiler API 使用JDK6的Compiler API去动态的编译Java源文件，Compiler API结合反射功能就可以实现动态的产生Java代码并编译执行这些代码。 5、轻量级Http Server API6、插入式注解处理API7、用Console开发控制台程序8、对脚本语言的支持如：ruby，groovy，javascript9、Common Annotationsjdk7新特性1、switch中可以使用字符串2、泛型的自动判断3、自定义自动关闭类（实现AutoCloseable接口）4、新增一些取环境信息的工具方法（System中的方法）5、Boolean类型反转，空指针安全，参数与位运算6、两个char间的equals7、安全的加减乘除1、对Java集合（Collections）的增强支持12345List&lt;String&gt; list=[\"item\"]; //向List集合中添加元素String item=list[0]; //从List集合中获取元素Set&lt;String&gt; set=&#123;\"item\"&#125;; //向Set集合对象中添加元Map&lt;String,Integer&gt; map=&#123;\"key\":1&#125;; //向Map集合中添加对象int value=map[\"key\"]; //从Map集合中获取对象 但是经过自己测试，按照上面的使用方法，并不能创建集合。 2、int支持二进制数据3、在try catch异常捕捉中，一个catch可以写多个异常类型1234567Connection conn = null;try &#123; Class.forName(\"com.mysql.jdbc.Driver\"); conn = DriverManager.getConnection(\"\",\"\",\"\");&#125; catch(ClassNotFoundException|SQLException ex) &#123; ex.printStackTrace();&#125; 4、try catch中资源定义好之后try catch自动关闭12345678910try (BufferedReader in = new BufferedReader(new FileReader(\"in.txt\")); BufferedWriter out = new BufferedWriter(new FileWriter(\"out.txt\"))) &#123; int charRead; while ((charRead = in.read()) != -1) &#123; System.out.printf(\"%c \", (char)charRead); out.write(charRead); &#125;&#125; catch (IOException ex) &#123; ex.printStackTrace();&#125; jdk8新特性1、接口的默认方法Java 8允许我们给接口添加一个非抽象的方法实现，只需要使用default关键字即可，这个特征又叫做扩展方法，示例如下： 123456public interface Formula &#123; double calculate(int a); default double sqrt(int a) &#123; return Math.sqrt(a); &#125;&#125; Formula接口在拥有calculate方法之外同时还定义了sqrt方法，实现了Formula接口的子类只需要实现一个calculate方法，默认方法sqrt将在子类上可以直接使用。 12345678 Formula formula = new Formula() &#123;@Overridepublic double calculate(int a) &#123; return sqrt(a * 100); &#125; &#125;; System.out.println(formula.calculate(100)); // 100.0 System.out.println(formula.sqrt(16)); // 4.0 文中的formula被实现为一个匿名类的实例，该代码非常 2、Lambda表达式1234567List&lt;String&gt; names = Arrays.asList(\"tom\",\"jace\",\"mike\");Collections.sort(names, new Comparator&lt;String&gt;() &#123; @Override public int compare(String o1, String o2) &#123; return o2.compareTo(o1); &#125;&#125;); 只需要给静态方法Collections.sort传入一个List对象以及一个比较器来指定顺序排列。通常做法都是创建一个匿名的比较器对象，然后将其传递给sort方法。在Java 8中提供了更简洁的语法，lambda表达式： 123Collections.sort(names, (String a, String b) -&gt; &#123; return b.compareTo(a);&#125;); 还可以更简洁： 1Collections.sort(names, (String a, String b) -&gt; b.compareTo(a)); 去掉大括号以及return关键字 1Collections.sort(names, (a,b) -&gt; b.compareTo(a)); Java编译器可以自动推导出参数类型，所以可以不用再写一次类型。 3、函数式接口Lambda表达式是如何在java的类型系统中表示的呢？每一个lambda表达式都对应着一个类型，通常是接口类型。而“函数式接口”是指仅仅只包含一个抽象方法的接口，每一个该类型的lambda表达式都会被匹配到这个抽象方法。因为默认方法不算抽象方法，所以也可以给自己的函数式接口添加默认方法。我们可以将lambda表达式当做一个抽象方法的接口类型，确保自己的接口一定达到这个要求，你只需要给你的接口添加@FunctionalInterface注解，编译器如果发现标注了这个注解的接口有多于一个抽象方法的时候就会报错。也就是说@FunctionalInterface注解标注的接口只能有一个抽象方法。例如： 1234567@FunctionalInterfacepublic interface Converter&lt;F, T&gt; &#123; T convert(F from);&#125;Converter&lt;String, Integer&gt; converter = (from) -&gt; Integer.valueOf(from);Integer converted = converter.convert(\"123\");System.out.println(converted); 以上代码不需要@FunctionalInterface注解也是正确的。 4、方法与构造函数引用上面的代码也可以通过静态方法引用来表示： 123Converter&lt;String, Integer&gt; converter = Integer::valueOf;Integer converted = converter.convert(\"123\");System.out.println(converted); Java8允许使用::关键字来传递方法或者构造函数引用，上面的代码展示了如何引用一个静态方法，我们也可以引用一个对象的方法： 12345678910public class Person &#123; String firstName; String lastName; Person() &#123; &#125; public Person(String firstName, String lastName) &#123; this.firstName = firstName; this.lastName = lastName; &#125;&#125; 指定一个用来创建Person对象的对象工厂接口： 123public interface PersonFactory&lt;P extends Person&gt; &#123; P create(String fisrtName, String lastName);&#125; 创建Person对象 12PersonFactory&lt;Person&gt; personFactory = Person::new;Person person = personFactory.create(\"Peter\",\"Parker”); 我们只需要使用Person::new 来获取Person类构造函数的引用，Java编译器就会自动根据PersonFactory.create方法的签名来选择合适的构造函数。 5、Lambda作用域在lambda表达式中访问外层作用域和老版本的匿名对象中的方式很相似。你可以直接访问标记了final的外层局部变量，或者实例的字段以及静态变量。 6、访问局部变量我们可以直接在lambda表达式中访问外层的局部变量 123final int num = 1;Converter&lt;Integer, String&gt; stringConverter = (from) -&gt; String.valueOf(from + num);stringConverter.convert(2); 但是和匿名对象不同的是，这里的变量num可以不用声明为final，该代码同样正确。 7、访问对象字段与静态变量和本地不良不同的是，lambda内部对于实例的字段以及静态变量是即可读又可写。该行为和匿名对象是一致的： 123456789101112static int outerStaticNum;int outerNum;public void testScopes() &#123; Converter stringConverter1 = (from) -&gt; &#123; outerNum = 23; return String.valueOf(from); &#125;; Converter stringConverter2 = (from) -&gt; &#123; outerStaticNum = 72; return String.valueOf(from); &#125;;&#125; 8、访问接口的默认方法9、Date API10、Annotation注解","permalink":"/2016/12/18/jdk各版本区别/","tags":[{"name":"jdk版本","slug":"jdk版本","permalink":"/tags/jdk版本/"}]},{"title":"Spring Boot入门","date":"2016-12-13T15:18:29.000Z","path":"2016/12/13/Spring-Boot入门/","text":"一、Spring Boot简介 Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。通过这种方式使得开发人员使用Spring开发极大的简便了配置过程，基本上实现了零配置。 Spring Boot有以下几个优点： 1、 没有代码生成，不需要XML配置文件 2、 内嵌Tomcat，Jetty或者Undertow服务器，不需要额外部署web工程到Servlet容器 3、 可以独立运行Spring应用程序 4、 提供了Maven，Gradle两种方法搭建Spring Boot工程 5、 无缝整合其他开源框架（只需要添加开源框架的依赖包，Spring Boot自动完成整合） 6、 提供可以直接在生产环境中使用的功能，如性能指标、应用信息和应用健康检查 二、Spring Boot入门工程搭建：1、采用Spring官网提供的SPRING INITIALIZR进行搭建。可以选择Maven Project或者Gradle Project来搭建，然后选择Spring Boot版本，输入Group，Artifact，以及需要的依赖包，然后点击Generate Project，会生成一个Artifact.zip压缩包，将Artifact工程导入常用的开发工具即可。 2、使用开发工具手动构建Spring Boot工程（本文采用Intellij Idea 2016.3）1、新建一个Maven的web工程2、在pom.xml文件中添加Spring Boot的相关依赖添加父级依赖，这样当前的项目就是Spring Boot项目了。spring-boot-starter-parent是一个特殊的starer，它用来提供相关的maven默认依赖，使用它之后，当前项目的的常用依赖包就可以省去version标签。 123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt; 添加spring-boot-starter依赖，spring-boot-starter是Spring Boot核心starter，包含自动配置、日志、yaml配置文件的支持。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 然后在dependencies中添加Web支持的starter pom。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; spring-boot-starter-web会自动添加它所依赖的jar包 然后添加Spring Boot的编译插件，便于使用Spring Boot命令操作工程 1234567&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt;&lt;/plugin&gt; 3、简单测试新建包路径com.gnd.chapter01，在com.gnd.chapter01包路径下新建Chapter01Application.java入口类，编写入口方法 123456@SpringBootApplicationpublic class Chapter01Application &#123; public static void main(String[] args)&#123; SpringApplication.run(Chapter01Application.class, args); &#125;&#125; 注：@SpringBootApplication是一个组合注解，查看其源码，@SpringBootApplication组合了@SpringBootConfiguration，@EnableAutoConfiguration，@ComponentScan三个注解，@SpringBootConfiguration表示当前类是一个启动应用程序的入口；@EnableAutoConfiguration注解开启自动配置，让Spring Boot根据类路径中的jar包依赖为当前项目进行自动配置(例如:添加了spring-boot-starter-web依赖，会自动添加tomcat和SpringMVC的依赖)；@ComponentScan会以Application入口类所在目录为根目录，自动扫描工程中标注了@Component注解的类。 然后新建目录controller，在其中新建一个HelloController测试类。 1234567@RestControllerpublic class HelloController &#123; @RequestMapping(\"/hello\") public String index() &#123; return \"Hello, World!\"; &#125;&#125; @RestController也是一个组合注解，组合了@Controller，@ResponseBody两个注解 4、运行使用Spring Boot命令运行工程，mvn spring-boot:run，或者直接运行Chapter01Application类，在浏览器中访问http://localhost:8080/hello即可访问HelloController。","permalink":"/2016/12/13/Spring-Boot入门/","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"/tags/SpringBoot/"}]}]